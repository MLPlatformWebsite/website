---
layout: jumbotron-container
title: About Machine Learning Platform
description: >-
    The machine learning platform is part of the Linaro Artificial Intelligence Initiative and is the home for open-source software libraries (Arm NN and Arm Compute Library) that optimise the execution of machine learning workloads on Arm-based processors.
permalink: /about/
jumbotron:
    title: About
    description: ""
    triangle-divider: true
    background-image: /assets/images/content/ml-banner.jpg
---
<div class="col-xs-12" markdown="1">
## What is the machine learning platform?

The machine learning platform is part of the [Linaro](https://www.linaro.org/news/linaro-announces-launch-of-machine-intelligence-initiative/)[ Artificial Intelligence Initiative](https://www.linaro.org/news/linaro-announces-launch-of-machine-intelligence-initiative/) and is the home for open-source software libraries (Arm NN and Arm Compute Library) that optimise the execution of machine learning workloads on Arm-based processors.

It enables a new era of advanced, ultra-efficient inference at the edge. Specifically designed for machine learning (ML) and neural network (NN) capabilities, the architecture is versatile enough to scale to any device, from the Internet of Things (IoT) to connected cars and servers.

</div>

<div class="col-xs-12 col-sm-8">
    <div class="double-scroll">
        <table class="table">
            <thead>
                <th>Project</th>
                <th>Description</th>
            </thead>
            <tbody>
                <tr>
                    <td>Arm NN</td>
                    <td>
                        Arm NN is an inference engine for CPUs, GPUs and NPUs. It bridges the gap between existing NN frameworks and the underlying IP. It enables efficient translation of existing neural network frameworks, such as TensorFlow and Caffe, allowing them to run efficiently – without modification – across Arm Cortex CPUs and Arm Mali GPUs. For more details see: <a href="https://developer.arm.com/products/processors/machine-learning/arm-nn">https://developer.arm.com/products/processors/machine-learning/arm-nn</a>
                    </td>
                </tr>
                <tr>
                    <td>Arm Compute Library</td>
                    <td>
                        The Arm Compute Library contains a comprehensive collection of software functions implemented for the Arm Cortex-A family of CPU processors and the Arm Mali family of GPUs. It is a convenient repository of low-level optimized functions that developers can source individually or use as part of complex pipelines in order to accelerate their algorithms and applications. For more details see: <a href="https://developer.arm.com/technologies/compute-library">https://developer.arm.com/technologies/compute-library</a>
                    </td>
                </tr>
            </tbody>
        </table>
    </div>
</div>

<div class="col-xs-12" markdown="1">
## Our Focus

The aim of the machine learning platform is to provide a home for the development of open-source software that optimises and simplifies the running of machine learning jobs on Arm-based processors.

We aim to create a thriving community of developers working together to make the machine learning platform a key resource for achieving ultra-efficient inference at the edge.

</div>

<div class="col-xs-12" markdown="1">
## Join Us!

If you or your company are interested in participating in this effort, please visit the [Contributing](/contributing/) page. We welcome all feedback and participation in the development of the machine learning platform.

</div>

<div class="col-xs-12" markdown="1">
## Linaro’s Artificial Intelligence Initiative

In 2018, Linaro launched the Artificial Intelligence Initiative, kick starting with Arm’s donation of Arm NN. The initiative aims to provide the best-in-class Deep Learning performance by leveraging Neural Network acceleration in IP and SoCs from the Arm ecosystem. Currently every IP vendor forks the runtime of each machine learning framework to integrate their hardware blocks and then tune for performance. This leads to a duplication of effort amongst all players, perpetual cost of re-integration for every new rebasing, and overall increased total cost of ownership. To find out more about the initiative and how to get involved, go to [https://www.linaro.org/engineering/artificial-intelligence/](https://www.linaro.org/engineering/artificial-intelligence/). 
</div>
