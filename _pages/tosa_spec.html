---
layout: none
permalink: /tosa/tosa_spec.html
---
<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 2.0.18">
<title>TOSA 1.0.0 specification</title>
<style>
/* Asciidoctor default stylesheet | MIT License | https://asciidoctor.org */
/* Remove comment around @import statement below when using as a custom stylesheet */
article,aside,details,figcaption,figure,footer,header,hgroup,main,nav,section,summary{display:block}
audio,canvas,video{display:inline-block}
audio:not([controls]){display:none;height:0}
[hidden],template{display:none}
script{display:none!important}
html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}
body{margin:0}
a{background:transparent}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
abbr[title]{border-bottom:1px dotted}
b,strong{font-weight:bold}
dfn{font-style:italic}
hr{-moz-box-sizing:content-box;box-sizing:content-box;height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type="button"],input[type="reset"],input[type="submit"]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type="checkbox"],input[type="radio"]{box-sizing:border-box;padding:0}
input[type="search"]{-webkit-appearance:textfield;-moz-box-sizing:content-box;-webkit-box-sizing:content-box;box-sizing:content-box}
input[type="search"]::-webkit-search-cancel-button,input[type="search"]::-webkit-search-decoration{-webkit-appearance:none}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,*:before,*:after{-moz-box-sizing:border-box;-webkit-box-sizing:border-box;box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Helvetica Neue", "Helvetica", Helvetica, Arial, sans-serif; font-weight: normal;font-style:normal;line-height:1;position:relative;cursor:auto}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
body{-webkit-font-smoothing:antialiased}
img,object,svg{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
.center{margin-left:auto;margin-right:auto}
.spread{width:100%}
p.lead,.paragraph.lead>p,#preamble>.sectionbody>.paragraph:first-of-type p{font-size:1.21875em;line-height:1.6}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#002b49;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0;direction:ltr}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:none}
p{font-family:inherit;font-weight:400;font-size:1em;line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#002b49;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #ddddd8;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em;height:0}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:Consolas,"Liberation Mono", Courier, monospace;font-weight:normal;color:rgba(0,0,0,.9)}
ul,ol,dl{font-size:1em;line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol,ul.no-bullet,ol.no-bullet{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0;font-size:1em}
ul.square li ul,ul.circle li ul,ul.disc li ul{list-style:inherit}
ul.square{list-style-type:square}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ul.no-bullet{list-style:none}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
abbr,acronym{text-transform:uppercase;font-size:90%;color:rgba(0,0,0,.8);border-bottom:1px dotted #ddd;cursor:help}
abbr{text-transform:none}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote cite{display:block;font-size:.9375em;color:rgba(0,0,0,.6)}
blockquote cite:before{content:"\2014 \0020"}
blockquote cite a,blockquote cite a:visited{color:rgba(0,0,0,.6)}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media only screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}
table{background:#fff;margin-bottom:1.25em;border:solid 1px #dedede}
table thead,table tfoot{background:#f7f8f7;font-weight:bold}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt,table tr:nth-of-type(even){background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{display:table-cell;line-height:1.6}
body{tab-size:4}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.clearfix:before,.clearfix:after,.float-group:before,.float-group:after{content:" ";display:table}
.clearfix:after,.float-group:after{clear:both}
*:not(pre)>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background-color:#f7f7f8;-webkit-border-radius:4px;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed}
pre,pre>code{line-height:1.45;color:rgba(0,0,0,.9);font-family:Consolas, "Liberation Mono", Courier, monospace;font-weight:normal;text-rendering:optimizeSpeed}
.keyseq{color:rgba(51,51,51,.8)}
kbd{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;display:inline-block;color:rgba(0,0,0,.8);font-size:.65em;line-height:1.45;background-color:#f7f7f7;border:1px solid #ccc;-webkit-border-radius:3px;border-radius:3px;-webkit-box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em white inset;box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em #fff inset;margin:0 .15em;padding:.2em .5em;vertical-align:middle;position:relative;top:-.1em;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menu{color:rgba(0,0,0,.8)}
b.button:before,b.button:after{position:relative;top:-1px;font-weight:400}
b.button:before{content:"[";padding:0 3px 0 2px}
b.button:after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin-left:auto;margin-right:auto;margin-top:0;margin-bottom:0;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header:before,#header:after,#content:before,#content:after,#footnotes:before,#footnotes:after,#footer:before,#footer:after{content:" ";display:table}
#header:after,#content:after,#footnotes:after,#footer:after{clear:both}
#content{margin-top:1.25em}
#content:before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #ddddd8}
#header>h1:only-child,body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #ddddd8;padding-bottom:8px}
#header .details{border-bottom:1px solid #ddddd8;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:-ms-flexbox;display:-webkit-flex;display:flex;-ms-flex-flow:row wrap;-webkit-flex-flow:row wrap;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span:before{content:"\00a0\2013\00a0"}
#header .details br+span.author:before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark:before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber:after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #ddddd8;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #efefed;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Noto",sans-serif;list-style-type:none}
#toc li{line-height:1.3334;margin-top:.3334em}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#002b49;font-size:1.2em}
@media only screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
#toc.toc2{margin-top:0!important;background-color:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #efefed;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;margin-bottom:.8rem;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #efefed;left:auto;right:0}}
@media only screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}
#content #toc{border-style:solid;border-width:1px;border-color:#e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;-webkit-border-radius:4px;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:100%;background-color:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:rgba(255,255,255,.8);line-height:1.44}
.sect1{padding-bottom:.625em}
@media only screen and (min-width:768px){.sect1{padding-bottom:1.25em}}
.sect1+.sect1{border-top:1px solid #efefed}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor:before,h2>a.anchor:before,h3>a.anchor:before,#toctitle>a.anchor:before,.sidebarblock>.content>.title>a.anchor:before,h4>a.anchor:before,h5>a.anchor:before,h6>a.anchor:before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem}
table.tableblock>caption.title{white-space:nowrap;overflow:visible;max-width:0}
.paragraph.lead>p,#preamble>.sectionbody>.paragraph:first-of-type p{color:rgba(0,0,0,.85)}
table.tableblock #preamble>.sectionbody>.paragraph:first-of-type p{font-size:inherit}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #ddddd8;color:rgba(0,0,0,.6)}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border-style:solid;border-width:1px;border-color:#e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;-webkit-border-radius:4px;border-radius:4px}
.exampleblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child{margin-bottom:0}
.sidebarblock{border-style:solid;border-width:1px;border-color:#e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;-webkit-border-radius:4px;border-radius:4px}
.sidebarblock>:first-child{margin-top:0}
.sidebarblock>:last-child{margin-bottom:0}
.sidebarblock>.content>.title{color:#002b49;margin-top:0;text-align:center}
.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock pre:not(.highlight),.listingblock pre[class="highlight"],.listingblock pre[class^="highlight "],.listingblock pre.CodeRay,.listingblock pre.prettyprint{background:#f7f7f8}
.sidebarblock .literalblock pre,.sidebarblock .listingblock pre:not(.highlight),.sidebarblock .listingblock pre[class="highlight"],.sidebarblock .listingblock pre[class^="highlight "],.sidebarblock .listingblock pre.CodeRay,.sidebarblock .listingblock pre.prettyprint{background:#f2f1f1}
.literalblock pre,.literalblock pre[class],.listingblock pre,.listingblock pre[class]{-webkit-border-radius:4px;border-radius:4px;word-wrap:break-word;padding:1em;font-size:.8125em}
.literalblock pre.nowrap,.literalblock pre[class].nowrap,.listingblock pre.nowrap,.listingblock pre[class].nowrap{overflow-x:auto;white-space:pre;word-wrap:normal}
@media only screen and (min-width:768px){.literalblock pre,.literalblock pre[class],.listingblock pre,.listingblock pre[class]{font-size:.90625em}}
@media only screen and (min-width:1280px){.literalblock pre,.literalblock pre[class],.listingblock pre,.listingblock pre[class]{font-size:1em}}
.literalblock.output pre{color:#f7f7f8;background-color:rgba(0,0,0,.9)}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;-webkit-border-radius:4px;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.listingblock>.content{position:relative}
.listingblock code[data-lang]:before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:#999}
.listingblock:hover code[data-lang]:before{display:block}
.listingblock.terminal pre .command:before{content:attr(data-prompt);padding-right:.5em;color:#999}
.listingblock.terminal pre .command:not([data-prompt]):before{content:"$"}
table.pyhltable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.pyhltable td{vertical-align:top;padding-top:0;padding-bottom:0;line-height:1.45}
table.pyhltable td.code{padding-left:.75em;padding-right:0}
pre.pygments .lineno,table.pyhltable td:not(.code){color:#999;padding-left:0;padding-right:.5em;border-right:1px solid #ddddd8}
pre.pygments .lineno{display:inline-block;margin-right:.25em}
table.pyhltable .linenodiv{background:none!important;padding-right:0!important}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock blockquote p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote:before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#002b49;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.5em;margin-right:.5ex;text-align:right}
.quoteblock .quoteblock{margin-left:0;margin-right:0;padding:.5em 0;border-left:3px solid rgba(0,0,0,.6)}
.quoteblock .quoteblock blockquote{padding:0 0 0 .75em}
.quoteblock .quoteblock blockquote:before{display:none}
.verseblock{margin:0 1em 1.25em 1em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.025em;color:rgba(0,0,0,.6)}
.quoteblock.abstract{margin:0 0 1.25em 0;display:block}
.quoteblock.abstract blockquote,.quoteblock.abstract blockquote p{text-align:left;word-spacing:0}
.quoteblock.abstract blockquote:before,.quoteblock.abstract blockquote p:first-of-type:before{display:none}
table.tableblock{max-width:100%;border-collapse:separate}
table.tableblock td>.paragraph:last-child p>p:last-child,table.tableblock th>p:last-child,table.tableblock td>p:last-child{margin-bottom:0}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table thead tr th{background:rgba(0,145,189,0.6); color:white}
table.grid-all th.tableblock,table.grid-all td.tableblock{border-width:0 1px 1px 0}
table.grid-all tfoot>tr>th.tableblock,table.grid-all tfoot>tr>td.tableblock{border-width:1px 1px 0 0}
table.grid-cols th.tableblock,table.grid-cols td.tableblock{border-width:0 1px 0 0}
table.grid-all *>tr>.tableblock:last-child,table.grid-cols *>tr>.tableblock:last-child{border-right-width:0}
table.grid-rows th.tableblock,table.grid-rows td.tableblock{border-width:0 0 1px 0}
table.grid-all tbody>tr:last-child>th.tableblock,table.grid-all tbody>tr:last-child>td.tableblock,table.grid-all thead:last-child>tr>th.tableblock,table.grid-rows tbody>tr:last-child>th.tableblock,table.grid-rows tbody>tr:last-child>td.tableblock,table.grid-rows thead:last-child>tr>th.tableblock{border-bottom-width:0}
table.grid-rows tfoot>tr>th.tableblock,table.grid-rows tfoot>tr>td.tableblock{border-width:1px 0 0 0}
table.frame-all{border-width:1px}
table.frame-sides{border-width:0 1px}
table.frame-topbot{border-width:1px 0}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{display:table-cell;line-height:1.6;background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
td>div.verse{white-space:pre}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
ol>li p,ul>li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.unstyled,ol.unnumbered,ul.checklist,ul.none{list-style-type:none}
ul.unstyled,ol.unnumbered,ul.checklist{margin-left:.625em}
ul.checklist li>p:first-child>.fa-square-o:first-child,ul.checklist li>p:first-child>.fa-check-square-o:first-child{width:1em;font-size:.85em}
ul.checklist li>p:first-child>input[type="checkbox"]:first-child{width:1em;position:relative;top:1px}
ul.inline{margin:0 auto .625em auto;margin-left:-1.375em;margin-right:0;padding:0;list-style:none;overflow:hidden}
ul.inline>li{list-style:none;float:left;margin-left:1.375em;display:block}
ul.inline>li>*{display:block}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1,td.hdlist2{vertical-align:top;padding:0 .625em}
td.hdlist1{font-weight:bold;padding-bottom:1.25em}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist>table tr>td:first-of-type{padding:0 .75em;line-height:1}
.colist>table tr>td:last-of-type{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:solid 4px #fff;-webkit-box-shadow:0 0 0 1px #ddd;box-shadow:0 0 0 1px #ddd}
.imageblock.left,.imageblock[style*="float: left"]{margin:.25em .625em 1.25em 0}
.imageblock.right,.imageblock[style*="float: right"]{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none;display:inline-block}
a.image object{pointer-events:none}
sup.footnote,sup.footnoteref{font-size:.875em;position:static;vertical-align:super}
sup.footnote a,sup.footnoteref a{text-decoration:none}
sup.footnote a:active,sup.footnoteref a:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em 0;border-width:1px 0 0 0}
#footnotes .footnote{padding:0 .375em 0 .225em;line-height:1.3334;font-size:.875em;margin-left:1.2em;text-indent:-1.05em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
.gist .file-data>table{border:0;background:#fff;width:100%;margin-bottom:0}
.gist .file-data>table td.line-data{width:99%}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background-color:#00fafa}
.black{color:#000}
.black-background{background-color:#000}
.blue{color:#0000bf}
.blue-background{background-color:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background-color:#fa00fa}
.gray{color:#606060}
.gray-background{background-color:#7d7d7d}
.green{color:#006000}
.green-background{background-color:#007d00}
.lime{color:#00bf00}
.lime-background{background-color:#00fa00}
.maroon{color:#600000}
.maroon-background{background-color:#7d0000}
.navy{color:#000060}
.navy-background{background-color:#00007d}
.olive{color:#606000}
.olive-background{background-color:#7d7d00}
.purple{color:#600060}
.purple-background{background-color:#7d007d}
.red{color:#bf0000}
.red-background{background-color:#fa0000}
.silver{color:#909090}
.silver-background{background-color:#bcbcbc}
.teal{color:#006060}
.teal-background{background-color:#007d7d}
.white{color:#bfbfbf}
.white-background{background-color:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background-color:#fafa00}
span.icon>.fa{cursor:default}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note:before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip:before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning:before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution:before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important:before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background-color:rgba(0,0,0,.8);-webkit-border-radius:100px;border-radius:100px;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]:after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
dt,th.tableblock,td.content,div.footnote{text-rendering:optimizeLegibility}
h1,h2,p,td.content,span.alt{letter-spacing:-.01em}
p strong,td.content strong,div.footnote strong{letter-spacing:-.005em}
p,blockquote,dt,td.content,span.alt{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background-color:#fffef7;border-color:#e0e0dc;-webkit-box-shadow:0 1px 4px #e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@media print{@page{margin:1.25cm .75cm}
*{-webkit-box-shadow:none!important;box-shadow:none!important;text-shadow:none!important}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^=";http:"]:not(.bare):after,a[href^="https:"]:not(.bare):after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]:after{content:" (" attr(title) ")"}
pre,blockquote,tr,img,object,svg{page-break-inside:avoid}
thead{display:table-header-group}
svg{max-width:100%}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #ddddd8!important;padding-bottom:0!important}
.sect1{padding-bottom:0!important}
.sect1+.sect1{border:0!important}
#header>h1:first-child{margin-top:1.25rem}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em 0}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span:before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]:before{display:block}
#footer{background:none!important;padding:0 .9375em}
#footer-text{color:rgba(0,0,0,.6)!important;font-size:.9em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}

</style>
<style>
/*! Stylesheet for CodeRay to loosely match GitHub themes | MIT License */
pre.CodeRay{background:#f7f7f8}
.CodeRay .line-numbers{border-right:1px solid;opacity:.35;padding:0 .5em 0 0;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}
.CodeRay span.line-numbers{display:inline-block;margin-right:.75em}
.CodeRay .line-numbers strong{color:#000}
table.CodeRay{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.CodeRay td{vertical-align:top;line-height:inherit}
table.CodeRay td.line-numbers{text-align:right}
table.CodeRay td.code{padding:0 0 0 .75em}
.CodeRay .debug{color:#fff!important;background:navy!important}
.CodeRay .annotation{color:#007}
.CodeRay .attribute-name{color:navy}
.CodeRay .attribute-value{color:#700}
.CodeRay .binary{color:#509}
.CodeRay .comment{color:#998;font-style:italic}
.CodeRay .char{color:#04d}
.CodeRay .char .content{color:#04d}
.CodeRay .char .delimiter{color:#039}
.CodeRay .class{color:#458;font-weight:bold}
.CodeRay .complex{color:#a08}
.CodeRay .constant,.CodeRay .predefined-constant{color:teal}
.CodeRay .color{color:#099}
.CodeRay .class-variable{color:#369}
.CodeRay .decorator{color:#b0b}
.CodeRay .definition{color:#099}
.CodeRay .delimiter{color:#000}
.CodeRay .doc{color:#970}
.CodeRay .doctype{color:#34b}
.CodeRay .doc-string{color:#d42}
.CodeRay .escape{color:#666}
.CodeRay .entity{color:#800}
.CodeRay .error{color:#808}
.CodeRay .exception{color:inherit}
.CodeRay .filename{color:#099}
.CodeRay .function{color:#900;font-weight:bold}
.CodeRay .global-variable{color:teal}
.CodeRay .hex{color:#058}
.CodeRay .integer,.CodeRay .float{color:#099}
.CodeRay .include{color:#555}
.CodeRay .inline{color:#000}
.CodeRay .inline .inline{background:#ccc}
.CodeRay .inline .inline .inline{background:#bbb}
.CodeRay .inline .inline-delimiter{color:#d14}
.CodeRay .inline-delimiter{color:#d14}
.CodeRay .important{color:#555;font-weight:bold}
.CodeRay .interpreted{color:#b2b}
.CodeRay .instance-variable{color:teal}
.CodeRay .label{color:#970}
.CodeRay .local-variable{color:#963}
.CodeRay .octal{color:#40e}
.CodeRay .predefined{color:#369}
.CodeRay .preprocessor{color:#579}
.CodeRay .pseudo-class{color:#555}
.CodeRay .directive{font-weight:bold}
.CodeRay .type{font-weight:bold}
.CodeRay .predefined-type{color:inherit}
.CodeRay .reserved,.CodeRay .keyword{color:#000;font-weight:bold}
.CodeRay .key{color:#808}
.CodeRay .key .delimiter{color:#606}
.CodeRay .key .char{color:#80f}
.CodeRay .value{color:#088}
.CodeRay .regexp .delimiter{color:#808}
.CodeRay .regexp .content{color:#808}
.CodeRay .regexp .modifier{color:#808}
.CodeRay .regexp .char{color:#d14}
.CodeRay .regexp .function{color:#404;font-weight:bold}
.CodeRay .string{color:#d20}
.CodeRay .string .string .string{background:#ffd0d0}
.CodeRay .string .content{color:#d14}
.CodeRay .string .char{color:#d14}
.CodeRay .string .delimiter{color:#d14}
.CodeRay .shell{color:#d14}
.CodeRay .shell .delimiter{color:#d14}
.CodeRay .symbol{color:#990073}
.CodeRay .symbol .content{color:#a60}
.CodeRay .symbol .delimiter{color:#630}
.CodeRay .tag{color:teal}
.CodeRay .tag-special{color:#d70}
.CodeRay .variable{color:#036}
.CodeRay .insert{background:#afa}
.CodeRay .delete{background:#faa}
.CodeRay .change{color:#aaf;background:#007}
.CodeRay .head{color:#f8f;background:#505}
.CodeRay .insert .insert{color:#080}
.CodeRay .delete .delete{color:#800}
.CodeRay .change .change{color:#66f}
.CodeRay .head .head{color:#f4f}
</style>
</head>
<body class="article toc2 toc-left">
<div id="header">
<h1>TOSA 1.0.0 specification</h1>
<div id="toc" class="toc2">
<div id="toctitle">Table of Contents</div>
<ul class="sectlevel1">
<li><a href="#_introduction">1. Introduction</a>
<ul class="sectlevel2">
<li><a href="#_overview">1.1. Overview</a></li>
<li><a href="#_goals">1.2. Goals</a></li>
<li><a href="#_specification">1.3. Specification</a></li>
<li><a href="#_operator_selection_principles">1.4. Operator Selection Principles</a></li>
<li><a href="#_versioning">1.5. Versioning</a>
<ul class="sectlevel3">
<li><a href="#_backwards_compatibility">1.5.1. Backwards Compatibility</a></li>
</ul>
</li>
<li><a href="#_profiles">1.6. Profiles</a></li>
<li><a href="#_levels">1.7. Levels</a></li>
<li><a href="#_status">1.8. Status</a></li>
<li><a href="#_supported_number_formats">1.9. Supported Number Formats</a></li>
<li><a href="#_compliance">1.10. Compliance</a>
<ul class="sectlevel3">
<li><a href="#_tosa_graph_compliance">1.10.1. TOSA Graph Compliance</a></li>
<li><a href="#_integer_profile_compliance">1.10.2. Integer Profile Compliance</a></li>
<li><a href="#_floating_point_profile_compliance">1.10.3. Floating-Point Profile Compliance</a></li>
</ul>
</li>
<li><a href="#_tensor_definitions">1.11. Tensor Definitions</a>
<ul class="sectlevel3">
<li><a href="#_tensors">1.11.1. Tensors</a></li>
<li><a href="#_data_layouts">1.11.2. Data Layouts</a></li>
<li><a href="#_broadcasting">1.11.3. Broadcasting</a></li>
</ul>
</li>
<li><a href="#_integer_behavior">1.12. Integer Behavior</a>
<ul class="sectlevel3">
<li><a href="#_quantization">1.12.1. Quantization</a></li>
<li><a href="#_precision_scaling">1.12.2. Precision Scaling</a></li>
<li><a href="#_integer_convolutions">1.12.3. Integer Convolutions</a></li>
<li><a href="#_integer_elementwise_operators">1.12.4. Integer Elementwise Operators</a></li>
<li><a href="#_general_unary_functions">1.12.5. General Unary Functions</a></li>
</ul>
</li>
<li><a href="#_reporting_errors">1.13. Reporting Errors</a></li>
<li><a href="#_other_publications">1.14. Other Publications</a></li>
</ul>
</li>
<li><a href="#_operators">2. Operators</a>
<ul class="sectlevel2">
<li><a href="#_operator_arguments">2.1. Operator Arguments</a></li>
<li><a href="#operator-graphs">2.2. Operator Graphs</a></li>
<li><a href="#_tensor_operators">2.3. Tensor Operators</a>
<ul class="sectlevel3">
<li><a href="#_argmax">2.3.1. ARGMAX</a></li>
<li><a href="#_avg_pool2d">2.3.2. AVG_POOL2D</a></li>
<li><a href="#_conv2d">2.3.3. CONV2D</a></li>
<li><a href="#_conv3d">2.3.4. CONV3D</a></li>
<li><a href="#_depthwise_conv2d">2.3.5. DEPTHWISE_CONV2D</a></li>
<li><a href="#_fft2d">2.3.6. FFT2D</a></li>
<li><a href="#_matmul">2.3.7. MATMUL</a></li>
<li><a href="#_max_pool2d">2.3.8. MAX_POOL2D</a></li>
<li><a href="#_rfft2d">2.3.9. RFFT2D</a></li>
<li><a href="#_transpose_conv2d">2.3.10. TRANSPOSE_CONV2D</a></li>
</ul>
</li>
<li><a href="#_activation_functions">2.4. Activation Functions</a>
<ul class="sectlevel3">
<li><a href="#_clamp">2.4.1. CLAMP</a></li>
<li><a href="#_erf">2.4.2. ERF</a></li>
<li><a href="#_sigmoid">2.4.3. SIGMOID</a></li>
<li><a href="#_tanh">2.4.4. TANH</a></li>
</ul>
</li>
<li><a href="#_elementwise_binary_operators">2.5. Elementwise Binary Operators</a>
<ul class="sectlevel3">
<li><a href="#_add">2.5.1. ADD</a></li>
<li><a href="#_arithmetic_right_shift">2.5.2. ARITHMETIC_RIGHT_SHIFT</a></li>
<li><a href="#_bitwise_and">2.5.3. BITWISE_AND</a></li>
<li><a href="#_bitwise_or">2.5.4. BITWISE_OR</a></li>
<li><a href="#_bitwise_xor">2.5.5. BITWISE_XOR</a></li>
<li><a href="#_intdiv">2.5.6. INTDIV</a></li>
<li><a href="#_logical_and">2.5.7. LOGICAL_AND</a></li>
<li><a href="#_logical_left_shift">2.5.8. LOGICAL_LEFT_SHIFT</a></li>
<li><a href="#_logical_right_shift">2.5.9. LOGICAL_RIGHT_SHIFT</a></li>
<li><a href="#_logical_or">2.5.10. LOGICAL_OR</a></li>
<li><a href="#_logical_xor">2.5.11. LOGICAL_XOR</a></li>
<li><a href="#_maximum">2.5.12. MAXIMUM</a></li>
<li><a href="#_minimum">2.5.13. MINIMUM</a></li>
<li><a href="#_mul">2.5.14. MUL</a></li>
<li><a href="#_pow">2.5.15. POW</a></li>
<li><a href="#_sub">2.5.16. SUB</a></li>
<li><a href="#_table">2.5.17. TABLE</a></li>
</ul>
</li>
<li><a href="#_elementwise_unary_operators">2.6. Elementwise Unary Operators</a>
<ul class="sectlevel3">
<li><a href="#_abs">2.6.1. ABS</a></li>
<li><a href="#_bitwise_not">2.6.2. BITWISE_NOT</a></li>
<li><a href="#_ceil">2.6.3. CEIL</a></li>
<li><a href="#_clz">2.6.4. CLZ</a></li>
<li><a href="#_cos">2.6.5. COS</a></li>
<li><a href="#_exp">2.6.6. EXP</a></li>
<li><a href="#_floor">2.6.7. FLOOR</a></li>
<li><a href="#_log">2.6.8. LOG</a></li>
<li><a href="#_logical_not">2.6.9. LOGICAL_NOT</a></li>
<li><a href="#_negate">2.6.10. NEGATE</a></li>
<li><a href="#_reciprocal">2.6.11. RECIPROCAL</a></li>
<li><a href="#_rsqrt">2.6.12. RSQRT</a></li>
<li><a href="#_sin">2.6.13. SIN</a></li>
</ul>
</li>
<li><a href="#_elementwise_ternary_operators">2.7. Elementwise Ternary Operators</a>
<ul class="sectlevel3">
<li><a href="#_select">2.7.1. SELECT</a></li>
</ul>
</li>
<li><a href="#_comparison_operators">2.8. Comparison Operators</a>
<ul class="sectlevel3">
<li><a href="#_equal">2.8.1. EQUAL</a></li>
<li><a href="#_greater">2.8.2. GREATER</a></li>
<li><a href="#_greater_equal">2.8.3. GREATER_EQUAL</a></li>
</ul>
</li>
<li><a href="#_reduction_operators">2.9. Reduction Operators</a>
<ul class="sectlevel3">
<li><a href="#_reduce_all">2.9.1. REDUCE_ALL</a></li>
<li><a href="#_reduce_any">2.9.2. REDUCE_ANY</a></li>
<li><a href="#_reduce_max">2.9.3. REDUCE_MAX</a></li>
<li><a href="#_reduce_min">2.9.4. REDUCE_MIN</a></li>
<li><a href="#_reduce_product">2.9.5. REDUCE_PRODUCT</a></li>
<li><a href="#_reduce_sum">2.9.6. REDUCE_SUM</a></li>
</ul>
</li>
<li><a href="#_data_layout">2.10. Data Layout</a>
<ul class="sectlevel3">
<li><a href="#_concat">2.10.1. CONCAT</a></li>
<li><a href="#_pad">2.10.2. PAD</a></li>
<li><a href="#_reshape">2.10.3. RESHAPE</a></li>
<li><a href="#_reverse">2.10.4. REVERSE</a></li>
<li><a href="#_slice">2.10.5. SLICE</a></li>
<li><a href="#_tile">2.10.6. TILE</a></li>
<li><a href="#_transpose">2.10.7. TRANSPOSE</a></li>
</ul>
</li>
<li><a href="#_scattergather_operators">2.11. Scatter/Gather Operators</a>
<ul class="sectlevel3">
<li><a href="#_gather">2.11.1. GATHER</a></li>
<li><a href="#_scatter">2.11.2. SCATTER</a></li>
</ul>
</li>
<li><a href="#_image_operators">2.12. Image Operators</a>
<ul class="sectlevel3">
<li><a href="#_resize">2.12.1. RESIZE</a></li>
</ul>
</li>
<li><a href="#_type_conversion">2.13. Type Conversion</a>
<ul class="sectlevel3">
<li><a href="#_cast">2.13.1. CAST</a></li>
<li><a href="#_rescale">2.13.2. RESCALE</a></li>
</ul>
</li>
<li><a href="#_data_nodes">2.14. Data Nodes</a>
<ul class="sectlevel3">
<li><a href="#_const">2.14.1. CONST</a></li>
<li><a href="#_identity">2.14.2. IDENTITY</a></li>
</ul>
</li>
<li><a href="#_custom_operators">2.15. Custom Operators</a>
<ul class="sectlevel3">
<li><a href="#_custom">2.15.1. CUSTOM</a></li>
</ul>
</li>
<li><a href="#_control_flow_operators">2.16. Control Flow Operators</a>
<ul class="sectlevel3">
<li><a href="#_cond_if">2.16.1. COND_IF</a></li>
<li><a href="#_while_loop">2.16.2. WHILE_LOOP</a></li>
</ul>
</li>
<li><a href="#_variable_operators">2.17. Variable Operators</a>
<ul class="sectlevel3">
<li><a href="#_variable">2.17.1. VARIABLE</a></li>
<li><a href="#_variable_write">2.17.2. VARIABLE_WRITE</a></li>
<li><a href="#_variable_read">2.17.3. VARIABLE_READ</a></li>
</ul>
</li>
<li><a href="#_shape_operators">2.18. Shape Operators</a>
<ul class="sectlevel3">
<li><a href="#_const_shape">2.18.1. CONST_SHAPE</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_enumerations">3. Enumerations</a>
<ul class="sectlevel2">
<li><a href="#_resize_mode_t">3.1. resize_mode_t</a></li>
<li><a href="#_acc_type_t">3.2. acc_type_t</a></li>
<li><a href="#_var_t">3.3. var_t</a></li>
<li><a href="#_nan_propagation_mode_t">3.4. nan_propagation_mode_t</a></li>
<li><a href="#_rounding_mode_t">3.5. rounding_mode_t</a></li>
</ul>
</li>
<li><a href="#_tosa_pseudocode">4. TOSA Pseudocode</a>
<ul class="sectlevel2">
<li><a href="#_for_each">4.1. for_each</a></li>
<li><a href="#_for_each_data_position">4.2. for_each_data_position</a></li>
<li><a href="#_operator_validation_helpers">4.3. Operator Validation Helpers</a></li>
<li><a href="#_tensor_access_helpers">4.4. Tensor Access Helpers</a>
<ul class="sectlevel3">
<li><a href="#_tensor_utilities">4.4.1. Tensor Utilities</a></li>
<li><a href="#_tensor_read">4.4.2. Tensor Read</a></li>
<li><a href="#_tensor_write">4.4.3. Tensor Write</a></li>
<li><a href="#_variable_tensor_allocate">4.4.4. Variable Tensor Allocate</a></li>
<li><a href="#_variable_tensor_lookup">4.4.5. Variable Tensor Lookup</a></li>
<li><a href="#_broadcast_helpers">4.4.6. Broadcast Helpers</a></li>
</ul>
</li>
<li><a href="#_general_pseudocode_helpers">4.5. General Pseudocode Helpers</a>
<ul class="sectlevel3">
<li><a href="#_arithmetic_helpers">4.5.1. Arithmetic Helpers</a></li>
<li><a href="#_type_conversion_helpers">4.5.2. Type Conversion Helpers</a></li>
<li><a href="#_numeric_accuracy_helpers">4.5.3. Numeric Accuracy Helpers</a></li>
<li><a href="#_numeric_conversion_helpers">4.5.4. Numeric Conversion Helpers</a></li>
<li><a href="#_scaling_helpers">4.5.5. Scaling Helpers</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_appendix_a">5. Appendix A</a>
<ul class="sectlevel2">
<li><a href="#_random_data_generation">5.1. Random Data Generation</a></li>
<li><a href="#_floating_point_test_data_generator">5.2. Floating-Point Test Data Generator</a>
<ul class="sectlevel3">
<li><a href="#_test_set_s0_generator">5.2.1. Test Set S=0 Generator</a></li>
<li><a href="#_test_set_s1">5.2.2. Test Set S=1</a></li>
<li><a href="#_test_set_s2">5.2.3. Test Set S=2</a></li>
<li><a href="#_test_set_s3">5.2.4. Test Set S=3</a></li>
<li><a href="#_test_set_s4">5.2.5. Test Set S=4</a></li>
<li><a href="#_test_set_s5">5.2.6. Test Set S=5</a></li>
</ul>
</li>
<li><a href="#_floating_point_operator_test_data">5.3. Floating-Point Operator Test Data</a>
<ul class="sectlevel3">
<li><a href="#_conv2d_2">5.3.1. CONV2D</a></li>
<li><a href="#_conv3d_2">5.3.2. CONV3D</a></li>
<li><a href="#_depthwise_conv2d_2">5.3.3. DEPTHWISE_CONV2D</a></li>
<li><a href="#_matmul_2">5.3.4. MATMUL</a></li>
<li><a href="#_transpose_conv2d_2">5.3.5. TRANSPOSE_CONV2D</a></li>
<li><a href="#_fft2d_2">5.3.6. FFT2D</a></li>
<li><a href="#_rfft2d_2">5.3.7. RFFT2D</a></li>
<li><a href="#_reduce_sum_2">5.3.8. REDUCE_SUM</a></li>
<li><a href="#_avg_pool2d_2">5.3.9. AVG_POOL2D</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_appendix_b_profile_operator_tables">6. Appendix B - Profile operator tables</a>
<ul class="sectlevel2">
<li><a href="#_profiles_2">6.1. Profiles</a>
<ul class="sectlevel3">
<li><a href="#_integer">6.1.1. Integer</a></li>
<li><a href="#_floating_point">6.1.2. Floating-Point</a></li>
</ul>
</li>
<li><a href="#_profile_extensions">6.2. Profile Extensions</a>
<ul class="sectlevel3">
<li><a href="#_ext_int16_extension">6.2.1. EXT-INT16 extension</a></li>
<li><a href="#_ext_int4_extension">6.2.2. EXT-INT4 extension</a></li>
<li><a href="#_ext_bf16_extension">6.2.3. EXT-BF16 extension</a></li>
<li><a href="#_ext_fp8e4m3_extension">6.2.4. EXT-FP8E4M3 extension</a></li>
<li><a href="#_ext_fp8e5m2_extension">6.2.5. EXT-FP8E5M2 extension</a></li>
<li><a href="#_ext_fft_extension">6.2.6. EXT-FFT extension</a></li>
<li><a href="#_ext_variable_extension">6.2.7. EXT-VARIABLE extension</a></li>
<li><a href="#_ext_controlflow_extension">6.2.8. EXT-CONTROLFLOW extension</a></li>
<li><a href="#_ext_dynamic_extension">6.2.9. EXT-DYNAMIC extension</a></li>
<li><a href="#_ext_doubleround_extension">6.2.10. EXT-DOUBLEROUND extension</a></li>
<li><a href="#_ext_inexactround_extension">6.2.11. EXT-INEXACTROUND extension</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_appendix_c_rationale">7. Appendix C - Rationale</a>
<ul class="sectlevel2">
<li><a href="#_fp8">7.1. FP8</a></li>
<li><a href="#_transcendental_functions">7.2. Transcendental Functions</a></li>
<li><a href="#_removed_operators">7.3. Removed Operators</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="content">
<div id="preamble">
<div class="sectionbody">
<div style="page-break-after: always;"></div>
<div class="paragraph">
<p><strong>TOSA Specification License ("License")</strong></p>
</div>
<div class="paragraph">
<p>This Licence is a legal agreement between you and Arm Limited (“Arm”) for the use of Arm’s intellectual property (including, without limitation, any copyright) embodied in the relevant TOSA Specification accompanying this Licence (“Specification”). Arm licenses its intellectual property in the Specification to you on condition that you agree to the terms of this Licence. By using or copying the Specification you indicate that you agree to be bound by the terms of this Licence.</p>
</div>
<div class="paragraph">
<p>“Subsidiary” means any company the majority of whose voting shares is now or hereafter owner or controlled, directly or indirectly, by you. A company shall be a Subsidiary only for the period during which such control exists.</p>
</div>
<div class="paragraph">
<p>This Specification is NON-CONFIDENTIAL and any use by you and your Subsidiaries (“Licensee”) is subject to the terms of this Licence between you and Arm and nothing in this License shall restrict you from further disseminating this Specification. You shall provide a copy of this License upon disseminating the Arm Specification to a third party.</p>
</div>
<div class="paragraph">
<p>Subject to the terms and conditions of this Licence, Arm hereby grants to Licensee under the intellectual property in the Specification owned or controlled by Arm, a perpetual, a non-exclusive, non-transferable, non-sub-licensable, royalty-free, worldwide licence to:</p>
</div>
<div class="olist lowerroman">
<ol class="lowerroman" type="i">
<li>
<p>use and copy the Specification solely for the purpose of designing and having designed products that fully complies with the Specification;</p>
</li>
<li>
<p>manufacture and have manufactured products which have been created under the licence granted in (i) above; and</p>
</li>
<li>
<p>sell, supply and distribute products which have been created under the licence granted in (i) above.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Licensee hereby agrees that the licenses granted above are conditional on implementing the Specification in products in its entirety and shall not extend to any portion or function of a product that is not itself fully compliant with the Specification.</p>
</div>
<div class="paragraph">
<p>Except as expressly licensed above, Licensee acquires no right, title or interest in any Arm technology or any intellectual property embodied therein.</p>
</div>
<div class="paragraph">
<p>Your access to the information in the Specification is conditional upon your acceptance that you will not use or permit others to use the information for the purposes of determining whether implementations infringe any third party patents.</p>
</div>
<div class="paragraph">
<p>THE SPECIFICATION IS PROVIDED “AS IS”. ARM PROVIDES NO REPRESENTATIONS AND NO WARRANTIES, EXPRESS, IMPLIED OR STATUTORY, INCLUDING, WITHOUT LIMITATION, THE IMPLIED WARRANTIES OF MERCHANTABILITY, SATISFACTORY QUALITY, NON-INFRINGEMENT OR FITNESS FOR A PARTICULAR PURPOSE WITH RESPECT TO THE SPECIFICATION. Arm may make changes to the Specification at any time and without notice. For the avoidance of doubt, Arm makes no representation with respect to, and has undertaken no analysis to identify or understand the scope and content of, third party patents, copyrights, trade secrets, or other rights.</p>
</div>
<div class="paragraph">
<p>NOTWITHSTANDING ANYTHING TO THE CONTRARY CONTAINED IN THIS LICENCE, TO THE FULLEST EXTENT PERMITTED BY LAW, IN NO EVENT WILL ARM BE LIABLE FOR ANY DAMAGES, IN CONTRACT, TORT OR OTHERWISE, IN CONNECTION WITH THE SUBJECT MATTER OF THIS LICENCE (INCLUDING WITHOUT LIMITATION: (I) LICENSEE’S USE OF THE SPECIFICATION; AND (II) THE IMPLEMENTATION OF THE SPECIFICATION IN ANY PRODUCT CREATED BY LICENSEE UNDER THIS LICENCE). THE EXISTENCE OF MORE THAN ONE CLAIM OR SUIT WILL NOT ENLARGE OR EXTEND THE LIMIT. LICENSEE RELEASES ARM FROM ALL OBLIGATIONS, LIABILITY, CLAIMS OR DEMANDS IN EXCESS OF THIS LIMITATION.</p>
</div>
<div class="paragraph">
<p>This Licence shall remain in force until terminated by Licensee or by Arm. Without prejudice to any of its other rights, if Licensee is in breach of any of the terms and conditions of this Licence then Arm may terminate this Licence immediately upon giving written notice to Licensee. Licensee may terminate this Licence at any time. Upon termination of this Licence by Licensee or by Arm, Licensee shall stop using the Specification and destroy all copies of the Specification in its possession. Upon termination of this Licence, all terms shall survive except for the licence grants.</p>
</div>
<div class="paragraph">
<p>Any breach of this Licence by a Subsidiary shall entitle Arm to terminate this Licence as if you were the party in breach. Any termination of this Licence shall be effective in respect of all Subsidiaries. Any rights granted to any Subsidiary hereunder shall automatically terminate upon such Subsidiary ceasing to be a Subsidiary.</p>
</div>
<div class="paragraph">
<p>The Specification consists solely of commercial items. Licensee shall be responsible for ensuring that any use, duplication or disclosure of the Specification complies fully with any relevant export laws and regulations to assure that the Specification or any portion thereof is not exported, directly or indirectly, in violation of such export laws.</p>
</div>
<div class="paragraph">
<p>This Licence may be translated into other languages for convenience, and Licensee agrees that if there is any conflict between the English version of this Licence and any translation, the terms of the English version of this Licence shall prevail.</p>
</div>
<div class="paragraph">
<p>The Arm corporate logo and words marked with ® or ™ are registered trademarks or trademarks of Arm Limited (or its subsidiaries) in the US and/or elsewhere. All rights reserved.  Other brands and names mentioned in this Specification may be the trademarks of their respective owners. No licence, express, implied or otherwise, is granted to Licensee under this Licence, to use the Arm trade marks in connection with the Specification or any products based thereon. Visit Arm’s website at <a href="https://www.arm.com/company/policies/trademarks" class="bare">https://www.arm.com/company/policies/trademarks</a> for more information about Arm’s trademarks.</p>
</div>
<div class="paragraph">
<p>The validity, construction and performance of this Licence shall be governed by English Law.</p>
</div>
<div class="paragraph">
<p>Copyright © 2020-2025 Arm Limited (or its affiliates). All rights reserved.</p>
</div>
<div class="paragraph">
<p>Arm Limited. Company 02557590 registered in England.
110 Fulbourn Road, Cambridge, England CB1 9NJ.</p>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
<div class="sect1">
<h2 id="_introduction">1. Introduction</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_overview">1.1. Overview</h3>
<div class="paragraph">
<p>Tensor Operator Set Architecture (TOSA) provides a set of whole-tensor
operations commonly employed by Deep Neural Networks. The intent is to enable a
variety of implementations running on a diverse range of processors, with the
results at the TOSA level consistent across those implementations. Applications
or frameworks which target TOSA can therefore be deployed on a wide range of
different processors, such as SIMD CPUs, GPUs and custom hardware such as
NPUs/TPUs, with defined accuracy and compatibility constraints. Most operators
from the common ML frameworks (TensorFlow, PyTorch, etc.) should be expressible
in TOSA. It is expected that there will be tools to lower from ML frameworks
into TOSA.</p>
</div>
</div>
<div class="sect2">
<h3 id="_goals">1.2. Goals</h3>
<div class="paragraph">
<p>The goals of TOSA include the following:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>A minimal and stable set of tensor-level operators to which machine learning
framework operators can be reduced.</p>
</li>
<li>
<p>Full support for both quantized integer and floating-point content.</p>
</li>
<li>
<p>Precise functional description of the behavior of every operator, including their numerical behavior in the case of precision, saturation, scaling, and range as required by quantized datatypes.</p>
</li>
<li>
<p>Independent of any single high-level framework, compiler backend stack or
particular implementation.</p>
</li>
<li>
<p>The detailed functional and numerical description enables precise code
construction for a diverse range of targets – SIMD CPUs, GPUs and custom
hardware such as NPUs/TPUs.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_specification">1.3. Specification</h3>
<div class="paragraph">
<p>The TOSA Specification is written as a combination of XML, AsciiDoc mark-up, and pseudocode files.
The content is managed through a git repository here: <a href="https://git.mlplatform.org/tosa/specification.git/" class="bare">https://git.mlplatform.org/tosa/specification.git/</a>.
The specification is developed and versioned much like software.
The pseudocode (.tosac files) is written in a style similar to C++, however it is not guaranteed to be valid or compile as it exists.
While the AsciiDoc content is legible and can be read fairly easily in its raw form, it is recommended to build or “render” the mark-up into PDF or HTML.
The build process will also create the tables in the specification from the XML.
To do this, please follow the instructions in the README.md in the root of the specification repository.</p>
</div>
</div>
<div class="sect2">
<h3 id="_operator_selection_principles">1.4. Operator Selection Principles</h3>
<div class="paragraph">
<p>TOSA defines a set of primitive operators to which higher level operators can be lowered in a consistent way.
To remain effective and efficient to implement, the set of operators must be constrained to a reasonably small set of primitive operations out of which others can be constructed.
The following principles govern the selection of operators within TOSA.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 1. Principles</caption>
<colgroup>
<col style="width: 9.0909%;">
<col style="width: 45.4545%;">
<col style="width: 45.4546%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">ID</th>
<th class="tableblock halign-left valign-top">Principle</th>
<th class="tableblock halign-left valign-top">Reason for this</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">P0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">An operator shall be a primitive operation or building block that cannot be decomposed into simpler whole tensor operations.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">If the operator can be broken down, then we should look at the component operators.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">P1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">An operator shall be usable as a component out of which more than one type of complex operation can be constructed.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Single use operators have a high architectural cost and a more reusable version should be considered instead.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">P2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Precision should be appropriate for the input and output data types.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Precision higher than that needed to calculate the result leads to extra implementation complexity.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">P3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Numerical definition of common sub-operations should be consistent between operators (for example: value scaling).</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Consistent sub-operation definition reduces the operator implementation complexity.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">P4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The valid input and output ranges for all arguments shall be specified.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Ranges are required to make consistent (numerically agreeing) implementations possible.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">P5</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Integer operators shall be implementable in a bit-exact form with good efficiency on CPU, GPU and hardware targets.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Reduces implementation cost and gives consistent inference results.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="_versioning">1.5. Versioning</h3>
<div class="paragraph">
<p>TOSA follows a semantic versioning policy with a major.minor.patch.draft scheme.
See below for the TOSA definition of backward compatibility.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Major version changes may break backwards compatibility.</p>
</li>
<li>
<p>Minor numbers may add functionality in a backwards compatible way.</p>
</li>
<li>
<p>Patch versions are for bug fixes, clarifications, or trivial changes.</p>
</li>
<li>
<p>The draft flag notes whether the version referenced is finalized.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Major, minor, and patch numbers are limited to eight bits.
Draft is a single bit flag.
If stored in a 32-bit value, the remaining bits are reserved for future use.</p>
</div>
<div class="sect3">
<h4 id="_backwards_compatibility">1.5.1. Backwards Compatibility</h4>
<div class="paragraph">
<p>TOSA graphs created with previous minor versions within a major version must continue to work.</p>
</div>
<div class="paragraph">
<p>The following portions of the specification and implementation will not change within a major version:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Operator Names</p>
</li>
<li>
<p>Arguments including ordering, input/attribute/output, name, rank</p>
</li>
<li>
<p>ERROR_IF statements</p>
</li>
<li>
<p>Functionality of the pseudocode for each operator</p>
</li>
<li>
<p>Level definitions and checks</p>
</li>
<li>
<p>Removal of rows in the Supported Data Type tables</p>
</li>
<li>
<p>Enumerated types and values</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Changes to the following do not break compatibility:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Machine readable specification format (currently XML)</p>
</li>
<li>
<p>Machine readable specification schema</p>
</li>
<li>
<p>Order of operation definitions within the XML specification</p>
</li>
<li>
<p>Operator section names</p>
</li>
<li>
<p>Descriptive text that does not affect functionality</p>
</li>
<li>
<p>Non-functional changes to pseudocode (for example: cleanup, variable name changes)</p>
</li>
<li>
<p>Additions of new rows to the Supported Data Type tables</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Minor versions are allowed to add new operators or other functionality as long as the above guarantees hold.</p>
</div>
<div class="paragraph">
<p>In this version of TOSA, the precision requirements are subject to change while additional implementations are tested.
When multiple implementations are shown to meet the precision requirements, those requirements will be guaranteed not to change within a major version.</p>
</div>
<div class="paragraph">
<p>In addition, new extensions may be added to the specification between TOSA releases.
They may not change anything that would break backward compatibility according to the above definitions.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_profiles">1.6. Profiles</h3>
<div class="paragraph">
<p>TOSA profiles enable efficient implementation on different classes of device.
Each profile is an independent set of operations and data type combinations.</p>
</div>
<div class="paragraph">
<p>TOSA profile extensions define optional operation and data type combinations.</p>
</div>
<div class="paragraph">
<p>Each operator&#8217;s Supported Data Types table defines which profile or extension includes that operator with different data types.
An operator / data type combination may be part of multiple profiles or extensions.
If so, each profile and extension will be listed in the Supported Data Types table.
In addition, a table listing all operations for each profile can be found in Appendix B.</p>
</div>
<div class="paragraph">
<p>The following are required for compliant TOSA implementations:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>A TOSA implementation must implement at least one profile.</p>
</li>
<li>
<p>A TOSA implementation may choose to implement any extensions.</p>
</li>
<li>
<p>If a TOSA implementation chooses to implement an extension, it must implement the complete extension.</p>
</li>
<li>
<p>If an operator / data type combination requires multiple extensions, the combination is only required to be implemented if all extensions are implemented</p>
<div class="ulist">
<ul>
<li>
<p>For example, a CAST from bf16 to fp8 is only required if both extensions are implemented.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 2. Profiles</caption>
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Description</th>
<th class="tableblock halign-left valign-top">Specification Status</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Integer</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Integer operations, primarily 8- and 32-bit values</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Complete</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Floating-Point</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">FP16 and FP32 operations</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Complete</p></td>
</tr>
</tbody>
</table>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 3. Profile Extensions</caption>
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Description</th>
<th class="tableblock halign-left valign-top">Allowed profiles</th>
<th class="tableblock halign-left valign-top">Specification Status</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-INT16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">16-bit integer operations</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Complete</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-INT4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">4-bit integer weights</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Complete</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">BFloat16 operations</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Experimental</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E4M3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">8-bit floating-point operations E4M3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Experimental</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E5M2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">8-bit floating-point operations E5M2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Experimental</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FFT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Fast Fourier Transform operations</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Complete</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-VARIABLE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Stateful variable operations</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT,PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Experimental</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-CONTROLFLOW</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Control Flow operations</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT,PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Experimental</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-DYNAMIC</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Removes all Compile Time Constant state for CTC inputs</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT,PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Experimental</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-DOUBLEROUND</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Adds double rounding support to the RESCALE operator</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Complete</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-INEXACTROUND</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Adds inexact rounding support to the RESCALE operator</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Experimental</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="_levels">1.7. Levels</h3>
<div class="paragraph">
<p>A TOSA level defines operator argument ranges that an implementation shall support.
This is distinct from a profile that defines the operations and data-types supported.
One level must apply to all profiles and extensions supported by an implementation.</p>
</div>
<div class="paragraph">
<p>This version of the specification defines two TOSA levels:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>No level : allows the full range of arguments specified by the operations according to the operation data types.</p>
</li>
<li>
<p>Level 8K : ranges are expected to be sufficient for applications with frame sizes up to 8K.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Later versions of the specification may define additional levels.
The following table defines the value ranges for each level.
These ranges are checked using the LEVEL_CHECK() function with the operator descriptions.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 4. Level maxima</caption>
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tosa_level_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">tosa_level_none</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">tosa_level_8K</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Description</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">No level</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Level 8K</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">6</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MAX_KERNEL</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2147483647</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">8192</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MAX_STRIDE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2147483647</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">8192</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MAX_SCALE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2048</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">256</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MAX_LOG2_SIZE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">63</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">31</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MAX_NESTING</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">256</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">6</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MAX_TENSOR_LIST_SIZE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">256</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">64</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="_status">1.8. Status</h3>
<div class="paragraph">
<p>This specification is the release candidate for TOSA 1.0.</p>
</div>
<div class="paragraph">
<p>The specific status of each profile and extension is contained in the tables in <a href="#_profiles">Profiles</a>.
Possible values for status are:</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 80%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Status</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Complete</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">All operators are specified, conformance tests are provided, no changes are expected. Backward compatibility is guaranteed.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Experimental</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Operators are subject to change, backwards compatibility is not guaranteed for experimental extensions.<br>
If an implementation implements an experimental extension, it must pass the conformance tests for that extension.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Deprecated</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Operators retained for compatibility, but may be removed in a future major release of TOSA.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="_supported_number_formats">1.9. Supported Number Formats</h3>
<div class="paragraph">
<p>The following number formats are defined in TOSA.
The number formats supported by a given operator are listed in its table of supported types.
A TOSA implementation must support the number formats listed in the supported data types for operators contained in that profile.
Number formats not required for any operators in a profile do not need to be implemented.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 5. Number formats</caption>
<colgroup>
<col style="width: 12.5%;">
<col style="width: 12.5%;">
<col style="width: 12.5%;">
<col style="width: 62.5%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Format</th>
<th class="tableblock halign-left valign-top">Minimum</th>
<th class="tableblock halign-left valign-top">Maximum</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean value that is either <code>true</code> or <code>false</code>. Size is implementation defined. The TOSA reference model implements this as int8_t with 0 for <code>false</code> and 1 for <code>true</code>. All non-zero values are accepted on input as <code>true</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">i4_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Signless 4-bit integer type. Will be interpreted as int4_t by all operators</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">int4_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-7</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+7</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Signed 4-bit two&#8217;s-complement value. Excludes -8 to maintain a symmetric about zero range for weights.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Signless 8-bit integer value. Will be interpreted as int8_t unless otherwise specified by an operator.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-128</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+127</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Signed 8-bit two&#8217;s-complement value.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">uint8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">255</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Unsigned 8-bit integer value.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Signless 16-bit integer type. Will be interpreted as int16_t unless otherwise specified by an operator.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-32768</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+32767</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Signed 16-bit two&#8217;s-complement value.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">uint16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">65535</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Unsigned 16-bit value.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Signless 32-bit integer value. Will be interpreted as int32_t by all operators.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-(1&lt;&lt;31)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">(1&lt;&lt;31)-1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Signed 32-bit two&#8217;s-complement value.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">i48_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Signless 48-bit integer value. Will be interpreted as int48_t by all operators.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">int48_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-(1&lt;&lt;47)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">(1&lt;&lt;47)-1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Signed 48-bit two&#8217;s-complement value.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-448</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">448</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">8-bit floating-point defined by <a href="#OCP-OFP8">OCP-OFP8</a> with four bits of exponent and three bits of mantissa.<br>
Normal values must be supported.<br>
Subnormal values must be supported.<br>
NaN encodings must be supported.<br>
Signed zero must be supported.<br>
This format has no encoding for infinities.<br>
The range is extended by using a mantissa-exponent bit pattern to encode NaN instead of sacrificing an exponent value.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">8-bit floating-point defined by <a href="#OCP-OFP8">OCP-OFP8</a> with five bits of exponent and two bits of mantissa.<br>
Normal values must be supported.<br>
Subnormal values must be supported.<br>
Positive and negative infinity must be supported.<br>
NaN encodings must be supported.<br>
Signed zero must be supported.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">16-bit half-precision floating-point defined by <a href="#IEEE-754">IEEE-754</a>.<br>
Normal values must be supported.<br>
Subnormal values must either be supported or flushed to sign-preserved zero.<br>
Positive and negative infinity must be supported.<br>
At least one NaN encoding must be supported.<br>
Signed zero must be supported.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">16-bit brain floating-point defined as bits [31:16] of the fp32_t format.<br>
Normal values must be supported.<br>
Subnormal values must either be supported or flushed to sign-preserved zero.<br>
Positive and negative infinity must be supported.<br>
At least one NaN encoding must be supported.<br>
Signed zero must be supported.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">32-bit single-precision floating-point defined by <a href="#IEEE-754">IEEE-754</a>.<br>
Normal values must be supported.<br>
Subnormal values must either be supported or flushed to sign-preserved zero.<br>
Positive and negative infinity must be supported.<br>
At least one NaN encoding must be supported.<br>
Signed zero must be supported.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp64_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+ infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">64-bit double-precision floating-point defined by <a href="#IEEE-754">IEEE-754</a>.<br>
Normal values must be supported.<br>
Subnormal values must either be supported or flushed to sign-preserved zero.<br>
Positive and negative infinity must be supported.<br>
At least one NaN encoding must be supported.<br>
Signed zero must be supported.</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>Note: In this specification, minimum&lt;type&gt; and maximum&lt;type&gt; will denote the minimum and maximum values of the data as stored in memory (ignoring the zero point).
The minimum and maximum values for each type are given in the preceding table.</p>
</div>
<div class="paragraph">
<p>Note: Integer number formats smaller than 8 bits may be used provided that the numerical result is the same as using a sequence of 8-bit TOSA operations.
For example, the result of a convolution with low precision data must equal that of running the convolution at 8 bits and then clipping the result to the permitted output range.
This ensures that an Integer profile TOSA implementation can calculate the same result.</p>
</div>
</div>
<div class="sect2">
<h3 id="_compliance">1.10. Compliance</h3>
<div class="paragraph">
<p>This section defines when a TOSA implementation is compliant to a given TOSA specification profile and level.
To be compliant an implementation must achieve the results and accuracy defined by this specification.
TOSA also defines a set of conformance tests.
A compliant implementation must pass the conformance tests.
The conformance tests are not exhaustive, so an implementation that passes the conformance tests may not be compliant if there is a non-compliance that is undetected by the tests.</p>
</div>
<div class="sect3">
<h4 id="_tosa_graph_compliance">1.10.1. TOSA Graph Compliance</h4>
<div class="paragraph">
<p>The <a href="#operator-graphs">Operator Graphs</a> section of this specification defines a TOSA graph and the behavior defined for a TOSA graph.
This behavior is captured in the pseudocode function tosa_execute_graph().
For a given input graph (with attributes) and input tensors there are three possible tosa_graph_result values after executing the graph:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>tosa_unpredictable: The result of the graph on the given inputs cannot be relied upon.</p>
</li>
<li>
<p>tosa_error: The graph does not meet the specification and is recognised as an illegal graph.</p>
</li>
<li>
<p>tosa_valid: The result is defined and predictable and the list of output tensors defines the result.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>An implementation must behave as follows given the above tosa_graph result values:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>For tosa_unpredictable, the implementation can return whatever result it chooses (including error)</p>
</li>
<li>
<p>For tosa_error, the implementation must return an error result (and there is no requirement on how much of the graph is executed, if any).</p>
</li>
<li>
<p>For tosa_valid, the implementation must execute the entire graph without error and return the result defined by this specification.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>In terms of pseudocode, if <strong>graph</strong> is a TOSA graph consisting of TOSA operators and <strong>input_list</strong> is a list of input tensors then the following test must pass.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++"><span class="comment">// Global result status value</span>
<span class="comment">// Will be updated by REQUIRE and ERROR_IF statements when evaluating the TOSA graph</span>
tosa_result_t tosa_graph_result;
<span class="comment">// Tracks the nesting depth of TOSA operators to allow a limit on nesting depth to be checked.</span>
int32_t tosa_nesting_depth;

bool_t tosa_test_compliance(tosa_graph_t graph, tensor_list_t input_list, tosa_level_t level) {
    shape_list_t output_list_spec = tosa_allocate_list(tosa_output_shape(graph));
    shape_list_t output_list_test = tosa_allocate_list(tosa_output_shape(graph));
    tosa_graph_result = tosa_valid;    <span class="comment">// result starts as valid</span>
    tosa_nesting_depth = <span class="integer">0</span>;            <span class="comment">// if/while nesting level</span>
    tosa_execute_graph(graph, input_list, output_list_spec, level);
    <span class="keyword">if</span> (tosa_graph_result == tosa_unpredictable) {
        <span class="keyword">return</span> <span class="predefined-constant">true</span>;    <span class="comment">// No requirement to match an unpredictable result</span>
    }
    result_test = execute_implementation_under_test(graph, input_list, output_list_test);
    <span class="keyword">if</span> (tosa_graph_result == tosa_error) {
        <span class="keyword">return</span> result_test == tosa_error;   <span class="comment">// result must be an error</span>
    }
    <span class="keyword">if</span> (exact_tensor_match(output_list_spec, output_list_test)) {
       <span class="comment">// Predictable bit-exact value match required</span>
       <span class="keyword">return</span> <span class="predefined-constant">true</span>;
    }
    <span class="keyword">return</span> <span class="predefined-constant">false</span>;
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_integer_profile_compliance">1.10.2. Integer Profile Compliance</h4>
<div class="paragraph">
<p>An Integer profile compliant implementation must satisfy the following:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The implementation must support all operator and data type combinations listed in <a href="#_integer">Integer</a>.</p>
<div class="ulist">
<ul>
<li>
<p>The operations must meet the <a href="#_integer_precision_requirements">Integer Precision Requirements</a>.</p>
</li>
</ul>
</div>
</li>
<li>
<p>The implementation must follow the <a href="#_tosa_graph_compliance">TOSA Graph Compliance</a> behavior.</p>
</li>
</ul>
</div>
<div class="sect4">
<h5 id="_integer_precision_requirements">Integer Precision Requirements</h5>
<div class="paragraph">
<p>In a compliant implementation, individual integer operations within the graph must match exactly.</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_floating_point_profile_compliance">1.10.3. Floating-Point Profile Compliance</h4>
<div class="paragraph">
<p>A Floating-Point profile compliant implementation must satisfy the following:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The implementation must support all operator and data type combinations listed in <a href="#_floating_point">Floating-Point</a>.</p>
<div class="ulist">
<ul>
<li>
<p>The operations must meet the <a href="#_floating_point_precision_requirements">Floating-Point Precision Requirements</a>.</p>
</li>
<li>
<p>Note: These requirements allow fp16_t operations to be implemented using the fp32_t datatype.</p>
</li>
</ul>
</div>
</li>
<li>
<p>The implementation must follow the <a href="#_tosa_graph_compliance">TOSA Graph Compliance</a> behavior.</p>
</li>
</ul>
</div>
<div class="sect4">
<h5 id="_floating_point_precision_requirements">Floating-Point Precision Requirements</h5>
<div class="paragraph">
<p>When evaluating floating-point precision, <em>ulp</em> means unit of the last place.</p>
</div>
<div class="paragraph">
<p>In a compliant implementation, individual integer operations must match exactly.
To check exact matching, the tosa_reference_check_fp function can be used with num_ulp set to 0.
In a compliant implementation, individual floating-point operations within the graph must meet the accuracy bounds defined in each operator definition.</p>
</div>
<div class="paragraph">
<p>When the operator precision definitions refer to a result "calculated by fp64_t arithmetic", the following rules must be followed:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The operation order must follow that specified in the operator pseudocode.</p>
</li>
<li>
<p>Each fp64_t operation result must be round-to-nearest-even of the infinite precision result as defined by <a href="#IEEE-754">IEEE-754</a> round to nearest even rounding.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The function tosa_reference_check_fp() defines the error range permitted by a given number of units of last place in this specification.
For data types that allow subnormal values to be flushed to zero, either all values must be flushed to sign-preserved zero, or none of them.</p>
</div>
</div>
<div class="sect4">
<h5 id="_operator_sequence_precision_requirement">Operator sequence precision requirement</h5>
<div class="paragraph">
<p>Precision criteria are specified for a single operator.</p>
</div>
<div class="paragraph">
<p>An implementation M of a sequence of n TOSA operators, A[0] to A[n-1] is said to
be compliant if M gives the same result as a sequence of implementations
M[0] to M[n-1] such that:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Each M[k] implements A[k] with same or higher precision datatypes.</p>
</li>
<li>
<p>Each M[k] meets the accuracy defined in this specification for A[k] where the M[k] output is converted to A[k] output precision using round to nearest.</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="_dot_product_accuracy_requirements">Dot product accuracy requirements</h5>
<div class="paragraph">
<p>This section assumes an operation acting on tensors named 'input', 'weight' and optionally 'bias'.
Each output tensor element can be expressed as a dot product of elements between the 'input' and 'weight' tensors with optional bias addition.
The dot product has length KS, the kernel size.
If the operation does not specify a bias then 'bias' is taken to be zero in this section.
Note: KS is defined for each relevant operator in the appendix section <a href="#_floating_point_operator_test_data">Floating-Point Operator Test Data</a>.</p>
</div>
<div class="paragraph">
<p>In other words, each output element <code>out</code> can be expressed as a dot product between input elements <code>in[k]</code>, weight elements <code>w[k]</code>, bias <code>b</code>:</p>
</div>
<div class="paragraph">
<p><code>out = in[0] * w[0] + in[1] * w[1] + &#8230;&#8203; + in[KS-1] * w[KS-1] + b</code></p>
</div>
<div class="paragraph">
<p>The positions of <code>in[k]</code>, <code>w[k]</code>, <code>b</code> in the input, weight and bias tensors depends on the operation being performed.
This may be, for example, a convolution.</p>
</div>
<div class="paragraph">
<p>This section defines the accuracy required for these operations.
In this section:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>"fp64 arithmetic" refers to double-precision floating-point arithmetic defined by <a href="#IEEE-754">IEEE-754</a>.</p>
</li>
<li>
<p><code>reference_fp64()</code> is the result of the operation calculated using fp64_t arithmetic.</p>
</li>
<li>
<p><code>implementation()</code> is the implementation under test.</p>
</li>
<li>
<p><code>local_bound</code> is defined as follows:</p>
<div class="ulist">
<ul>
<li>
<p>For operations with a local_bound attribute it is the value of the optional attribute, with default value of false.</p>
</li>
<li>
<p>For operations that do not have a local_bound attribute the value is true.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>For the checks described in the following code:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Data sets defined for the operation in Appendix A <a href="#_floating_point_operator_test_data">Floating-Point Operator Test Data</a> must pass.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The following tables describe some of the constraints applied during the dot product conformance check.</p>
</div>
<div class="paragraph">
<p>ABS_BOUND is the maximum allowed absolute error when NaN or overflow is not present.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Condition</th>
<th class="tableblock halign-left valign-top">ABS_BOUND</th>
<th class="tableblock halign-left valign-top">Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">all cases</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2 * ksb</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Allow one rounding error for each accumulation. The 2 factor allows for different rounding modes.</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>VARIANCE_ERROR_BOUND is the maximum allowed variance across the entire output tensor.
The squared error for each result is summed, and the result must be less than the VARIANCE_ERROR_BOUND.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Condition</th>
<th class="tableblock halign-left valign-top">VARIANCE_ERROR_BOUND</th>
<th class="tableblock halign-left valign-top">Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">all cases</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>4 * 0.4 * ksb</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The 0.4 factor is derived from the uniform [-1,1] distribution variance of 1/3 by rounding up.<br>
The 4 factor is the square of the 2 factor in the absolute bound  to allow for different rounding modes.</p></td>
</tr>
</tbody>
</table>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">bool_t tosa_reference_check_dotproduct&lt;OP, in_t, weight_t, out_t, acc_t&gt;(
    i32_t S,             <span class="comment">// test set number</span>
    T&lt;in_t&gt; input,       <span class="comment">// input tensor</span>
    T&lt;weight_t&gt; weight,  <span class="comment">// weight tensor</span>
    T&lt;out_t&gt; bias        <span class="comment">// bias tensor</span>
) {
    T&lt;in_t&gt;     input_abs  = max(abs(input),  normal_min&lt;in_t&gt;()); <span class="comment">// Element-wise</span>
    T&lt;weight_t&gt; weight_abs = max(abs(weight), normal_min&lt;in_t&gt;()); <span class="comment">// Element-wise</span>
    T&lt;out_t&gt;    bias_abs   = max(abs(bias),   normal_min&lt;in_t&gt;()); <span class="comment">// Element-wise</span>
    <span class="keyword">if</span> (!local_bound) {
        in_t input_abs_max = max_value(input_abs);  <span class="comment">// maximum over all elements</span>
        for_each_data_position(index in shape(input_abs)) {
            input_abs[index] = input_abs_max;  <span class="comment">// set all entries to global maximum</span>
        }
    }
    <span class="comment">// reference_fp64(OP) calculates the results of operation OP using fp64_t arithmetic</span>
    <span class="comment">// implementation(OP) runs operation OP using the implementation under test</span>
    T&lt;out_t&gt;  output_imp = implementation(OP, input, weight, bias, tosa_extra_multiplies = IMPLEMENTATION_DEFINED);
    T&lt;fp64_t&gt; output_ref = reference_fp64(OP, input, weight, bias, tosa_extra_multiplies = <span class="predefined-constant">false</span>);
    T&lt;fp64_t&gt; output_bnd = reference_fp64(OP, input_abs, weight_abs, bias_abs, tosa_extra_multiplies = <span class="predefined-constant">true</span>);

    tensor_size_t T = tensor_size(output_shape);  <span class="comment">// number dot product results</span>
    tensor_size_t ksb = ceil(KS / pow(<span class="integer">2</span>, (normal_frac&lt;acc_t&gt;() - normal_frac&lt;out_t&gt;())/<span class="integer">2</span>)) + ((max_value(bias_abs) &gt; <span class="integer">0</span>) ? <span class="integer">1</span> : <span class="integer">0</span>);
    fp64_t out_err_sum = <span class="float">0</span><span class="float">.0</span>;
    fp64_t out_err_sumsq = <span class="float">0</span><span class="float">.0</span>;
    for_each_data_position(index in output_shape) {
        fp64_t out_bnd_el = tensor_read&lt;fp64_t&gt;(output_bnd, output_shape, index);
        fp64_t out_ref_el = tensor_read&lt;fp64_t&gt;(output_ref, output_shape, index);
        acc_t  out_imp_el = tensor_read&lt;acc_t&gt; (output_imp, output_shape, index);
        fp64_t out_err;

        <span class="keyword">if</span> (isNaN(out_ref_el)) {
            <span class="comment">// Reference is a NaN on non-padded data, the implementation must match</span>
            <span class="keyword">if</span> (!isNaN(out_imp_el)) {
                <span class="keyword">return</span> <span class="predefined-constant">false</span>;
            }
            out_err = <span class="float">0</span><span class="float">.0</span>;
        } <span class="keyword">else</span> <span class="keyword">if</span> (isNaN(out_bnd_el)) {
            <span class="comment">// No further accuracy requirements for a NaN bound</span>
            out_err = <span class="float">0</span><span class="float">.0</span>;
        } <span class="keyword">else</span> <span class="keyword">if</span>.(<span class="keyword">static_cast</span>&lt;out_t&gt;(out_bnd_el * (<span class="integer">1</span> + ABS_BOUND * exp2(-<span class="integer">1</span>-normal_frac&lt;out_t&gt;()))) == infinity) {
            <span class="comment">// dot product can overflow within error bound and there is no accuracy limit</span>
            out_err = <span class="float">0</span><span class="float">.0</span>;
        } <span class="keyword">else</span> <span class="keyword">if</span> (out_bnd_el == <span class="float">0</span><span class="float">.0</span>) {
            <span class="comment">// All products in the dot product are zero</span>
            <span class="keyword">if</span> (out_ref_el != <span class="float">0</span><span class="float">.0</span> || out_imp_el != <span class="float">0</span><span class="float">.0</span>) {
                <span class="keyword">return</span> <span class="predefined-constant">false</span>;
            }
            out_err = <span class="float">0</span><span class="float">.0</span>;
        } <span class="keyword">else</span> {  <span class="comment">// 0.0 &lt; out_bnd &lt; infinity</span>
            fp64_t out_err_bnd = max(out_bnd_el * exp2(-<span class="integer">1</span>-normal_frac&lt;out_t&gt;()), normal_min&lt;out_t&gt;());
            out_err = (<span class="keyword">static_cast</span>&lt;fp64_t&gt;(out_imp_el) - out_ref_el) / out_err_bnd;
            <span class="comment">// Check the absolute error. See the table for the definition of ABS_BOUND.</span>
            <span class="keyword">if</span> (abs(out_err) &gt; ABS_BOUND) {
                <span class="keyword">return</span> <span class="predefined-constant">false</span>;
            }
        }
        out_err_sum   += out_err;
        out_err_sumsq += out_err * out_err;
    }
    <span class="comment">// Only check this for input and weights for test data sets 3-5</span>
    <span class="keyword">if</span> ( S &gt;= <span class="integer">3</span> &amp;&amp; S &lt;= <span class="integer">5</span>) {
        <span class="comment">// check output error bias magnitude for data sets S which are not positive biased</span>
        <span class="comment">// The factor 10 allows for up to a 4 sigma difference of the error sum around the</span>
        <span class="comment">// expected error sum assuming errors are normally distributed.</span>
        <span class="keyword">if</span> (abs(out_err_sum) &gt; sqrt(<span class="integer">10</span> * VARIANCE_ERROR_BOUND * T)) {
            <span class="keyword">return</span> <span class="predefined-constant">false</span>;
        }
    }
    <span class="comment">// check output error variance magnitude</span>
    <span class="comment">// See the table for the definition of VARIANCE_ERROR_BOUND</span>
    <span class="keyword">if</span> (out_err_sumsq &gt; VARIANCE_ERROR_BOUND * T) {
        <span class="keyword">return</span> <span class="predefined-constant">false</span>;
    }
    <span class="keyword">return</span> <span class="predefined-constant">true</span>;
}</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_tensor_definitions">1.11. Tensor Definitions</h3>
<div class="sect3">
<h4 id="_tensors">1.11.1. Tensors</h4>
<div class="paragraph">
<p>Tensors are multidimensional arrays of data.
Tensors have metadata associated with them that describe characteristics of the tensor, including:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Data Type</p>
</li>
<li>
<p>Shape</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The number of dimensions in a shape is called the rank.
A tensor with rank equal to zero is permitted.
A tensor shape is an array of integers of size equal to the rank of the tensor.
Each element in the tensor shape describes the number of elements in the dimension.
The tensor shape in each dimension must be greater than or equal to 1.
For tensor access information, see <a href="#_tensor_access_helpers">Tensor Access Helpers</a>.</p>
</div>
<div class="paragraph">
<p>The shape of a tensor is a special type <code>shape_t</code>.
<code>shape_t</code> is a one-dimensional list with the size equal to the rank of the original tensor.
The components of a <code>shape_t</code> are of type <code>tensor_size_t</code>.
<code>tensor_size_t</code> is a signed integer as it may be used for negative offsets.
This type must be able to hold integers in the range [<code>-(1 &lt;&lt; MAX_LOG2_SIZE)</code> .. <code>(1 &lt;&lt; MAX_LOG2_SIZE) - 1</code>] where <code>MAX_LOG2_SIZE</code> is defined in <a href="#_levels">Levels</a>.
The <code>shape_t</code> for a zero-dimensional tensor is the empty list.</p>
</div>
<div class="paragraph">
<p>For each tensor, the number of tensor elements multiplied by the element size in
bytes (which is taken to be 1 for elements smaller than a 8-bit) must be
representable as a <code>tensor_size_t</code>.</p>
</div>
<div class="paragraph">
<p>In this version of the specification, <code>shape_t</code> values must be resolvable to
constants at backend compile time.</p>
</div>
</div>
<div class="sect3">
<h4 id="_data_layouts">1.11.2. Data Layouts</h4>
<div class="paragraph">
<p>The following data layouts are supported in TOSA.
TOSA operations are defined in terms of a linear packed tensor layout.
In a linear packed layout a rank r tensor has elements of dimension (r-1) consecutive.
The next to increment is dimension (r-2) and so on.
For a specification of this layout see the tensor read and write functions in section <a href="#_tensor_access_helpers">Tensor Access Helpers</a>.</p>
</div>
<div class="paragraph">
<p>An implementation of TOSA can choose a different tensor memory layout provided that the operation behavior is maintained.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 6. Data Layouts</caption>
<colgroup>
<col style="width: 11.1111%;">
<col style="width: 44.4444%;">
<col style="width: 44.4445%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Description of dimensions</th>
<th class="tableblock halign-left valign-top">Usage</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">NHWC</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch, Height, Width, Channels</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Feature maps</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">NDHWC</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch, Depth, Height, Width, Channels</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Feature maps for 3D convolution</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">OHWI</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output channels, Filter Height, Filter Width, Input channels</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">HWIM</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Filter Height, Filter Width, Input channels, Channel Multiplier</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Weights for depthwise convolutions</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">DOHWI</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Depth, Output Channels, Filter Height, Filter Width, Input Channels</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Weights for 3D convolution</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_broadcasting">1.11.3. Broadcasting</h4>
<div class="paragraph">
<p>In operations where broadcasting is supported, an input shape dimension can be broadcast to an output shape dimension if the input shape dimension is 1.
TOSA broadcast requires the rank of both tensors to be the same.
A RESHAPE can be done to create a compatible tensor with appropriate dimensions of size 1.
To map indexes in an output tensor to that of an input tensor, see <a href="#_broadcast_helpers">Broadcast Helpers</a>.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_integer_behavior">1.12. Integer Behavior</h3>
<div class="paragraph">
<p>TOSA integer inputs and outputs are specified by signless values with the given number of bits.
Unless otherwise specified, these values will be interpreted as signed two&#8217;s-complement.
The pseudocode will use int*_t to indicate use as a signed value and uint*_t to indicate use as an unsigned value.
If overflow occurs doing integer calculation, the result is unpredictable, as indicated by the REQUIRE checks in the pseudocode for the operators.</p>
</div>
<div class="paragraph">
<p>Unsigned 8- and 16-bit values are only allowed in the RESCALE operation, to allow for compatibility with networks which expect unsigned 8-bit or 16-bit tensors for input and output.</p>
</div>
<div class="sect3">
<h4 id="_quantization">1.12.1. Quantization</h4>
<div class="paragraph">
<p>Machine Learning frameworks may represent tensors with a quantized implementation, using integer values to represent the original floating-point numbers.
TOSA integer operations do not perform any implicit scaling to represent quantized values.
Required zero point values are passed to the operator as necessary, and will be processed according to the pseudocode for each operator.</p>
</div>
<div class="paragraph">
<p>To convert a network containing quantized tensors to TOSA, generate explicit RESCALE operators for any change of quantization scaling.
This reduces quantized operations to purely integer operations.</p>
</div>
<div class="paragraph">
<p>As an example, an ADD between two quantized tensors requires the integer values to belong to the same domain.
The scale arguments for RESCALE can be calculated to ensure that the resulting tensors belong to the same domain.
Then the ADD is performed, and a RESCALE can be used to ensure that the result is scaled properly.</p>
</div>
<div class="paragraph">
<p>RESCALE provides support for per-tensor and per-channel scaling values to ensure compatibility with a range of possible quantization implementations.</p>
</div>
</div>
<div class="sect3">
<h4 id="_precision_scaling">1.12.2. Precision Scaling</h4>
<div class="paragraph">
<p>TOSA uses the <a href="#_rescale">RESCALE</a> operation to scale between values with differing precision.</p>
</div>
</div>
<div class="sect3">
<h4 id="_integer_convolutions">1.12.3. Integer Convolutions</h4>
<div class="paragraph">
<p>For the convolution operators, the input is not required to be scaled.
The integer versions of the convolution operators will subtract the zero point from the integer values as defined for each operator.
The convolution produces an accumulator output of type int32_t or int48_t.
This accumulator output is then scaled to the final output range using the RESCALE operator.
The scale applied in the RESCALE operator should be set to multiplier and shift values such that: multiplier * 2<sup>-shift</sup> = (input scale * weight scale) / output_scale.
Here, input_scale, weight_scale and output_scale are the conversion factors from integer to floating-point for the input, weight and output tensor values respectively.
If per-channel scaling is needed then the per-channel option of the RESCALE operation should be used.</p>
</div>
</div>
<div class="sect3">
<h4 id="_integer_elementwise_operators">1.12.4. Integer Elementwise Operators</h4>
<div class="paragraph">
<p>When two quantized tensors are used in an operation, they must represent the same numeric range for the result to be valid.
In this case, TOSA expects that RESCALE operators will be used as necessary to generate 32-bit integer values in a common range.
There are many valid choices for scale factors and options for the common range.
TOSA does not impose a requirement on which scale factors and range should be used.
Compilers generating TOSA sequences should choose a range that allows the operation to be computed without overflow, while allowing the highest possible accuracy of the output.</p>
</div>
</div>
<div class="sect3">
<h4 id="_general_unary_functions">1.12.5. General Unary Functions</h4>
<div class="paragraph">
<p>General unary functions such as sigmoid(), tanh(), exp() for integer inputs are expressed using a lookup table and interpolation to enable efficient implementation.
This also allows for other operations with the addition of user-supplied tables (the TABLE operation).
All table lookups are based on the following reference lookup function that takes as input a table of 513 entries of 16 bits each.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">int32_t apply_lookup_s(int16_t *table, int32_t value)
{
    int16_t clipped_value = <span class="keyword">static_cast</span>&lt;int16_t&gt;(apply_clip_s&lt;int32_t&gt;(value, -<span class="integer">32768</span>, +<span class="integer">32767</span>));
    int32_t index = (clipped_value + <span class="integer">32768</span>) &gt;&gt; <span class="integer">7</span>;
    int32_t fraction = clipped_value &amp; <span class="hex">0x7f</span>;
    int16_t base = table[index];
    int16_t next = table[index+<span class="integer">1</span>];
    int32_t slope = next - base;
    REQUIRE(slope &gt;= minimum&lt;int16_t&gt; &amp;&amp; slope &lt;= maximum&lt;int16_t&gt;)
    int32_t return_value = (base &lt;&lt; <span class="integer">7</span>) + slope * fraction;
    <span class="keyword">return</span> return_value;        <span class="comment">// return interpolated value of 16 + 7 = 23 bits</span>
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Note that although the table lookup defined here has 16-bit precision, for 8-bit only operations an 8-bit table can be derived by applying the reference function to each of the possible 256 input values.
The following code constructs a 513-entry table based on a reference function.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++"><span class="directive">void</span> generate_lookup_table(int16_t *table, int32_t (*reference)(int32_t))
{
    <span class="keyword">for</span> (<span class="predefined-type">int</span> i = -<span class="integer">256</span>; i &lt;= <span class="integer">256</span>; i++) {
        int32_t value = (*reference)(i);
        table[i + <span class="integer">256</span>] = <span class="keyword">static_cast</span>&lt;int16_t&gt;(apply_clip_s&lt;int32_t&gt;(value, -<span class="integer">32768</span>, +<span class="integer">32767</span>));
    }
}</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_reporting_errors">1.13. Reporting Errors</h3>
<div class="paragraph">
<p>If you find any errors in this document, please feel free to report them by sending an errata entry.
To propose new features or text in the specification, please refer to the TOSA contribution process, including the contribution agreement: <a href="https://www.mlplatform.org/tosa/contributing_spec.html">Specification Contributions</a>
To submit an erratum, kindly include the following information:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Section or Location: The section, chapter, or specific location where the error appears.</p>
</li>
<li>
<p>Description of the Error: A brief explanation of the issue you found (e.g., typo, formatting problem, inaccuracy, unclear wording).</p>
</li>
<li>
<p>Corrected Text: The corrected or suggested clarified text (if applicable).</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Please send this information via email to: <a href="mailto:tosa.errata@arm.com">tosa.errata@arm.com</a>.</p>
</div>
</div>
<div class="sect2">
<h3 id="_other_publications">1.14. Other Publications</h3>
<div class="paragraph">
<p>The following publications are referred to in this specification, or provide more information:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><a id="IEEE-754"></a>IEEE Std 754-2008, <em>IEEE Standard for Floating-point Arithmetic</em>, August 2008.</p>
</li>
<li>
<p><a id="OCP-OFP8"></a>Open Compute Project OCP 8-bit Floating Point Specification (OFP8) Revision 1.0</p>
</li>
</ol>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_operators">2. Operators</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_operator_arguments">2.1. Operator Arguments</h3>
<div class="paragraph">
<p>Operators process input arguments to produce output arguments.
Their behavior can be configured using attribute arguments.
Arguments may have one of the following types:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>tensor_t&lt;element_type&gt;</code>, abbreviated <code>T&lt;element_type&gt;</code>, represents a tensor whose elements are of type <code>element_type</code> where <code>element_type</code> can be any of the data types supported in TOSA.</p>
</li>
<li>
<p><code>tensor_list_t</code> represents a list of tensors. When lists are homogeneous, containing tensors of the same type, their type is further qualified as follows: <code>tensor_list_t&lt;T&lt;element_type&gt;&gt;</code>.<br>
The maximum number of elements in a tensor list is set by the MAX_TENSOR_LIST_SIZE level parameter.</p>
</li>
<li>
<p><code>tosa_graph_t</code> represents a TOSA graph (see <a href="#operator-graphs">Operator Graphs</a>).</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Arguments belong to one of three categories: Input, Output, or Attribute. The category to which an argument belongs further constrains its type:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>An Input argument must be a tensor or a list of tensors used to provide the data read by the operation.</p>
</li>
<li>
<p>An Attribute argument is constant, its value is always known at compilation time.</p>
</li>
<li>
<p>An Output argument must be a tensor or a list of tensors into which the data produced by the operation is written.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Profiles may restrict a set of inputs and/or outputs to be known (constant) at compile time.
Compile time is defined as the time at which TOSA operators are converted to implementation specific commands prior to execution.
This type of input or output is called a Compile Time Constant (CTC).</p>
</div>
<div class="ulist">
<ul>
<li>
<p>A TOSA profile may define some input and/or output arguments to be CTC.</p>
<div class="ulist">
<ul>
<li>
<p>A TOSA extension may change the state of a CTC back to a non-constant input or output.</p>
</li>
<li>
<p>A TOSA extension is not allowed to change a non-constant input or output to a CTC.</p>
</li>
<li>
<p>When a profile defines a CTC for an operator a <strong>Compile Time Constant Status</strong> table will be defined for that operator.<br>
For any arguments in the table, the profiles under which it must be constant are listed as well as the extensions which change this back to a variable input or output.</p>
</li>
<li>
<p>For a TOSA conformant graph a CTC input must be connected to a CTC output, such as the output of a <a href="#_const">CONST</a> or <a href="#_const_shape">CONST_SHAPE</a> operator.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="operator-graphs">2.2. Operator Graphs</h3>
<div class="paragraph">
<p>A TOSA graph is a collection of TOSA operators where:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The output of an operator in the graph may be connected to one or more inputs of other operators in the graph.</p>
</li>
<li>
<p>When an output is connected to an input the tensor list shapes must match.</p>
</li>
<li>
<p>The attributes of the operators are defined and considered part of the graph.</p>
</li>
<li>
<p>The attributes must be in the valid range permitted for the operator.</p>
</li>
<li>
<p>The tensor dimensions must be in the valid range permitted for the operator.</p>
</li>
<li>
<p>The inputs to a graph are a list of tensors, and may not include any elements of type shape_t.</p>
</li>
<li>
<p>The outputs of a graph are a list of tensors, and may not include any elements of type shape_t.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Some operators, such as control flow operators, take a graph of other operators as an attribute. The type <code>tosa_graph_t</code> will denote a graph of operators and the following functions define the tensor shape list for the graph input and outputs:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">shape_list_t tosa_input_shape(tosa_graph_t graph);
shape_list_t tosa_output_shape(tosa_graph_t graph);</code></pre>
</div>
</div>
<div class="paragraph">
<p>Similarly the type tensor_list_t will be used for a list of tensors and the following function returns the shape of a tensor list:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">shape_list_t tensor_list_shape(tensor_list_t tensor_list);</code></pre>
</div>
</div>
<div class="paragraph">
<p>The following function denotes the execution of a TOSA graph within a TOSA context,
on an input tensor list to produce an output tensor list. A TOSA context, represented
by <code>tosa_context_t</code> provides the environment in which a TOSA graph is executed.
Any side-effects that result from the execution of a graph within a context are not
observable by graphs executing in a different context. Operators are executed in an
implementation-defined order that must be a topological ordering of the TOSA graph.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">tosa_execute_graph(tosa_context_t context, tosa_graph_t graph, tensor_list_t input_list, tensor_list_t output_list, tosa_level_t level) {
    ERROR_IF(tensor_list_shape(input_list) != tosa_input_shape(graph));
    ERROR_IF(tensor_list_shape(output_list) != tosa_output_shape(graph));

    <span class="comment">// Declare the global list for storing persistent variable tensors across multiple graphs</span>
    <span class="keyword">if</span> (!variable_tensors) {
        variable_tensors = list&lt;tensor_t&gt;();
    } <span class="keyword">else</span> { <span class="comment">// Clear the &quot;seen flag&quot;</span>
        <span class="keyword">for</span> (tensor_t var_tensor in variable_tensors) {
            var_tensor.seen = <span class="predefined-constant">false</span>;
        }
    }

    for_each(<span class="directive">operator</span> in graph order) {
        ERROR_IF(<span class="directive">operator</span> input tensors <span class="keyword">do</span> <span class="keyword">not</span> meet requirement of <span class="directive">operator</span> Arguments inputs)
        ERROR_IF(<span class="directive">operator</span> attributes <span class="keyword">do</span> <span class="keyword">not</span> meet requirement of <span class="directive">operator</span> Arguments attributes)
        ERROR_IF(<span class="directive">operator</span> output tensors <span class="keyword">do</span> <span class="keyword">not</span> meet requirement of <span class="directive">operator</span> Arguments outputs)
        ERROR_IF(<span class="directive">operator</span> data types <span class="keyword">do</span> <span class="keyword">not</span> meet requirement of <span class="directive">operator</span> Supported Data Types)
        <span class="comment">// Execute the operator as defined by the operation function pseduo-code</span>
        tosa_execute_operator(context, <span class="directive">operator</span>, level);
    }
}</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_tensor_operators">2.3. Tensor Operators</h3>
<div class="sect3">
<h4 id="_argmax">2.3.1. ARGMAX</h4>
<div class="paragraph">
<p>This returns the index with the largest value across the given axis of the input tensor.
If multiple locations have equal values, returns the first match along the search axis.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Integer results must be exact.</p>
</div>
<div class="paragraph">
<p>NaN propagation mode only affects floating-point types.
It indicates either propagating or ignoring NaN.</p>
</div>
<div class="paragraph">
<p>For floating-point input, the following rules apply:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>In the NaN propagating mode, NaN values always compare as greater than non-NaN values.</p>
</li>
<li>
<p>In the NaN ignoring mode, NaN values always compare as less than non-NaN values.</p>
</li>
<li>
<p>The sign of zero is ignored when comparing values.</p>
</li>
<li>
<p>Infinities of the same sign compare as equal.</p>
</li>
<li>
<p>All NaN values compare as equal to other NaN values.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">axis</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Axis in range from 0 to rank(shape1) - 1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">nan_propagation_mode_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">nan_mode</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PROPAGATE or IGNORE. Set to PROPAGATE by default.
                This attribute affects the floating-point NaN propagation approach. This attribute is ignored by non floating-point types.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK - 1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor, with rank = rank(shape1) - 1</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_t</th>
<th class="tableblock halign-left valign-top">out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E4M3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E5M2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-INT16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape1) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">ERROR_IF(axis &lt; <span class="integer">0</span> || axis &gt;= rank(shape1));
shape_t left_shape, right_shape;
<span class="keyword">if</span> (axis == <span class="integer">0</span>) {
    left_shape = [];
} <span class="keyword">else</span> {
    left_shape = shape1[<span class="integer">0</span>:axis - <span class="integer">1</span>];
}
<span class="keyword">if</span> (axis == rank(shape1)-<span class="integer">1</span>) {
    right_shape = [];
} <span class="keyword">else</span> {
    right_shape = shape1[axis+<span class="integer">1</span>:rank(shape1) - <span class="integer">1</span>];
}
ERROR_IF(flatten(left_shape, right_shape) != shape);
for_each_data_position(left_index in left_shape) {
    for_each_data_position(right_index in right_shape) {
        in_t max_value = (is_floating_point&lt;in_t&gt;() &amp;&amp; nan_mode == IGNORE)
                             ? nan&lt;in_t&gt;()
                             : minimum_s&lt;in_t&gt;();
        out_t max_index = <span class="integer">0</span>;
        <span class="keyword">for</span> (tensor_size_t i = <span class="integer">0</span>; i &lt; shape1[axis]; i++) {
            shape_t index = flatten(left_index, [i], right_index);
            in_t value = tensor_read&lt;in_t&gt;(input, shape1, index);
            in_t result = apply_max_s&lt;in_t&gt;(value, max_value, nan_mode);
            <span class="keyword">if</span> (result != max_value) {
                <span class="keyword">if</span> (!(isNaN(result) &amp;&amp; isNaN(max_value))) {
                    max_value = result;
                    max_index = i;
                }
            }
        }
        shape_t index = flatten(left_index, right_index);
        tensor_write&lt;out_t&gt;(output, shape, index, max_index);
    }
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_avg_pool2d">2.3.2. AVG_POOL2D</h4>
<div class="paragraph">
<p>This performs an average pooling over the given input tensor.
A sliding window of size given by &lt;kernel size&gt; is passed over the input tensor, with the mean value being placed in the output tensor.
When calculating the average, only the number of valid input tensor values, but not padding, are used to calculate the divisor.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Integer results must be exact.</p>
</div>
<div class="paragraph">
<p>For floating-point values, the following rules apply:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Subnormal bf16_t, fp16_t, and fp32_t input values may be flushed to zero before calculation.</p>
</li>
<li>
<p>Outputs can be expressed as a dot product of an input vector with a vector with elements 1/KS where KS is the kernel size.</p>
</li>
<li>
<p>This dot product must meet the <a href="#_dot_product_accuracy_requirements">Dot product accuracy requirements</a>.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,IH,IW,C]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[1]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor zero point. Must be zero for non-int8 types.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[1]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor zero point. Must be zero for non-int8 types.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;i32_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">kernel</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[2]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[kernel_y, kernel_x]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;i32_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">stride</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[2]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[stride_y, stride_x]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;i32_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">pad</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[4]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[pad_top, pad_bottom, pad_left, pad_right]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">acc_type_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">acc_type</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Enumerated type, must be one of INT32, FP16, FP32 matching the type of acc_t in the Supported Data Types table for this operation</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,OH,OW,C]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor 4D</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Compile Time Constant Status:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">CTC enabled profile(s)</th>
<th class="tableblock halign-left valign-top">CTC disabled extension(s)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">input_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT, PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-DYNAMIC</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">output_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT, PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-DYNAMIC</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
<th class="tableblock halign-left valign-top">acc_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 with fp16 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8 with int32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E4M3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3 with fp16 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E5M2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2 with fp16 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-INT16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16 with int32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(kernel_y &lt;= MAX_KERNEL);
LEVEL_CHECK(kernel_x &lt;= MAX_KERNEL);
LEVEL_CHECK(stride_y &lt;= MAX_STRIDE);
LEVEL_CHECK(stride_x &lt;= MAX_STRIDE);
LEVEL_CHECK(pad_top &lt;= MAX_KERNEL);
LEVEL_CHECK(pad_bottom &lt;= MAX_KERNEL);
LEVEL_CHECK(pad_left &lt;= MAX_KERNEL);
LEVEL_CHECK(pad_right &lt;= MAX_KERNEL);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">ERROR_IF(!is_same&lt;in_out_t,i8_t&gt;() &amp;&amp; input_zp != <span class="integer">0</span>); <span class="comment">// Zero point only for int8_t</span>
ERROR_IF(!is_same&lt;in_out_t,i8_t&gt;() &amp;&amp; output_zp != <span class="integer">0</span>); <span class="comment">// Zero point only for int8_t</span>
ERROR_IF(kernel_y &lt; <span class="integer">1</span> || kernel_x &lt; <span class="integer">1</span>); <span class="comment">// kernel size must be &gt;= 1</span>
ERROR_IF(stride_y &lt; <span class="integer">1</span> || stride_x &lt; <span class="integer">1</span>);
ERROR_IF(pad_top &lt; <span class="integer">0</span> || pad_bottom &lt; <span class="integer">0</span> || pad_left &lt; <span class="integer">0</span> || pad_right &lt; <span class="integer">0</span>);
<span class="comment">// Padding must be less than kernel size to avoid</span>
<span class="comment">// a divide-by-zero.</span>
ERROR_IF(pad_right &gt;= kernel_x || pad_left &gt;= kernel_x);
ERROR_IF(pad_top &gt;= kernel_y || pad_bottom &gt;= kernel_y);
ERROR_IF(OH != idiv_check(IH + pad_top + pad_bottom - kernel_y, stride_y) + <span class="integer">1</span>);
ERROR_IF(OW != idiv_check(IW + pad_left + pad_right - kernel_x, stride_x) + <span class="integer">1</span>);

for_each(<span class="integer">0</span> &lt;= n &lt; N, <span class="integer">0</span> &lt;= oy &lt; OH, <span class="integer">0</span> &lt;= ox &lt; OW, <span class="integer">0</span> &lt;= c &lt; C ) {
    in_out_t output_val;
    acc_t acc = <span class="integer">0</span>;
    <span class="predefined-type">int</span> count = <span class="integer">0</span>;
    tensor_size_t iy = oy * stride_y - pad_top;
    tensor_size_t ix = ox * stride_x - pad_left;
    for_each(<span class="integer">0</span> &lt;= ky &lt; kernel_y, <span class="integer">0</span> &lt;= kx &lt; kernel_x) {
        tensor_size_t y = iy + ky;
        tensor_size_t x = ix + kx;
        <span class="comment">// Only values from the input tensor are used to calculate the</span>
        <span class="comment">// average, padding does not count</span>
        <span class="keyword">if</span> (<span class="integer">0</span> &lt;= y &lt; IH &amp;&amp; <span class="integer">0</span> &lt;= x &lt; IW) {
            count++;
            acc_t value = sign_extend&lt;acc_t&gt;(tensor_read&lt;in_out_t&gt;(input, [N,IH,IW,C], [n,y,x,c]));
            value = apply_sub_s&lt;acc_t&gt;(value, sign_extend&lt;acc_t&gt;(input_zp));
            acc = apply_add_s&lt;acc_t&gt;(acc, value);
        }
    }
    <span class="keyword">if</span> (is_floating_point&lt;in_out_t&gt;()) {
        output_val = acc / <span class="keyword">static_cast</span>&lt;in_out_t&gt;(count);
    } <span class="keyword">else</span> {
        scale_t scale = reciprocal_scale(count);
        acc = apply_scale_32(acc, scale.multiplier, scale.shift, <span class="predefined-constant">false</span>);
        acc = apply_add_s&lt;acc_t&gt;(acc, sign_extend&lt;acc_t&gt;(output_zp));
        acc = apply_clip_s&lt;acc_t&gt;(acc, minimum_s&lt;in_out_t&gt;(), maximum_s&lt;in_out_t&gt;());
        output_val = <span class="keyword">static_cast</span>&lt;in_out_t&gt;(acc);
    }
    tensor_write&lt;in_out_t&gt;(output, [N,OH,OW,C], [n,oy,ox,c], output_val);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_conv2d">2.3.3. CONV2D</h4>
<div class="paragraph">
<p>Performs a 2D convolution over the given tensor input, using the weight tensor.
Implementations may choose to skip calculation of multiplies in the padding area.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Integer results must be exact.</p>
</div>
<div class="paragraph">
<p>For floating-point values, the following rules apply:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Subnormal bf16_t, fp16_t, and fp32_t input values may be flushed to zero before calculation.</p>
</li>
<li>
<p>Each output can be expressed as a dot product of two input vectors.</p>
</li>
<li>
<p>The dot product must meet the <a href="#_dot_product_accuracy_requirements">Dot product accuracy requirements</a>.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,IH,IW,IC]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;weight_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">weight</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[OC,KH,KW,IC]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Weight kernel size KH x KW</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bias</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[BC]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Per output channel bias data.<br>
            Bias data will be broadcast if BC == 1.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[1]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor zero point. Must be zero for non-int8 types.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;weight_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">weight_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[1]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Weight zero point. Must be zero for non-int8 types.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;i32_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">pad</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[4]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[pad_top, pad_bottom, pad_left, pad_right]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;i32_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">stride</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[2]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[stride_y, stride_x]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;i32_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">dilation</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[2]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[dilation_y, dilation_x]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">acc_type_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">acc_type</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Enumerated type, must be one of INT32, INT48, FP16, FP32 matching the type of acc_t in the Supported Data Types table for this operation</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">local_bound</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">This optional attribute affects the floating-point compliance error bound.
                The default of false allows for direct and transform based, fast convolution algorithms.
                Only set to true if direct dot-product calculation precision is required.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,OH,OW,OC]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Compile Time Constant Status:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">CTC enabled profile(s)</th>
<th class="tableblock halign-left valign-top">CTC disabled extension(s)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">input_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT, PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-DYNAMIC</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">weight_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT, PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-DYNAMIC</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_t</th>
<th class="tableblock halign-left valign-top">weight_t</th>
<th class="tableblock halign-left valign-top">out_t</th>
<th class="tableblock halign-left valign-top">acc_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 with fp16 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8x8 with int32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E4M3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3 with fp16 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E5M2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2 with fp16 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-INT16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16x8 with int48 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i48_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i48_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-INT4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8x4 with int32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i4_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(dilation_y * KH &lt;= MAX_KERNEL);
LEVEL_CHECK(dilation_x * KW &lt;= MAX_KERNEL);
LEVEL_CHECK(pad_top &lt;= MAX_KERNEL);
LEVEL_CHECK(pad_bottom &lt;= MAX_KERNEL);
LEVEL_CHECK(pad_left &lt;= MAX_KERNEL);
LEVEL_CHECK(pad_right &lt;= MAX_KERNEL);
LEVEL_CHECK(stride_y &lt;= MAX_STRIDE);
LEVEL_CHECK(stride_x &lt;= MAX_STRIDE);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">ERROR_IF(!is_same&lt;in_t,i8_t&gt;() &amp;&amp; input_zp != <span class="integer">0</span>); <span class="comment">// Zero point only for int8_t</span>
ERROR_IF(!is_same&lt;weight_t,int8_t&gt;() &amp;&amp; weight_zp != <span class="integer">0</span>);
ERROR_IF(pad_top &lt; <span class="integer">0</span> || pad_bottom &lt; <span class="integer">0</span> || pad_left &lt; <span class="integer">0</span> || pad_right &lt; <span class="integer">0</span>);
ERROR_IF(stride_y &lt; <span class="integer">1</span> || stride_x &lt; <span class="integer">1</span>);
ERROR_IF(dilation_y &lt; <span class="integer">1</span> || dilation_x &lt; <span class="integer">1</span>);
ERROR_IF(OH != idiv_check(IH - <span class="integer">1</span> + pad_top + pad_bottom - (KH - <span class="integer">1</span>) * dilation_y, stride_y) + <span class="integer">1</span>);
ERROR_IF(OW != idiv_check(IW - <span class="integer">1</span> + pad_left + pad_right - (KW - <span class="integer">1</span>) * dilation_x, stride_x) + <span class="integer">1</span>);
ERROR_IF(BC != OC &amp;&amp; BC != <span class="integer">1</span>);

for_each(<span class="integer">0</span> &lt;= n &lt; N, <span class="integer">0</span> &lt;= oy &lt; OH, <span class="integer">0</span> &lt;= ox &lt; OW, <span class="integer">0</span> &lt;= oc &lt; OC) {
    acc_t acc = <span class="integer">0</span>;
    tensor_size_t iy = oy * stride_y - pad_top;
    tensor_size_t ix = ox * stride_x - pad_left;
    for_each(<span class="integer">0</span> &lt;= ky &lt; KH, <span class="integer">0</span> &lt;= kx &lt; KW, <span class="integer">0</span> &lt;= ic &lt; IC) {
        tensor_size_t y = iy + ky * dilation_y;
        tensor_size_t x = ix + kx * dilation_x;
        acc_t value = <span class="integer">0</span>;
        <span class="keyword">if</span> (<span class="integer">0</span> &lt;= y &lt; IH &amp;&amp; <span class="integer">0</span> &lt;= x &lt; IW) {
            value  = <span class="keyword">static_cast</span>&lt;acc_t&gt;(tensor_read&lt;in_t&gt;(input,
                                                          [N,IH,IW,IC],
                                                          [n,y,x,ic]));
            value  = apply_sub_s&lt;acc_t&gt;(value, <span class="keyword">static_cast</span>&lt;acc_t&gt;(input_zp));
        }
        <span class="keyword">if</span> ((<span class="integer">0</span> &lt;= y &lt; IH &amp;&amp; <span class="integer">0</span> &lt;= x &lt; IW) || tosa_extra_multiplies) {
            acc_t weight_el = <span class="keyword">static_cast</span>&lt;acc_t&gt;(tensor_read&lt;weight_t&gt;(weight,
                                                                       [OC,KH,KW,IC],
                                                                       [oc,ky,kx,ic]));
            weight_el = apply_sub_s&lt;acc_t&gt;(weight_el, <span class="keyword">static_cast</span>&lt;acc_t&gt;(weight_zp));
            acc = apply_add_s&lt;acc_t&gt;(acc, apply_mul_s&lt;acc_t&gt;(value, weight_el));
        }
    }
    out_t out = <span class="keyword">static_cast</span>&lt;out_t&gt;(acc);
    out = apply_add_s&lt;out_t&gt;(out, bias[(BC == <span class="integer">1</span>) ? <span class="integer">0</span> : oc]);
    tensor_write&lt;out_t&gt;(output, [N,OH,OW,OC], [n,oy,ox,oc], out);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_conv3d">2.3.4. CONV3D</h4>
<div class="paragraph">
<p>Performs a 3D convolution over the given input tensor.
Implementations may choose to skip calculation of multiplies in the padding area.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Integer results must be exact.</p>
</div>
<div class="paragraph">
<p>For floating-point values, the following rules apply:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Subnormal bf16_t, fp16_t, and fp32_t input values may be flushed to zero before calculation.</p>
</li>
<li>
<p>Each output can be expressed as a dot product of two input vectors.</p>
</li>
<li>
<p>The dot product must meet the <a href="#_dot_product_accuracy_requirements">Dot product accuracy requirements</a>.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,ID,IH,IW,IC]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">5</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;weight_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">weight</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[OC,KD,KH,KW,IC]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">5</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Weight kernel size KDxKHxKW</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bias</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[BC]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Per output channel bias data.<br>
            Bias data will be broadcast if BC == 1.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[1]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor zero point. Must be zero for non-int8 types.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;weight_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">weight_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[1]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Weight zero point. Must be zero for non-int8 types.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;i32_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">pad</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[6]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[pad_d0, pad_d1, pad_top, pad_bottom, pad_left, pad_right]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;i32_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">stride</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[3]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[stride_d, stride_y, stride_x]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;i32_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">dilation</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[3]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[dilation_d, dilation_y, dilation_x]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">acc_type_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">acc_type</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Enumerated type, must be one of INT32, INT48, FP16, FP32 matching the type of acc_t in the Supported Data Types table for this operation</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">local_bound</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">This optional attribute affects the floating-point compliance error bound.
                The default of false allows for direct and transform based, fast convolution algorithms.
                Only set to true if direct dot-product calculation precision is required.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,OD,OH,OW,OC]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">5</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Compile Time Constant Status:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">CTC enabled profile(s)</th>
<th class="tableblock halign-left valign-top">CTC disabled extension(s)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">input_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT, PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-DYNAMIC</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">weight_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT, PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-DYNAMIC</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_t</th>
<th class="tableblock halign-left valign-top">weight_t</th>
<th class="tableblock halign-left valign-top">out_t</th>
<th class="tableblock halign-left valign-top">acc_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 with fp16 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8x8 with int32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E4M3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3 with fp16 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E5M2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2 with fp16 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-INT16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16x8 with int48 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i48_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i48_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-INT4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8x4 with int32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i4_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(dilation_d * KD &lt;= MAX_KERNEL);
LEVEL_CHECK(dilation_y * KH &lt;= MAX_KERNEL);
LEVEL_CHECK(dilation_x * KW &lt;= MAX_KERNEL);
LEVEL_CHECK(pad_d0 &lt;= MAX_KERNEL);
LEVEL_CHECK(pad_d1 &lt;= MAX_KERNEL);
LEVEL_CHECK(pad_top &lt;= MAX_KERNEL);
LEVEL_CHECK(pad_bottom &lt;= MAX_KERNEL);
LEVEL_CHECK(pad_left &lt;= MAX_KERNEL);
LEVEL_CHECK(pad_right &lt;= MAX_KERNEL);
LEVEL_CHECK(stride_y &lt;= MAX_STRIDE);
LEVEL_CHECK(stride_x &lt;= MAX_STRIDE);
LEVEL_CHECK(stride_d &lt;= MAX_STRIDE);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">ERROR_IF(!is_same&lt;in_t,i8_t&gt;() &amp;&amp; input_zp != <span class="integer">0</span>); <span class="comment">// Zero point only for int8_t</span>
ERROR_IF(!is_same&lt;weight_t,i8_t&gt;() &amp;&amp; weight_zp != <span class="integer">0</span>);
ERROR_IF(pad_d0 &lt; <span class="integer">0</span> || pad_d1 &lt; <span class="integer">0</span> || pad_top &lt; <span class="integer">0</span> || pad_bottom &lt; <span class="integer">0</span> || pad_left &lt; <span class="integer">0</span> || pad_right &lt; <span class="integer">0</span>);
ERROR_IF(stride_d &lt; <span class="integer">1</span> || stride_y &lt; <span class="integer">1</span> || stride_x &lt; <span class="integer">1</span>);
ERROR_IF(dilation_d &lt; <span class="integer">1</span> || dilation_y &lt; <span class="integer">1</span> || dilation_x &lt; <span class="integer">1</span>);
ERROR_IF(OD != idiv_check(ID - <span class="integer">1</span> + pad_d0 + pad_d1      - (KD - <span class="integer">1</span>) * dilation_d, stride_d) + <span class="integer">1</span>);
ERROR_IF(OH != idiv_check(IH - <span class="integer">1</span> + pad_top + pad_bottom - (KH - <span class="integer">1</span>) * dilation_y, stride_y) + <span class="integer">1</span>);
ERROR_IF(OW != idiv_check(IW - <span class="integer">1</span> + pad_left + pad_right - (KW - <span class="integer">1</span>) * dilation_x, stride_x) + <span class="integer">1</span>);
ERROR_IF(BC != OC &amp;&amp; BC != <span class="integer">1</span>);

for_each(<span class="integer">0</span> &lt;= n &lt; N, <span class="integer">0</span> &lt;= od &lt; OD, <span class="integer">0</span> &lt;= oy &lt; OH, <span class="integer">0</span> &lt;= ox &lt; OW, <span class="integer">0</span> &lt;= oc &lt; OC) {
    acc_t acc = <span class="integer">0</span>;
    tensor_size_t id = od * stride_d - pad_d0;
    tensor_size_t iy = oy * stride_y - pad_top;
    tensor_size_t ix = ox * stride_x - pad_left;
    for_each(<span class="integer">0</span> &lt;= kd &lt; KD, <span class="integer">0</span> &lt;= ky &lt; KH, <span class="integer">0</span> &lt;= kx &lt; KW, <span class="integer">0</span> &lt;= ic &lt; IC) {
        tensor_size_t d = id + kd * dilation_d;
        tensor_size_t y = iy + ky * dilation_y;
        tensor_size_t x = ix + kx * dilation_x;
        acc_t value = <span class="integer">0</span>;
        <span class="keyword">if</span> (<span class="integer">0</span> &lt;= x &lt; IW &amp;&amp; <span class="integer">0</span> &lt;= y &lt; IH &amp;&amp; <span class="integer">0</span> &lt;= d &lt; ID) {
            value  = <span class="keyword">static_cast</span>&lt;acc_t&gt;(tensor_read&lt;in_t&gt;(input,
                                                          [N,ID,IH,IW,IC],
                                                          [n,d,y,x,ic]));
            value  = apply_sub_s&lt;acc_t&gt;(value, <span class="keyword">static_cast</span>&lt;acc_t&gt;(input_zp));
        }
        <span class="keyword">if</span> ((<span class="integer">0</span> &lt;= x &lt; IW &amp;&amp; <span class="integer">0</span> &lt;= y &lt; IH &amp;&amp; <span class="integer">0</span> &lt;= d &lt; ID) || tosa_extra_multiplies) {
            acc_t weight_el = <span class="keyword">static_cast</span>&lt;acc_t&gt;(tensor_read&lt;weight_t&gt;(weight,
                                                                       [OC,KD,KH,KW,IC],
                                                                       [oc,kd,ky,kx,ic]));
            weight_el = apply_sub_s&lt;acc_t&gt;(weight_el, <span class="keyword">static_cast</span>&lt;acc_t&gt;(weight_zp));
            acc = apply_add_s&lt;acc_t&gt;(acc, apply_mul_s&lt;acc_t&gt;(value, weight_el));
        }
    }
    out_t out = <span class="keyword">static_cast</span>&lt;out_t&gt;(acc);
    out = apply_add_s&lt;out_t&gt;(out, bias[(BC == <span class="integer">1</span>) ? <span class="integer">0</span> : oc]);
    tensor_write&lt;out_t&gt;(output, [N,OD,OH,OW,OC], [n,od,oy,ox,oc], out);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_depthwise_conv2d">2.3.5. DEPTHWISE_CONV2D</h4>
<div class="paragraph">
<p>Performs 2D convolutions separately over each channel of the given tensor input, using the weight tensor.
Implementations may choose to skip calculation of multiplies in the padding area.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Integer results must be exact.</p>
</div>
<div class="paragraph">
<p>For floating-point values, the following rules apply:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Subnormal bf16_t, fp16_t, and fp32_t input values may be flushed to zero before calculation.</p>
</li>
<li>
<p>Each output can be expressed as a dot product of two input vectors.</p>
</li>
<li>
<p>The dot product must meet the <a href="#_dot_product_accuracy_requirements">Dot product accuracy requirements</a>.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,IH,IW,C]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;weight_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">weight</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[KH,KW,C,M]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Weight kernel size KH x KW</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bias</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[BC]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Per output channel bias data.<br>
            Bias data will be broadcast if BC == 1.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[1]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor zero point. Must be zero for non-int8 types.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;weight_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">weight_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[1]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Weight zero point. Must be zero for non-int8 types.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;i32_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">pad</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[4]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[pad_top, pad_bottom, pad_left, pad_right]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;i32_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">stride</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[2]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[stride_y, stride_x]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;i32_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">dilation</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[2]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[dilation_y, dilation_x]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">acc_type_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">acc_type</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Enumerated type, must be one of INT32, INT48, FP16, FP32 matching the type of acc_t in the Supported Data Types table for this operation</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">local_bound</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">This optional attribute affects the floating-point compliance error bound.
                The default of false allows for direct and transform based, fast convolution algorithms.
                Only set to true if direct dot-product calculation precision is required.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,OH,OW,C*M]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Compile Time Constant Status:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">CTC enabled profile(s)</th>
<th class="tableblock halign-left valign-top">CTC disabled extension(s)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">input_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT, PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-DYNAMIC</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">weight_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT, PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-DYNAMIC</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_t</th>
<th class="tableblock halign-left valign-top">weight_t</th>
<th class="tableblock halign-left valign-top">out_t</th>
<th class="tableblock halign-left valign-top">acc_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 with fp16 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8x8 with int32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E4M3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3 with fp16 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E5M2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2 with fp16 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-INT16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16x8 with int48 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i48_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i48_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-INT4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8x4 with int32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i4_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(dilation_y * KH &lt;= MAX_KERNEL);
LEVEL_CHECK(dilation_x * KW &lt;= MAX_KERNEL);
LEVEL_CHECK(pad_top &lt;= MAX_KERNEL);
LEVEL_CHECK(pad_bottom &lt;= MAX_KERNEL);
LEVEL_CHECK(pad_left &lt;= MAX_KERNEL);
LEVEL_CHECK(pad_right &lt;= MAX_KERNEL);
LEVEL_CHECK(stride_y &lt;= MAX_STRIDE);
LEVEL_CHECK(stride_x &lt;= MAX_STRIDE);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">ERROR_IF(!is_same&lt;in_t,i8_t&gt;() &amp;&amp; input_zp != <span class="integer">0</span>); <span class="comment">// Zero point only for int8_t</span>
ERROR_IF(!is_same&lt;weight_t,i8_t&gt;() &amp;&amp; weight_zp != <span class="integer">0</span>);
ERROR_IF(pad_top &lt; <span class="integer">0</span> || pad_bottom &lt; <span class="integer">0</span> || pad_left &lt; <span class="integer">0</span> || pad_right &lt; <span class="integer">0</span>);
ERROR_IF(stride_y &lt; <span class="integer">1</span> || stride_x &lt; <span class="integer">1</span>);
ERROR_IF(dilation_y &lt; <span class="integer">1</span> || dilation_x &lt; <span class="integer">1</span>);
ERROR_IF(OH != idiv_check(IH - <span class="integer">1</span> + pad_top + pad_bottom - (KH - <span class="integer">1</span>) * dilation_y, stride_y) + <span class="integer">1</span>);
ERROR_IF(OW != idiv_check(IW - <span class="integer">1</span> + pad_left + pad_right - (KW - <span class="integer">1</span>) * dilation_x, stride_x) + <span class="integer">1</span>);
ERROR_IF(BC != C*M &amp;&amp; BC != <span class="integer">1</span>);

for_each(<span class="integer">0</span> &lt;= n &lt; N, <span class="integer">0</span> &lt;= oy &lt; OH, <span class="integer">0</span> &lt;= ox &lt; OW, <span class="integer">0</span> &lt;= c &lt; C, <span class="integer">0</span> &lt;= m &lt; M) {
    acc_t acc = <span class="integer">0</span>;
    tensor_size_t iy = oy * stride_y - pad_top;
    tensor_size_t ix = ox * stride_x - pad_left;
    for_each(<span class="integer">0</span> &lt;= ky &lt; KH, <span class="integer">0</span> &lt;= kx &lt; KW) {
        tensor_size_t y = iy + ky * dilation_y;
        tensor_size_t x = ix + kx * dilation_x;
        acc_t value = <span class="integer">0</span>;
        <span class="keyword">if</span> (<span class="integer">0</span> &lt;= y &lt; IH &amp;&amp; <span class="integer">0</span> &lt;= x &lt; IW) {
            value  = <span class="keyword">static_cast</span>&lt;acc_t&gt;(tensor_read&lt;in_t&gt;(input,
                                                          [N,IH,IW,C],
                                                          [n,y,x,c]));
            value  = apply_sub_s&lt;acc_t&gt;(value, <span class="keyword">static_cast</span>&lt;acc_t&gt;(input_zp));
        }
        <span class="keyword">if</span> ((<span class="integer">0</span> &lt;= y &lt; IH &amp;&amp; <span class="integer">0</span> &lt;= x &lt; IW) || tosa_extra_multiplies) {
            acc_t weight_el = <span class="keyword">static_cast</span>&lt;acc_t&gt;(tensor_read&lt;weight_t&gt;(weight,
                                                                       [KH,KW,C,M],
                                                                       [ky,kx,c,m]));
            weight_el = apply_sub_s&lt;acc_t&gt;(weight_el, <span class="keyword">static_cast</span>&lt;acc_t&gt;(weight_zp));
            acc = apply_add_s&lt;acc_t&gt;(acc, apply_mul_s&lt;acc_t&gt;(value, weight_el));
        }
    }
    out_t out = <span class="keyword">static_cast</span>&lt;out_t&gt;(acc);
    out = apply_add_s&lt;out_t&gt;(out, bias[(BC == <span class="integer">1</span>) ? <span class="integer">0</span> : (c * M) + m]);
    tensor_write&lt;out_t&gt;(output, [N,OH,OW,C * M], [n,oy,ox,c * M + m], out);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_fft2d">2.3.6. FFT2D</h4>
<div class="paragraph">
<p>Performs a batched complex 2D Fast Fourier Transform over the input.
The complex input values are constructed from the corresponding values in the input_real and input_imag tensors.
The resulting values in the output are split into the output_real and output_imag tensors.
No normalization is applied on either the forward or inverse versions of the operation.</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="/assets/images/forward_fft2d.svg" alt="forward FFT definition">
</div>
<div class="title">Figure 1. Calculation for the forward FFT2D calculation (inverse=false)</div>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="/assets/images/inverse_fft2d.svg" alt="inverse FFT definition">
</div>
<div class="title">Figure 2. Calculation for the inverse FFT2D calculation (inverse=true)</div>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Subnormal bf16_t, fp16_t, and fp32_t input values may be flushed to zero before calculation.</p>
</li>
<li>
<p>Each output can be expressed as a dot product of an input vector with a constant coefficient vector.</p>
</li>
<li>
<p>The following may be used to validate the output</p>
<div class="ulist">
<ul>
<li>
<p>Let <code>input_real</code> be the real input tensor.</p>
</li>
<li>
<p>Let <code>input_imag</code> be the imaginary input tensor.</p>
</li>
<li>
<p>Let <code>weight_real</code> be the coefficient vector tensor of real values.</p>
</li>
<li>
<p>Let <code>weight_imag</code> be the coefficient vector tensor of imaginary values.</p>
</li>
<li>
<p>Let <code>input</code> be an interleaved tensor of real values from input tensors <code>input_real</code> and <code>input_imag</code> such that <code>input = [input_real[0], input_imag[0], input_real[1], input_imag[1], &#8230;&#8203;]</code> and <code>shape(input) = [N,H,W*2]</code>.</p>
</li>
<li>
<p>Let <code>weight</code> be an interleaved tensor of real values from weight tensors <code>weight_real</code> and <code>weight_imag</code> such that <code>weight = [weight_real[0], weight_imag[0], weight_real[1], weight_imag[1], &#8230;&#8203;]</code> and <code>shape(weight) = [N,H,W*2]</code>.</p>
</li>
<li>
<p>Let <code>FFT_Real</code> be the operation that calculates the real output (<code>output_real</code>).</p>
</li>
<li>
<p>Let <code>FFT_Imag</code> be the operation that calculates the imaginary output (<code>output_imag</code>).</p>
</li>
<li>
<p>For all <code>S</code> in the defined data sets in Appendix A <a href="#_floating_point_operator_test_data">Floating-Point Operator Test Data</a>.</p>
<div class="ulist">
<ul>
<li>
<p><code>tosa_reference_check_dotproduct&lt;FFT_Real, in_out_t, in_out_t, in_out_t, in_out_t&gt;(S, input, weight, [])</code> must be true.</p>
</li>
<li>
<p><code>tosa_reference_check_dotproduct&lt;FFT_Imag, in_out_t, in_out_t, in_out_t, in_out_t&gt;(S, input, weight, [])</code> must be true.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input_real</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,H,W]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Real part of the complex input. H,W must be powers of two.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input_imag</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,H,W]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Imaginary part of the complex input. H,W must be powers of two.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">inverse</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false for forward FFT, true for inverse FFT</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">local_bound</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">This optional attribute affects the floating-point compliance error bound.
                The default of false allows for direct and transform based, fast convolution algorithms.
                Only set to true if direct dot-product calculation precision is required.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output_real</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,H,W]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Real part of the complex output.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output_imag</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,H,W]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Imaginary part of the complex output.</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FFT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(H &lt;= MAX_KERNEL);
LEVEL_CHECK(W &lt;= MAX_KERNEL);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">ERROR_IF(!power_of_two(H));
ERROR_IF(!power_of_two(W));

<span class="predefined-type">float</span> sign_val = <span class="float">1</span><span class="float">.0</span>;

<span class="keyword">if</span> (inverse) {
    sign_val = -<span class="float">1</span><span class="float">.0</span>;
}

for_each(<span class="integer">0</span> &lt;= n &lt; N, <span class="integer">0</span> &lt;= oy &lt; H, <span class="integer">0</span> &lt;= ox &lt; W) {
    in_out_t sum_real = <span class="float">0</span><span class="float">.0</span>;
    in_out_t sum_imag = <span class="float">0</span><span class="float">.0</span>;
    for_each(<span class="integer">0</span> &lt;= iy &lt; H, <span class="integer">0</span> &lt;= ix &lt; W) {
        in_out_t val_real = tensor_read&lt;in_out_t&gt;(input_real, [N,H,W], [n,iy,ix]);
        in_out_t val_imag = tensor_read&lt;in_out_t&gt;(input_imag, [N,H,W], [n,iy,ix]);
        tensor_size_t ay = (<span class="keyword">static_cast</span>&lt;tensor_size_t&gt;(iy) * <span class="keyword">static_cast</span>&lt;tensor_size_t&gt;(oy)) % <span class="keyword">static_cast</span>&lt;tensor_size_t&gt;(H);
        tensor_size_t ax = (<span class="keyword">static_cast</span>&lt;tensor_size_t&gt;(ix) * <span class="keyword">static_cast</span>&lt;tensor_size_t&gt;(ox)) % <span class="keyword">static_cast</span>&lt;tensor_size_t&gt;(W);
        in_out_t a = sign_val * <span class="integer">2</span> * pi() * (<span class="keyword">static_cast</span>&lt;in_out_t&gt;(ay) / H + <span class="keyword">static_cast</span>&lt;in_out_t&gt;(ax) / W);
        sum_real +=  val_real * cos(a) + val_imag * sin(a);
        sum_imag += -val_real * sin(a) + val_imag * cos(a);
    }
    tensor_write&lt;in_out_t&gt;(output_real, [N,H,W], [n,oy,ox], sum_real);
    tensor_write&lt;in_out_t&gt;(output_imag, [N,H,W], [n,oy,ox], sum_imag);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_matmul">2.3.7. MATMUL</h4>
<div class="paragraph">
<p>Performs two dimensional matrix multiplications.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Integer results must be exact.</p>
</div>
<div class="paragraph">
<p>For floating-point values, the following rules apply:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Subnormal bf16_t, fp16_t, and fp32_t input values may be flushed to zero before calculation.</p>
</li>
<li>
<p>Each output can be expressed as a dot product of two input vectors.</p>
</li>
<li>
<p>The dot product must meet the <a href="#_dot_product_accuracy_requirements">Dot product accuracy requirements</a>.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,H,C]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor A, N matrices of size HxC</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">B</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,C,W]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor B, N matrices of size CxW</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[1]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor A zero point. Must be zero for non-int8 types.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">B_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[1]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor B zero point. Must be zero for non-int8 types.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,H,W]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor, N matrices of size HxW</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Compile Time Constant Status:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">CTC enabled profile(s)</th>
<th class="tableblock halign-left valign-top">CTC disabled extension(s)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">A_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT, PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-DYNAMIC</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">B_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT, PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-DYNAMIC</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_t</th>
<th class="tableblock halign-left valign-top">out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 with fp16 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8x8 with int32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E4M3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3 with fp16 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E5M2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2 with fp16 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-INT16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16x16 with int48 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i48_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">ERROR_IF(is_same&lt;in_t,i8_t&gt; &amp;&amp; (A_zp != <span class="integer">0</span> || B_zp != <span class="integer">0</span>)); <span class="comment">// Zero point only for i8_t</span>
for_each(<span class="integer">0</span> &lt;= n &lt; N, <span class="integer">0</span> &lt;= h &lt; H, <span class="integer">0</span> &lt;= w &lt; W) {
    out_t acc = <span class="integer">0</span>;
    for_each(<span class="integer">0</span> &lt;= c &lt; C) {
        out_t value1 = <span class="keyword">static_cast</span>&lt;out_t&gt;(tensor_read&lt;in_t&gt;(A, [N,H,C], [n,h,c]));
        out_t value2 = <span class="keyword">static_cast</span>&lt;out_t&gt;(tensor_read&lt;in_t&gt;(B, [N,C,W], [n,c,w]));
        value1 = apply_sub_s&lt;out_t&gt;(value1, <span class="keyword">static_cast</span>&lt;out_t&gt;(A_zp));
        value2 = apply_sub_s&lt;out_t&gt;(value2, <span class="keyword">static_cast</span>&lt;out_t&gt;(B_zp));
        acc = apply_add_s&lt;out_t&gt;(acc, apply_mul_s&lt;out_t&gt;(value1 * value2));
    }
    tensor_write&lt;out_t&gt;(output, [N,H,W], [n,h,w], acc);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_max_pool2d">2.3.8. MAX_POOL2D</h4>
<div class="paragraph">
<p>This performs a max pooling over the given input tensor.
A sliding window of size given by &lt;kernel size&gt; is passed over the input tensor, with the maximum value being placed in the output tensor.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Integer results must be exact.</p>
</div>
<div class="paragraph">
<p>NaN propagation mode only affects floating-point types.
It indicates either propagating or ignoring NaN.</p>
</div>
<div class="paragraph">
<p>The following rules apply to floating-point inputs:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Comparison rules:</p>
<div class="ulist">
<ul>
<li>
<p>The sign of a zero is ignored.</p>
</li>
<li>
<p>Infinities of the same sign compare as equal.</p>
</li>
<li>
<p>In the NaN propagating mode, if any input in the window is a NaN then the result must be NaN.</p>
</li>
<li>
<p>In the NaN ignoring mode, if all inputs in the window are NaN, the result is NaN.
Otherwise the result is the maximum non-NaN value in the window.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Subnormal bf16_t, fp16_t, and fp32_t input values may be flushed to zero before calculation.</p>
</li>
<li>
<p>If a floating-point result is zero, then the result must be either +0.0 or -0.0 but either sign is permitted.</p>
</li>
<li>
<p>If the result is a subnormal value for bf16_t, fp16_t, or fp32_t, the result may be a zero of either sign.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,IH,IW,C]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor 4D</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;i32_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">kernel</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[2]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[kernel_y, kernel_x]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;i32_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">stride</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[2]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[stride_y, stride_x]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;i32_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">pad</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[4]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[pad_top, pad_bottom, pad_left, pad_right]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">nan_propagation_mode_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">nan_mode</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PROPAGATE or IGNORE. Set to PROPAGATE by default.
                This attribute affects the floating-point NaN propagation approach. This attribute is ignored by non floating-point types.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,OH,OW,C]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor 4D</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E4M3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E5M2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-INT16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(kernel_y &lt;= MAX_KERNEL);
LEVEL_CHECK(kernel_x &lt;= MAX_KERNEL);
LEVEL_CHECK(stride_y &lt;= MAX_STRIDE);
LEVEL_CHECK(stride_x &lt;= MAX_STRIDE);
LEVEL_CHECK(pad_top &lt;= MAX_KERNEL);
LEVEL_CHECK(pad_bottom &lt;= MAX_KERNEL);
LEVEL_CHECK(pad_left &lt;= MAX_KERNEL);
LEVEL_CHECK(pad_right &lt;= MAX_KERNEL);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">ERROR_IF(kernel_y &lt; <span class="integer">1</span> || kernel_x &lt; <span class="integer">1</span>); <span class="comment">// kernel size must be &gt;= 1</span>
ERROR_IF(stride_y &lt; <span class="integer">1</span> || stride_x &lt; <span class="integer">1</span>);
ERROR_IF(pad_top &lt; <span class="integer">0</span> || pad_bottom &lt; <span class="integer">0</span> || pad_left &lt; <span class="integer">0</span> || pad_right &lt; <span class="integer">0</span>);
<span class="comment">// Padding must be less than kernel size, otherwise no</span>
<span class="comment">// input values will be used.</span>
ERROR_IF(pad_right &gt;= kernel_x || pad_left &gt;= kernel_x);
ERROR_IF(pad_top &gt;= kernel_y || pad_bottom &gt;= kernel_y);
ERROR_IF(OH != idiv_check(IH + pad_top + pad_bottom - kernel_y, stride_y) + <span class="integer">1</span>);
ERROR_IF(OW != idiv_check(IW + pad_left + pad_right - kernel_x, stride_x) + <span class="integer">1</span>);

for_each(<span class="integer">0</span> &lt;= n &lt; N, <span class="integer">0</span> &lt;= oy &lt; OH, <span class="integer">0</span> &lt;= ox &lt; OW, <span class="integer">0</span> &lt;= c &lt; C ) {
    in_out_t acc = (is_floating_point&lt;in_out_t&gt;() &amp;&amp; nan_mode == IGNORE)
                       ? nan&lt;in_out_t&gt;()
                       : minimum_s&lt;in_out_t&gt;();
    tensor_size_t iy = oy * stride_y - pad_top;
    tensor_size_t ix = ox * stride_x - pad_left;
    for_each( <span class="integer">0</span> &lt;= ky &lt; kernel_y, <span class="integer">0</span> &lt;= kx &lt; kernel_x ) {
        tensor_size_t y = iy + ky;
        tensor_size_t x = ix + kx;
        <span class="keyword">if</span> (y &gt;= <span class="integer">0</span> &amp;&amp; y &lt; IH &amp;&amp; x &gt;= <span class="integer">0</span> &amp;&amp; x &lt; IW) {
            in_out_t value = tensor_read&lt;in_out_t&gt;(input, [N,IH,IW,C], [n,y,x,c]);
            acc = apply_max_s&lt;in_out_t&gt;(acc, value, nan_mode);
        }
    }
    tensor_write&lt;in_out_t&gt;(output, [N,OH,OW,C], [n,oy,ox,c], acc);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_rfft2d">2.3.9. RFFT2D</h4>
<div class="paragraph">
<p>Performs a batched 2D real-valued Fast Fourier Transform over the input where the input tensor consists of real values producing complex valued output.
The complex output values will be split into the output_real and output_imag tensor arguments.
RFFT2D takes advantage of Hermitian symmetry to only calculate the first half of the final output axis.
Implementations may choose to skip calculation of the imaginary values at (0,0), (0,W/2), (H/2,0), and (H/2, W/2).
If the calculation is skipped, the result at that location must be zero.</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="/assets/images/forward_fft2d.svg" alt="forward RFFT definition">
</div>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Subnormal bf16_t, fp16_t, and fp32_t input values may be flushed to zero before calculation.</p>
</li>
<li>
<p>Each output can be expressed as a dot product of an input vector with a constant coefficient vector.</p>
</li>
<li>
<p>The following may be used to validate the output</p>
<div class="ulist">
<ul>
<li>
<p>Let <code>RFFT_Real</code> be the operation that calculates the real output (<code>output_real</code>).</p>
</li>
<li>
<p>Let <code>RFFT_Imag</code> be the operation that calculates the imaginary output (<code>output_imag</code>).</p>
</li>
<li>
<p>Let <code>input</code> be the input tensor.</p>
</li>
<li>
<p>Let <code>weight_real</code> be the coefficient vector tensor of real values.</p>
</li>
<li>
<p>Let <code>weight_imag</code> be the coefficient vector tensor of imaginary values.</p>
</li>
<li>
<p>For all <code>S</code> in the defined data sets in Appendix A <a href="#_floating_point_operator_test_data">Floating-Point Operator Test Data</a>.</p>
<div class="ulist">
<ul>
<li>
<p><code>tosa_reference_check_dotproduct&lt;RFFT_Real, in_out_t, in_out_t, in_out_t, in_out_t&gt;(S, input, weight_real, [])</code> must be true.</p>
</li>
<li>
<p><code>tosa_reference_check_dotproduct&lt;RFFT_Imag, in_out_t, in_out_t, in_out_t, in_out_t&gt;(S, input, weight_imag, [])</code> must be true.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input_real</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,H,W]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Real input. H,W must be powers of two.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">local_bound</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">This optional attribute affects the floating-point compliance error bound.
                The default of false allows for direct and transform based, fast convolution algorithms.
                Only set to true if direct dot-product calculation precision is required.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output_real</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,H,W/2 + 1]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Real part of the complex output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output_imag</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,H,W/2 + 1]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Imaginary part of the complex output.</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FFT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(H &lt;= MAX_KERNEL);
LEVEL_CHECK(W &lt;= MAX_KERNEL);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">ERROR_IF(!power_of_two(H));
ERROR_IF(!power_of_two(W));

for_each(<span class="integer">0</span> &lt;= n &lt; N, <span class="integer">0</span> &lt;= oy &lt; H, <span class="integer">0</span> &lt;= ox &lt; W/<span class="integer">2</span> + <span class="integer">1</span>) {
    in_out_t sum_real = <span class="float">0</span><span class="float">.0</span>;
    in_out_t sum_imag = <span class="float">0</span><span class="float">.0</span>;
    for_each(<span class="integer">0</span> &lt;= iy &lt; H, <span class="integer">0</span> &lt;= ix &lt; W) {
        in_out_t val_real = tensor_read&lt;in_out_t&gt;(input_real, [N,H,W], [n,iy,ix]);
        tensor_size_t ay = (<span class="keyword">static_cast</span>&lt;tensor_size_t&gt;(iy) * <span class="keyword">static_cast</span>&lt;tensor_size_t&gt;(oy)) % <span class="keyword">static_cast</span>&lt;tensor_size_t&gt;(H);
        tensor_size_t ax = (<span class="keyword">static_cast</span>&lt;tensor_size_t&gt;(ix) * <span class="keyword">static_cast</span>&lt;tensor_size_t&gt;(ox)) % <span class="keyword">static_cast</span>&lt;tensor_size_t&gt;(W);
        in_out_t a = <span class="integer">2</span> * pi() * (<span class="keyword">static_cast</span>&lt;in_out_t&gt;(ay) / H + <span class="keyword">static_cast</span>&lt;in_out_t&gt;(ax) / W);
        sum_real += val_real * cos(a);
        <span class="keyword">if</span> ((H &gt; <span class="integer">1</span> &amp;&amp; (ay % (H/<span class="integer">2</span>)) &gt; <span class="integer">0</span>) || (W &gt; <span class="integer">1</span> &amp;&amp; (ax % (W/<span class="integer">2</span>)) &gt; <span class="integer">0</span>)) {
            sum_imag += -val_real * sin(a);
        } <span class="keyword">else</span> <span class="keyword">if</span> (tosa_extra_multiplies) {
            sum_imag += -val_real * <span class="float">0</span><span class="float">.0</span>;
        }
    }
    tensor_write&lt;in_out_t&gt;(output_real, [N,H,W], [n,oy,ox], sum_real);
    tensor_write&lt;in_out_t&gt;(output_imag, [N,H,W], [n,oy,ox], sum_imag);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_transpose_conv2d">2.3.10. TRANSPOSE_CONV2D</h4>
<div class="paragraph">
<p>Performs a 2D transposed convolution over the given tensor input, using the weights tensor.
Implementations may choose to skip calculation of multiplies by zero at fractional input positions.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Integer results must be exact.</p>
</div>
<div class="paragraph">
<p>The following rules apply to floating-point inputs:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Subnormal bf16_t, fp16_t, and fp32_t input values may be flushed to zero before calculation.</p>
</li>
<li>
<p>Each output can be expressed as a dot product of two input vectors.</p>
</li>
<li>
<p>The dot product must meet the <a href="#_dot_product_accuracy_requirements">Dot product accuracy requirements</a>.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,IH,IW,IC]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;weight_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">weight</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[OC,KH,KW,IC]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Weight kernel size KH x KW</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bias</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[BC]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Per output channel bias data.<br>
            Bias data will be broadcast if BC == 1.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[1]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor zero point. Must be zero for non-int8 types.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;weight_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">weight_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[1]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Weight zero point. Must be zero for non-int8 types.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;i32_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">out_pad</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[4]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[out_pad_top, out_pad_bottom, out_pad_left, out_pad_right]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;i32_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">stride</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[2]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[stride_y, stride_x]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">acc_type_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">acc_type</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Enumerated type, must be one of INT32, INT48, FP16, FP32 matching the type of acc_t in the Supported Data Types table for this operation</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">local_bound</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">This optional attribute affects the floating-point compliance error bound.
                The default of false allows for direct and transform based, fast convolution algorithms.
                Only set to true if direct dot-product calculation precision is required.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,OH,OW,OC]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Compile Time Constant Status:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">CTC enabled profile(s)</th>
<th class="tableblock halign-left valign-top">CTC disabled extension(s)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">input_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT, PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-DYNAMIC</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">weight_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT, PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-DYNAMIC</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_t</th>
<th class="tableblock halign-left valign-top">weight_t</th>
<th class="tableblock halign-left valign-top">out_t</th>
<th class="tableblock halign-left valign-top">acc_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 with fp16 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8x8 with int32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E4M3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3 with fp16 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E5M2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2 with fp16 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-INT16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16x8 with int48 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i48_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i48_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-INT4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8x4 with int32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i4_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(KH &lt;= MAX_KERNEL);
LEVEL_CHECK(KW &lt;= MAX_KERNEL);
LEVEL_CHECK(out_pad_top &lt;= MAX_KERNEL);
LEVEL_CHECK(out_pad_bottom &lt;= MAX_KERNEL);
LEVEL_CHECK(out_pad_left &lt;= MAX_KERNEL);
LEVEL_CHECK(out_pad_right &lt;= MAX_KERNEL);
LEVEL_CHECK(stride_y &lt;= MAX_STRIDE);
LEVEL_CHECK(stride_x &lt;= MAX_STRIDE);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">ERROR_IF(!is_same&lt;in_t,i8_t&gt;() &amp;&amp; input_zp != <span class="integer">0</span>); <span class="comment">// Zero point only allowed for int8_t</span>
ERROR_IF(!is_same&lt;weight_t,i8_t&gt;() &amp;&amp; weight_zp != <span class="integer">0</span>);
ERROR_IF(out_pad_top &lt;= -KH || out_pad_bottom &lt;= -KH);
ERROR_IF(out_pad_left &lt;= -KW || out_pad_right &lt;= -KW);
ERROR_IF(stride_y &lt; <span class="integer">1</span> || stride_x &lt; <span class="integer">1</span>);
ERROR_IF(OH != (IH - <span class="integer">1</span>) * stride_y + out_pad_top + out_pad_bottom + KH);
ERROR_IF(OW != (IW - <span class="integer">1</span>) * stride_x + out_pad_left + out_pad_right + KW);
ERROR_IF(BC != OC &amp;&amp; BC != <span class="integer">1</span>);

for_each(<span class="integer">0</span> &lt;= n &lt; N, <span class="integer">0</span> &lt;= oy &lt; OH, <span class="integer">0</span> &lt;= ox &lt; OW, <span class="integer">0</span> &lt;= oc &lt; OC) {
    acc_t acc = <span class="integer">0</span>;
    tensor_size_t iy = oy - out_pad_top;
    tensor_size_t ix = ox - out_pad_left;
    for_each(<span class="integer">0</span> &lt;= ky &lt; KH, <span class="integer">0</span> &lt;= kx &lt; KW, <span class="integer">0</span> &lt;= ic &lt; IC) {
        tensor_size_t y = iy - ky;
        tensor_size_t x = ix - kx;
        acc_t value = <span class="integer">0</span>;
        <span class="keyword">if</span> (<span class="integer">0</span> &lt;= y &lt; IH * stride_y &amp;&amp; <span class="integer">0</span> &lt;= x &lt; IW * stride_x &amp;&amp; (y % stride_y)==<span class="integer">0</span> &amp;&amp; (x % stride_x)==<span class="integer">0</span>) {
            value  = <span class="keyword">static_cast</span>&lt;acc_t&gt;(tensor_read&lt;in_t&gt;(input,
                                                          [N,IH,IW,IC],
                                                          [n,y/stride_y,x/stride_x,ic]));
            value  = apply_sub_s&lt;acc_t&gt;(value, <span class="keyword">static_cast</span>&lt;acc_t&gt;(input_zp));
        }
        <span class="keyword">if</span> ((<span class="integer">0</span> &lt;= y &lt; IH * stride_y &amp;&amp; <span class="integer">0</span> &lt;= x &lt; IW * stride_x &amp;&amp; (y % stride_y)==<span class="integer">0</span> &amp;&amp; (x % stride_x)==<span class="integer">0</span>) || tosa_extra_multiplies) {
            acc_t weight_el = <span class="keyword">static_cast</span>&lt;acc_t&gt;(tensor_read&lt;weight_t&gt;(weight,
                                                                      [OC,KH,KW,IC],
                                                                      [oc,ky,kx,ic]));
            weight_el = apply_sub_s&lt;acc_t&gt;(weight_el, <span class="keyword">static_cast</span>&lt;acc_t&gt;(weight_zp));
            acc = apply_add_s&lt;acc_t&gt;(acc, apply_mul_s&lt;acc_t&gt;(value, weight_el));
        }
    }
    out_t out = <span class="keyword">static_cast</span>&lt;out_t&gt;(acc);
    out = apply_add_s&lt;out_t&gt;(out, bias[(BC == <span class="integer">1</span>) ? <span class="integer">0</span> : oc]);
    tensor_write&lt;out_t&gt;(output, [N,OH,OW,OC], [n,oy,ox,oc], out);
}</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_activation_functions">2.4. Activation Functions</h3>
<div class="sect3">
<h4 id="_clamp">2.4.1. CLAMP</h4>
<div class="paragraph">
<p>Clamp to an arbitrary minimum and maximum value.
Maximum and minimum values are specified as values in the range of the input type.
No zero point subtraction is done to the values, thus to clamp to the zero point value, the zero point itself should be supplied as the minimum value.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Integer results must be exact.</p>
</div>
<div class="paragraph">
<p>NaN propagation mode only affects floating-point types.
It indicates either propagating or ignoring NaN.</p>
</div>
<div class="paragraph">
<p>The following rules apply to floating-point inputs:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Comparison rules:</p>
<div class="ulist">
<ul>
<li>
<p>The sign of a zero is ignored.</p>
</li>
<li>
<p>Infinities of the same sign compare as equal.</p>
</li>
<li>
<p>In the NaN propagating mode, if the input is a NaN, the output must be a NaN.</p>
</li>
<li>
<p>In the NaN ignoring mode, if the input is a NaN, the output is the specified minimum value.</p>
</li>
</ul>
</div>
</li>
<li>
<p>bf16_t, fp16_t, and fp32_t subnormal values may be flushed to zero before computation.</p>
</li>
<li>
<p>If a floating-point result is zero, then the result must be either +0.0 or -0.0 but either sign is permitted.</p>
</li>
<li>
<p>If the result is a subnormal value for bf16_t, fp16_t, or fp32_t, the result may be a zero of either sign.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">min_val</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum clip value</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">max_val</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum clip value</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">nan_propagation_mode_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">nan_mode</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PROPAGATE or IGNORE. Set to PROPAGATE by default.
                This attribute affects the floating-point NaN propagation approach. This attribute is ignored by non floating-point types.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type and shape as input</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-INT16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">ERROR_IF(max_val &lt; min_val);
ERROR_IF(isNaN(min_val) || isNaN(max_val));
for_each_data_position(index in shape) {
    in_out_t value = tensor_read&lt;in_out_t&gt;(input, shape, index);
    value = apply_clip_s&lt;in_out_t&gt;(value, min_val, max_val, nan_mode);
    tensor_write&lt;in_out_t&gt;(output, shape, index, value);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_erf">2.4.2. ERF</h4>
<div class="paragraph">
<p>Error function:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="/assets/images/erf.svg" alt="Error function">
</div>
<div class="title">Figure 3. Calculation for the error function</div>
</div>
<div class="paragraph">
<p>For quantized integer data types, the TABLE operator should be used instead with
the following definition.</p>
</div>
<div class="paragraph">
<p>The ERF table has 513 entries each of 16-bit precision and covering the input range -4.0 to +4.0 in steps of 1/64.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">int16_t erf_reference(int16_t x) { <span class="comment">// input x range is -256 to + 256 inclusive</span>
    fp64_t v = <span class="keyword">static_cast</span>&lt;fp64_t&gt;(x) / <span class="keyword">static_cast</span>&lt;fp64_t&gt;(<span class="integer">64</span>);
    v = erf(v);
    <span class="keyword">return</span> round_to_nearest_int(<span class="integer">3276</span><span class="float">8</span><span class="float">.0</span> * v);
}

generate_lookup_table(&amp;erf_table, &amp;erf_reference);</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Subnormal bf16_t, fp16_t, and fp32_t input values may be flushed to zero before calculation.</p>
</li>
<li>
<p>The following may be used to validate the result:</p>
<div class="ulist">
<ul>
<li>
<p>Let <code>out_imp</code> be the implementation output.</p>
</li>
<li>
<p>Let <code>out_ref</code> be the result calculated using fp64_t arithmetic.</p>
</li>
<li>
<p>Then <code>tosa_reference_check_fp&lt;in_t&gt;(out_imp, out_ref, 5)</code> must be true.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type and shape as input</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">for_each_data_position(index in shape) {
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input, shape, index);
    in_out_t value = erf&lt;in_out_t&gt;(value1);
    tensor_write&lt;in_out_t&gt;(output, shape, index, value);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_sigmoid">2.4.3. SIGMOID</h4>
<div class="paragraph">
<p>Applies the sigmoid logistic function to each element of the input tensor.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="/assets/images/sigmoid.svg" alt="Sigmoid definition">
</div>
<div class="title">Figure 4. Calculation for the sigmoid function</div>
</div>
<div class="paragraph">
<p>For quantized integer data types, the TABLE operator should be used instead.
Each implementation may choose an appropriate TABLE given the scale and zero point of the input data.
Eight or sixteen bit precision tables may be used based on the input tensor to the sigmoid function.
Below we give an example table generation for 16-bit sigmoid.
This sigmoid table has 513 entries each of 16-bit precision and covering the input range -16.0 to +16.0 in steps of 1/16.</p>
</div>
<div class="listingblock">
<div class="title">Code for generating 16-bit sigmoid table</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">int16_t sigmoid_reference(int16_t x) { <span class="comment">// input x range is -256 to + 256 inclusive</span>
    fp64_t v = <span class="keyword">static_cast</span>&lt;fp64_t&gt;(x) / <span class="keyword">static_cast</span>&lt;fp64_t&gt;(<span class="integer">16</span>);
    v = <span class="float">1</span><span class="float">.0</span>/(<span class="float">1</span><span class="float">.0</span> + exp(-v));
    <span class="keyword">return</span> round_to_nearest_int(<span class="integer">3276</span><span class="float">8</span><span class="float">.0</span> * v);
}

generate_lookup_table(&amp;sigmoid_table, &amp;sigmoid_reference);</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Subnormal bf16_t, fp16_t, and fp32_t input values may be flushed to zero before calculation.</p>
</li>
<li>
<p>Infinity, NaN, and Zero behavior as defined in the following table.</p>
</li>
<li>
<p>Otherwise the following may be used to validate the result:</p>
<div class="ulist">
<ul>
<li>
<p>Let <code>x</code> be an input element.</p>
</li>
<li>
<p>Let <code>out_imp</code> be the implementation output.</p>
</li>
<li>
<p>Let <code>out_ref</code> be the result calculated using fp64_t arithmetic.</p>
</li>
<li>
<p>Let <code>err_bnd = calcAbsErrorBound&lt;in_out_t&gt;(out_ref, 2 * (1+abs(x)), 0, 1)</code>.</p>
</li>
<li>
<p>Then <code>tosa_reference_check_fp_bnd&lt;in_out_t&gt;(out_imp, out_ref, err_bnd)</code> must be true.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type and shape as input</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Floating-point behavior:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Input</th>
<th class="tableblock halign-left valign-top">-infinity</th>
<th class="tableblock halign-left valign-top">+infinity</th>
<th class="tableblock halign-left valign-top">-0</th>
<th class="tableblock halign-left valign-top">+0</th>
<th class="tableblock halign-left valign-top">NaN</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.5</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.5</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">any NaN</p></td>
</tr>
</tbody>
</table>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">for_each_data_position(index in shape) {
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input, shape, index);
    in_out_t value = sigmoid&lt;in_out_t&gt;(value1);
    tensor_write&lt;in_out_t&gt;(output, shape, index, value);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_tanh">2.4.4. TANH</h4>
<div class="paragraph">
<p>Parameterized hyperbolic tangent.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="/assets/images/tanh.svg" alt="Hyperbolic tangent definition">
</div>
<div class="title">Figure 5. Calculation for the tanh function</div>
</div>
<div class="paragraph">
<p>For quantized integer data types, the TABLE operator should be used instead.
Each implementation may choose an appropriate TABLE given the scale and zero point of the input data.
Eight or sixteen bit precision tables may be used based on the input tensor to the tanh function.
Below we give an example table generation for 16-bit hyperbolic tangent.
This tanh table has 513 entries each of 16-bit precision and covering the input range -8.0 to +8.0 in steps of 1/32.</p>
</div>
<div class="listingblock">
<div class="title">Calculation of an example 16-bit tanh table</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">int16_t tanh_reference(int16_t x) {  <span class="comment">// input x range is -256 to +256 inclusive</span>
    fp64_t v = <span class="keyword">static_cast</span>&lt;fp64_t&gt;(x) / <span class="keyword">static_cast</span>&lt;fp64_t&gt;(<span class="integer">32</span>);
    v = exp(-<span class="float">2</span><span class="float">.0</span>*v);
    v = (<span class="float">1</span><span class="float">.0</span>-v)/(<span class="float">1</span><span class="float">.0</span>+v);
    <span class="keyword">return</span> round_to_nearest_int(<span class="integer">3276</span><span class="float">8</span><span class="float">.0</span> * v);
}

generate_lookup_table(&amp;tanh_table, &amp;tanh_reference);</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Subnormal bf16_t, fp16_t, and fp32_t input values may be flushed to zero before calculation.</p>
</li>
<li>
<p>Infinity, NaN, and Zero behavior as defined in the following table.</p>
</li>
<li>
<p>Otherwise the following may be used to validate the result:</p>
<div class="ulist">
<ul>
<li>
<p>Let <code>x</code> be an input element.</p>
</li>
<li>
<p>Let <code>out_imp</code> be the implementation output.</p>
</li>
<li>
<p>Let <code>out_ref</code> be the result calculated using fp64_t arithmetic.</p>
<div class="ulist">
<ul>
<li>
<p>Note (informational): The error bound is derived from the error bound for the exp operator based on implementation of TANH as <code>(exp(x) - exp(-x)) / (exp(x) + exp(-x))</code>.</p>
</li>
<li>
<p>The absolute lower bound of 0.5 ulp relative to 1.0 is due to <code>exp(x) - exp(-x)</code> having an error of this magnitude when x is close to 0.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Let <code>exp_err_base = is_same&lt;in_out_t, fp32_t&gt;() ? 3 : 1</code>.</p>
</li>
<li>
<p>Let <code>err_bnd = calcAbsErrorBound&lt;in_out_t&gt;(out_ref, 4 * (exp_err_base + 2 * abs(x)), 0.5, 1)</code>.</p>
</li>
<li>
<p>Then <code>tosa_reference_check_fp_bnd&lt;in_out_t&gt;(out_imp, out_ref, err_bnd)</code> must be true.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type and shape as input</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Floating-point behavior:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Input</th>
<th class="tableblock halign-left valign-top">-infinity</th>
<th class="tableblock halign-left valign-top">+infinity</th>
<th class="tableblock halign-left valign-top">-0</th>
<th class="tableblock halign-left valign-top">+0</th>
<th class="tableblock halign-left valign-top">NaN</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">any NaN</p></td>
</tr>
</tbody>
</table>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">for_each_data_position(index in shape) {
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input, shape, index);
    in_out_t value = tanh&lt;in_out_t&gt;(value1);
    tensor_write&lt;in_out_t&gt;(output, shape, index, value);
}</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_elementwise_binary_operators">2.5. Elementwise Binary Operators</h3>
<div class="sect3">
<h4 id="_add">2.5.1. ADD</h4>
<div class="paragraph">
<p>Elementwise addition of input1 and input2.
Axis of size 1 will be broadcast, as necessary. Rank of input tensors must match.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Integer results must be exact.</p>
</div>
<div class="paragraph">
<p>The following rules apply to floating-point inputs:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>If any input is a NaN, the result must be a NaN.</p>
</li>
<li>
<p>Addition of infinities of different signs must produce a NaN.</p>
</li>
<li>
<p>Subnormal bf16_t, fp16_t, and fp32_t input values may be flushed to zero before calculation.</p>
</li>
<li>
<p>Subnormal bf16_t, fp16_t, and fp32_t result values may be flushed to zero of the appropriate sign after the calculation.</p>
</li>
<li>
<p>The following may be used to validate the result:</p>
<div class="ulist">
<ul>
<li>
<p>Let <code>out_imp</code> be the implementation output.</p>
</li>
<li>
<p>Let <code>out_ref</code> be the result calculated using fp64_t arithmetic.</p>
</li>
<li>
<p>Then <code>tosa_reference_check_fp&lt;in_t&gt;(out_imp, out_ref, 0.5)</code> must be true.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with the same rank as input1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT or PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">ERROR_IF(shape != broadcast_shape(shape1, shape2));
for_each_data_position(index in shape) {
    shape_t index1 = apply_broadcast(shape, shape1, index);
    shape_t index2 = apply_broadcast(shape, shape2, index);
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape1, index1);
    in_out_t value2 = tensor_read&lt;in_out_t&gt;(input2, shape2, index2);
    in_out_t result = apply_add_s&lt;in_out_t&gt;(value1, value2);
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_arithmetic_right_shift">2.5.2. ARITHMETIC_RIGHT_SHIFT</h4>
<div class="paragraph">
<p>Elementwise arithmetic right shift of input1 by the amount specified in input2.
Axis of size 1 will be broadcast, as necessary. Rank of input tensors must match.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Results must be exact.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with the same rank as input1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">round</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">If true then the shift is rounded</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">ERROR_IF(shape != broadcast_shape(shape1, shape2));
for_each_data_position(index in shape) {
    shape_t index1 = apply_broadcast(shape, shape1, index);
    shape_t index2 = apply_broadcast(shape, shape2, index);
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape1, index1);
    in_out_t value2 = tensor_read&lt;in_out_t&gt;(input2, shape2, index2);

    <span class="comment">// Ensure that shift amount is appropriate for the data type</span>
    REQUIRE((is_same&lt;in_out_t,i32_t&gt;() &amp;&amp; <span class="integer">0</span> &lt;= value2 &amp;&amp; value2 &lt;= <span class="integer">31</span>) ||
            (is_same&lt;in_out_t,i16_t&gt;() &amp;&amp; <span class="integer">0</span> &lt;= value2 &amp;&amp; value2 &lt;= <span class="integer">15</span>) ||
            (is_same&lt;in_out_t,i8_t&gt;() &amp;&amp; <span class="integer">0</span> &lt;= value2 &amp;&amp; value2 &lt;= <span class="integer">7</span>));

    in_out_t result = apply_arith_rshift&lt;in_out_t&gt;(value1, value2);
    <span class="keyword">if</span> (round == <span class="predefined-constant">true</span> &amp;&amp; <span class="keyword">static_cast</span>&lt;int32_t&gt;(value2) &gt; <span class="integer">0</span> &amp;&amp;
        (apply_arith_rshift&lt;in_out_t&gt;(value1, apply_sub_s&lt;in_out_t&gt;(value2, <span class="integer">1</span>)) &amp; <span class="integer">1</span> != <span class="integer">0</span>)) {
        result = result + <span class="integer">1</span>;
    }
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_bitwise_and">2.5.3. BITWISE_AND</h4>
<div class="paragraph">
<p>Elementwise bitwise AND of input1 and input2.
Axis of size 1 will be broadcast as necessary. Rank of input tensors must match.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Results must be exact.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with the same rank as input1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">ERROR_IF(shape != broadcast_shape(shape1, shape2));
for_each_data_position(index in shape) {
    shape_t index1 = apply_broadcast(shape, shape1, index);
    shape_t index2 = apply_broadcast(shape, shape2, index);
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape1, index1);
    in_out_t value2 = tensor_read&lt;in_out_t&gt;(input2, shape2, index2);
    in_out_t result = value1 &amp; value2;
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_bitwise_or">2.5.4. BITWISE_OR</h4>
<div class="paragraph">
<p>Elementwise bitwise OR of input1 and input2.
Axis of size 1 will be broadcast as necessary. Rank of input tensors must match.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Results must be exact.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with the same rank as input1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">ERROR_IF(shape != broadcast_shape(shape1, shape2));
for_each_data_position(index in shape) {
    shape_t index1 = apply_broadcast(shape, shape1, index);
    shape_t index2 = apply_broadcast(shape, shape2, index);
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape1, index1);
    in_out_t value2 = tensor_read&lt;in_out_t&gt;(input2, shape2, index2);
    in_out_t result = value1 | value2;
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_bitwise_xor">2.5.5. BITWISE_XOR</h4>
<div class="paragraph">
<p>Elementwise bitwise XOR of input1 and input2.
Axis of size 1 will be broadcast as necessary. Rank of input tensors must match.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Results must be exact.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with the same rank as input1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">ERROR_IF(shape != broadcast_shape(shape1, shape2));
for_each_data_position(index in shape) {
    shape_t index1 = apply_broadcast(shape, shape1, index);
    shape_t index2 = apply_broadcast(shape, shape2, index);
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape1, index1);
    in_out_t value2 = tensor_read&lt;in_out_t&gt;(input2, shape2, index2);
    in_out_t result = value1 ^ value2;
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_intdiv">2.5.6. INTDIV</h4>
<div class="paragraph">
<p>Elementwise integer divide of input1 by input2.
Axis of size 1 will be broadcast as necessary.
Rank of input tensors must match.
The result of the divide is truncated towards zero.
Expected use is for operations on non-scaled integers.
Floating point divide should use RECIPROCAL and MUL.
Quantized integer divide should use TABLE (for 1/x) and MUL.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Results must be exact.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with the same rank as input1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT or PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">ERROR_IF(shape != broadcast_shape(shape1, shape2));
for_each_data_position(index in shape) {
    shape_t index1 = apply_broadcast(shape, shape1, index);
    shape_t index2 = apply_broadcast(shape, shape2, index);
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape1, index1);
    in_out_t value2 = tensor_read&lt;in_out_t&gt;(input2, shape2, index2);
    REQUIRE(value2 != <span class="integer">0</span>);
    in_out_t result = apply_intdiv_s&lt;in_out_t&gt;(value1, value2);
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_logical_and">2.5.7. LOGICAL_AND</h4>
<div class="paragraph">
<p>Elementwise logical AND of input1 and input2.
Axis of size 1 will be broadcast, as necessary. Rank of input tensors must match.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Results must be exact.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with the same rank as input1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT or PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">ERROR_IF(shape != broadcast_shape(shape1, shape2));
for_each_data_position(index in shape) {
    shape_t index1 = apply_broadcast(shape, shape1, index);
    shape_t index2 = apply_broadcast(shape, shape2, index);
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape1, index1);
    in_out_t value2 = tensor_read&lt;in_out_t&gt;(input2, shape2, index2);
    in_out_t result = value1 &amp;&amp; value2;
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_logical_left_shift">2.5.8. LOGICAL_LEFT_SHIFT</h4>
<div class="paragraph">
<p>Elementwise logical left-shift of input1 by the amount specified in input2.
Axis of size 1 will be broadcast, as necessary. Rank of input tensors must match.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Results must be exact.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with the same rank as input1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT or PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT or PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT or PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">ERROR_IF(shape != broadcast_shape(shape1, shape2));
for_each_data_position(index in shape) {
    shape_t index1 = apply_broadcast(shape, shape1, index);
    shape_t index2 = apply_broadcast(shape, shape2, index);
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape1, index1);
    in_out_t value2 = tensor_read&lt;in_out_t&gt;(input2, shape2, index2);
    <span class="comment">// Ensure that shift amount is appropriate for the data type</span>
    REQUIRE((is_same&lt;in_out_t,i32_t&gt;() &amp;&amp; <span class="integer">0</span> &lt;= value2 &amp;&amp; value2 &lt;= <span class="integer">31</span>) ||
            (is_same&lt;in_out_t,i16_t&gt;() &amp;&amp; <span class="integer">0</span> &lt;= value2 &amp;&amp; value2 &lt;= <span class="integer">15</span>) ||
            (is_same&lt;in_out_t,i8_t&gt;() &amp;&amp; <span class="integer">0</span> &lt;= value2 &amp;&amp; value2 &lt;= <span class="integer">7</span>));
    in_out_t result = value1 &lt;&lt; value2;
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_logical_right_shift">2.5.9. LOGICAL_RIGHT_SHIFT</h4>
<div class="paragraph">
<p>Elementwise logical right shift of input1 by the amount specified in input2.
Axis of size 1 will be broadcast, as necessary. Rank of input tensors must match.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Results must be exact.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with the same rank as input1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT or PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT or PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT or PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">ERROR_IF(shape != broadcast_shape(shape1, shape2));
for_each_data_position(index in shape) {
    shape_t index1 = apply_broadcast(shape, shape1, index);
    shape_t index2 = apply_broadcast(shape, shape2, index);
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape1, index1);
    in_out_t value2 = tensor_read&lt;in_out_t&gt;(input2, shape2, index2);

    <span class="comment">// Ensure that shift amount is appropriate for the data type</span>
    REQUIRE((is_same&lt;in_out_t,i32_t&gt;() &amp;&amp; <span class="integer">0</span> &lt;= value2 &amp;&amp; value2 &lt;= <span class="integer">31</span>) ||
            (is_same&lt;in_out_t,i16_t&gt;() &amp;&amp; <span class="integer">0</span> &lt;= value2 &amp;&amp; value2 &lt;= <span class="integer">15</span>) ||
            (is_same&lt;in_out_t,i8_t&gt;() &amp;&amp; <span class="integer">0</span> &lt;= value2 &amp;&amp; value2 &lt;= <span class="integer">7</span>));

    <span class="comment">// Logical shifts happen as unsigned types internally</span>
    in_out_t result = apply_logical_rshift&lt;in_out_t&gt;(value1, value2);
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_logical_or">2.5.10. LOGICAL_OR</h4>
<div class="paragraph">
<p>Elementwise logical OR of input1 and input2.
Axis of size 1 will be broadcast as necessary. Rank of input tensors must match.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Results must be exact.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with the same rank as input1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT or PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">ERROR_IF(shape != broadcast_shape(shape1, shape2));
for_each_data_position(index in shape) {
    shape_t index1 = apply_broadcast(shape, shape1, index);
    shape_t index2 = apply_broadcast(shape, shape2, index);
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape1, index1);
    in_out_t value2 = tensor_read&lt;in_out_t&gt;(input2, shape2, index2);
    in_out_t result = value1 || value2;
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_logical_xor">2.5.11. LOGICAL_XOR</h4>
<div class="paragraph">
<p>Elementwise logical XOR of input1 and input2.
Axis of size 1 will be broadcast as necessary. Rank of input tensors must match.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Results must be exact.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with the same rank as input1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT or PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">ERROR_IF(shape != broadcast_shape(shape1, shape2));
for_each_data_position(index in shape) {
    shape_t index1 = apply_broadcast(shape, shape1, index);
    shape_t index2 = apply_broadcast(shape, shape2, index);
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape1, index1);
    in_out_t value2 = tensor_read&lt;in_out_t&gt;(input2, shape2, index2);
    in_out_t result = value1 != value2;
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_maximum">2.5.12. MAXIMUM</h4>
<div class="paragraph">
<p>Elementwise max of input1 and input2.
Axis of size 1 will be broadcast, as necessary. Rank of input tensors must match.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Integer results must be exact.</p>
</div>
<div class="paragraph">
<p>NaN propagation mode only affects floating-point types.
It indicates either propagating or ignoring NaN.</p>
</div>
<div class="paragraph">
<p>The following rules apply to floating-point inputs:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Comparison rules:</p>
<div class="ulist">
<ul>
<li>
<p>The sign of a zero is ignored.</p>
</li>
<li>
<p>Infinities of the same sign compare as equal.</p>
</li>
<li>
<p>In the NaN propagating mode, if either input value is a NaN, the result is NaN.</p>
</li>
<li>
<p>In the NaN ignoring mode, if either input value is a NaN, the result is the non-NaN element.</p>
</li>
<li>
<p>If both values are NaN, the result is NaN.</p>
</li>
</ul>
</div>
</li>
<li>
<p>bf16_t, fp16_t, and fp32_t subnormal values may be flushed to zero before computation.</p>
</li>
<li>
<p>If a floating-point result is zero, then the result must be either +0.0 or -0.0 but either sign is permitted.</p>
</li>
<li>
<p>If the result is a subnormal value for bf16_t, fp16_t, or fp32_t, the result may be a zero of either sign.</p>
</li>
<li>
<p>If none of the above conditions apply, the floating-point result must be exact.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with the same rank as input1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">nan_propagation_mode_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">nan_mode</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PROPAGATE or IGNORE. Set to PROPAGATE by default.
                This attribute affects the floating-point NaN propagation approach. This attribute is ignored by non floating-point types.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">ERROR_IF(shape != broadcast_shape(shape1, shape2));
for_each_data_position(index in shape) {
    shape_t index1 = apply_broadcast(shape, shape1, index);
    shape_t index2 = apply_broadcast(shape, shape2, index);
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape1, index1);
    in_out_t value2 = tensor_read&lt;in_out_t&gt;(input2, shape2, index2);
    in_out_t result = apply_max_s&lt;in_out_t&gt;(value1, value2, nan_mode);
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_minimum">2.5.13. MINIMUM</h4>
<div class="paragraph">
<p>Elementwise minimum of input1 and input2.
Axis of size 1 will be broadcast, as necessary. Rank of input tensors must match.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Integer results must be exact.</p>
</div>
<div class="paragraph">
<p>NaN propagation mode only affects floating-point types.
It indicates either propagating or ignoring NaN.</p>
</div>
<div class="paragraph">
<p>The following rules apply to floating-point inputs:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Comparison rules:</p>
<div class="ulist">
<ul>
<li>
<p>The sign of a zero is ignored.</p>
</li>
<li>
<p>Infinities of the same sign compare as equal.</p>
</li>
<li>
<p>In the NaN propagating mode, if either input value is a NaN, the result is NaN.</p>
</li>
<li>
<p>In the NaN ignoring mode, if either input value is a NaN, the result is the non-NaN element.</p>
</li>
<li>
<p>If both values are NaN, the result is NaN.</p>
</li>
</ul>
</div>
</li>
<li>
<p>bf16_t, fp16_t, and fp32_t subnormal values may be flushed to zero before computation.</p>
</li>
<li>
<p>If a floating-point result is zero, then the result must be either +0.0 or -0.0 but either sign is permitted.</p>
</li>
<li>
<p>If the result is a subnormal value for bf16_t, fp16_t, or fp32_t, the result may be a zero of either sign.</p>
</li>
<li>
<p>If none of the above conditions apply, the floating-point result must be exact.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with the same rank as input1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">nan_propagation_mode_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">nan_mode</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PROPAGATE or IGNORE. Set to PROPAGATE by default.
                This attribute affects the floating-point NaN propagation approach. This attribute is ignored by non floating-point types.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">ERROR_IF(shape != broadcast_shape(shape1, shape2));
for_each_data_position(index in shape) {
    shape_t index1 = apply_broadcast(shape, shape1, index);
    shape_t index2 = apply_broadcast(shape, shape2, index);
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape1, index1);
    in_out_t value2 = tensor_read&lt;in_out_t&gt;(input2, shape2, index2);
    in_out_t result = apply_min_s(value1, value2, nan_mode);
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_mul">2.5.14. MUL</h4>
<div class="paragraph">
<p>Elementwise multiplication (Hadamard product) of input1 and input2.
Axis of size 1 will be broadcast, as necessary. Rank of input tensors must match.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Integer results must be exact.</p>
</div>
<div class="paragraph">
<p>The following rules apply to floating-point inputs:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>If any input is a NaN, the result must be a NaN.</p>
</li>
<li>
<p>Multiplication of an infinity by a zero must produce a NaN.</p>
</li>
<li>
<p>Multiplication of two infinities must produce an infinity of the correct sign.</p>
</li>
<li>
<p>Subnormal bf16_t, fp16_t, and fp32_t input values may be flushed to zero before calculation.</p>
</li>
<li>
<p>Subnormal bf16_t, fp16_t, and fp32_t result values may be flushed to zero of the appropriate sign after the calculation.</p>
</li>
<li>
<p>The following may be used to validate the result:</p>
<div class="ulist">
<ul>
<li>
<p>Let <code>out_imp</code> be the implementation output.</p>
</li>
<li>
<p>Let <code>out_ref</code> be the result calculated using fp64_t arithmetic.</p>
</li>
<li>
<p>Then <code>tosa_reference_check_fp&lt;in_t&gt;(out_imp, out_ref, 0.5)</code> must be true.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with the same rank as input1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;i8_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shift</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[1]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Result right shift (used only when in_t is i32_t)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Compile Time Constant Status:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">CTC enabled profile(s)</th>
<th class="tableblock halign-left valign-top">CTC disabled extension(s)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">shift</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT, PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-DYNAMIC</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_t</th>
<th class="tableblock halign-left valign-top">out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT or PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">REQUIRE(<span class="integer">0</span> &lt;= shift &amp;&amp; shift &lt;= <span class="integer">63</span>);
REQUIRE(is_same&lt;in_t,int32_t&gt;() || shift == <span class="integer">0</span>);
ERROR_IF(shape != broadcast_shape(shape1, shape2));
for_each_data_position(index in shape) {
    shape_t index1 = apply_broadcast(shape, shape1, index);
    shape_t index2 = apply_broadcast(shape, shape2, index);
    in_t value1 = tensor_read&lt;in_t&gt;(input1, shape1, index1);
    in_t value2 = tensor_read&lt;in_t&gt;(input2, shape2, index2);
    out_t result;
    <span class="keyword">if</span> (is_same&lt;in_t,i32_t&gt;() &amp;&amp; shift &gt; <span class="integer">0</span>) {
        int64_t product = sign_extend&lt;int64_t&gt;(value1) * sign_extend&lt;int64_t&gt;(value2);
        int64_t round   = <span class="keyword">static_cast</span>&lt;int64_t&gt;(<span class="integer">1</span>) &lt;&lt; (shift - <span class="integer">1</span>);
        product = (product + round) &gt;&gt; shift;
        REQUIRE(product &gt;= minimum_s&lt;i32_t&gt;() &amp;&amp; product &lt;= maximum_s&lt;i32_t&gt;());
        result = <span class="keyword">static_cast</span>&lt;out_t&gt;(product);
    } <span class="keyword">else</span> {
        result = apply_mul_s&lt;out_t&gt;(<span class="keyword">static_cast</span>&lt;out_t&gt;(value1), <span class="keyword">static_cast</span>&lt;out_t&gt;(value2));  <span class="comment">// low 32-bits of result for i32_t</span>
    }
    tensor_write&lt;out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_pow">2.5.15. POW</h4>
<div class="paragraph">
<p>Elementwise input1 value raised to the power of input2.
Axis of size 1 will be broadcast, as necessary. Rank of input tensors must match.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Subnormal bf16_t, fp16_t, and fp32_t input values may be flushed to zero before calculation.</p>
</li>
<li>
<p>Otherwise the following may be used to validate the result.</p>
<div class="ulist">
<ul>
<li>
<p>Let <code>x</code>, <code>y</code> be input elements from <code>input1</code> and <code>input2</code> respectively.</p>
</li>
<li>
<p>Let <code>out_imp</code> be the implementation output.</p>
</li>
<li>
<p>If x or y is an infinity, the result is undefined.</p>
</li>
<li>
<p>If x or y is a NaN, the result is undefined.</p>
</li>
<li>
<p>If x &lt; 0, the result is undefined.</p>
</li>
<li>
<p>If x == 0 and y &#8656; 0, the result is undefined.</p>
</li>
<li>
<p>If x == 0 and y &gt; 0 then the result is 0.</p>
</li>
<li>
<p>If x &gt; 0 and y == 0 then the result is 1.</p>
</li>
<li>
<p>Otherwise:</p>
<div class="ulist">
<ul>
<li>
<p>Let <code>out_ref</code> be the result calculated using fp64_t arithmetic.</p>
</li>
<li>
<p>Note (informational): The error bound is derived from the error bound for the exp and log operators to allow implementation of pow as <code>exp(y * log(x))</code> for positive values of <code>x</code> and <code>y</code>.</p>
</li>
<li>
<p>Let <code>exp_err_base = is_same&lt;in_out_t, fp32_t&gt;&lt;&gt; ? 3 : 1</code>.</p>
</li>
<li>
<p>Let <code>err_bnd = calcAbsErrorBound&lt;in_out_t&gt;(out_ref, exp_err_base + 7.5 * abs(log(abs(x))*y), 0, 1)</code>.</p>
</li>
<li>
<p>Then <code>tosa_reference_check_fp_bnd&lt;in_out_t&gt;(out_imp, out_ref, err_bnd)</code> must be true.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with the same rank as input1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">ERROR_IF(shape != broadcast_shape(shape1, shape2));

for_each_data_position(index in shape) {
    shape_t index1 = apply_broadcast(shape, shape1, index);
    shape_t index2 = apply_broadcast(shape, shape2, index);
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape1, index1);
    in_out_t value2 = tensor_read&lt;in_out_t&gt;(input2, shape2, index2);
    REQUIRE(value1 &gt;= <span class="integer">0</span>);
    REQUIRE(value1 &gt; <span class="integer">0</span> || value2 &gt; <span class="integer">0</span>);
    REQUIRE(!isNaN(value1) &amp;&amp; !isNaN(value2));
    REQUIRE(is_finite(value1) &amp;&amp; is_finite(value2));
    in_out_t result = apply_pow&lt;in_out_t&gt;(value1, value2);
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_sub">2.5.16. SUB</h4>
<div class="paragraph">
<p>Elementwise subtraction of input1 and input2.
Axis of size 1 will be broadcast as necessary. Rank of input tensors must match.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Integer results must be exact.</p>
</div>
<div class="paragraph">
<p>The following rules apply to floating-point inputs:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>If any input is a NaN, the result must be a NaN.</p>
</li>
<li>
<p>Subnormal bf16_t, fp16_t, and fp32_t input values may be flushed to zero before calculation.</p>
</li>
<li>
<p>Subnormal bf16_t, fp16_t, and fp32_t result values may be flushed to zero of the appropriate sign after the calculation.</p>
</li>
<li>
<p>The following may be used to validate the result:</p>
<div class="ulist">
<ul>
<li>
<p>Let <code>out_imp</code> the implementation output.</p>
</li>
<li>
<p>Let <code>out_ref</code> be the result calculated using fp64_t arithmetic.</p>
</li>
<li>
<p>Then <code>tosa_reference_check_fp&lt;in_t&gt;(out_imp, out_ref, 0.5)</code> must be true.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with the same rank as input1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT or PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">ERROR_IF(shape != broadcast_shape(shape1, shape2));
for_each_data_position(index in shape) {
    shape_t index1 = apply_broadcast(shape, shape1, index);
    shape_t index2 = apply_broadcast(shape, shape2, index);
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape1, index1);
    in_out_t value2 = tensor_read&lt;in_out_t&gt;(input2, shape2, index2);
    in_out_t result = apply_sub_s&lt;in_out_t&gt;(value1, value2);
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_table">2.5.17. TABLE</h4>
<div class="paragraph">
<p>Table lookup operation.
For int8_t TABLE operation, perform a 256 entry table lookup returning an int8_t value.
For int16_t tables, the int16_t input is treated as a fixed-point 9.7 value.
The most significant 9 bits are used to index into the table.
The fractional 7 bits are used to interpolate based on table[index] and table[index+1].
For int16_t inputs, the TABLE operator returns a 16.7 interpolated value in an int32_t.
This value can then be input to the RESCALE operator to scale to the required output data type.
Note that int16_t table has 513 values to handle table[index+1] when index=511.</p>
</div>
<div class="paragraph">
<p>An int16_t to int16_t table lookup can be constructed in TOSA as follows:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Use the TABLE operator to produce a fixed point 16.7 interpolated result</p>
</li>
<li>
<p>Use RESCALE (in_t=int32_t, out_t=int16_t, scale=1&lt;&lt;14, shift=21) to scale the output to int16_t range (or alternate scale as required)</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Results must be exact.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;table_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">table</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[TABLE_SIZE]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Lookup table tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Compile Time Constant Status:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">CTC enabled profile(s)</th>
<th class="tableblock halign-left valign-top">CTC disabled extension(s)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">table</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-DYNAMIC</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_t</th>
<th class="tableblock halign-left valign-top">table_t</th>
<th class="tableblock halign-left valign-top">out_t</th>
<th class="tableblock halign-left valign-top">TABLE_SIZE</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">256</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-INT16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">513</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">REQUIRE(length(table) == TABLE_SIZE);
for_each_data_position(index in shape) {
    in_t value = tensor_read&lt;in_t&gt;(input1, shape, index);
    out_t result;
    <span class="keyword">if</span> (is_same&lt;in_t,i8_t&gt;()) {
        <span class="comment">// value is a signed int, convert to a 0 based index</span>
        result = table[<span class="keyword">static_cast</span>&lt;int16_t&gt;(value) + <span class="integer">128</span>];
    } <span class="keyword">else</span> {
        result = apply_lookup_s(<span class="keyword">static_cast</span>&lt;int16_t&gt;(table), <span class="keyword">static_cast</span>&lt;int16_t&gt;(value));
    }
    tensor_write&lt;out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_elementwise_unary_operators">2.6. Elementwise Unary Operators</h3>
<div class="sect3">
<h4 id="_abs">2.6.1. ABS</h4>
<div class="paragraph">
<p>Elementwise absolute value operation.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Integer results must be exact.</p>
</div>
<div class="paragraph">
<p>For floating-point values, in addition to the Floating-point behavior table, the following rules apply:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Subnormal bf16_t, fp16_t, and fp32_t input values may be flushed to zero before calculation.</p>
</li>
<li>
<p>Otherwise floating-point results must be exact.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type, size as the input tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Floating-point behavior:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Input</th>
<th class="tableblock halign-left valign-top">-infinity</th>
<th class="tableblock halign-left valign-top">+infinity</th>
<th class="tableblock halign-left valign-top">-0</th>
<th class="tableblock halign-left valign-top">+0</th>
<th class="tableblock halign-left valign-top">NaN</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">NaN</p></td>
</tr>
</tbody>
</table>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">for_each_data_position(index in shape) {
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape, index);
    <span class="keyword">if</span> (is_floating_point&lt;in_out_t&gt;() &amp;&amp; value1 == -<span class="float">0</span><span class="float">.0</span>) {
        value1 = <span class="float">0</span><span class="float">.0</span>;
    }
    <span class="keyword">if</span> (<span class="keyword">static_cast</span>&lt;int32_t&gt;(value1) &lt; <span class="float">0</span><span class="float">.0</span>) {
        value1 = apply_sub_s&lt;in_out_t&gt;(<span class="integer">0</span>, value1);
    }
    tensor_write&lt;in_out_t&gt;(output, shape, index, value1);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_bitwise_not">2.6.2. BITWISE_NOT</h4>
<div class="paragraph">
<p>Elementwise bitwise NOT of input tensor.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Results must be exact.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type, size as the input tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">for_each_data_position(index in shape) {
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape, index);
    in_out_t result = ~value1;
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_ceil">2.6.3. CEIL</h4>
<div class="paragraph">
<p>Elementwise ceiling operation</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Subnormal bf16_t, fp16_t, and fp32_t input values may be flushed to zero before calculation.</p>
</li>
<li>
<p>Infinity, NaN, and Zero behavior as defined in the following table.</p>
</li>
<li>
<p>The following may be used to validate the result:</p>
<div class="ulist">
<ul>
<li>
<p>Let <code>out_imp</code> the implementation output.</p>
</li>
<li>
<p>Let <code>out_ref</code> be the result calculated using fp64_t arithmetic.</p>
</li>
<li>
<p>Then <code>tosa_reference_check_fp&lt;in_t&gt;(out_imp, out_ref, 0.5)</code> must be true.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type, size as the input tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Floating-point behavior:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Input</th>
<th class="tableblock halign-left valign-top">-infinity</th>
<th class="tableblock halign-left valign-top">+infinity</th>
<th class="tableblock halign-left valign-top">-0</th>
<th class="tableblock halign-left valign-top">+0</th>
<th class="tableblock halign-left valign-top">NaN</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">any NaN</p></td>
</tr>
</tbody>
</table>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">for_each_data_position(index in shape) {
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape, index);
    in_out_t result = apply_ceil&lt;in_out_t&gt;(value1);
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_clz">2.6.4. CLZ</h4>
<div class="paragraph">
<p>Elementwise count leading zeros operation</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Results must be exact.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type, size as the input tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">for_each_data_position(index in shape) {
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape, index);
    in_out_t result = count_leading_zeros(value1);
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_cos">2.6.5. COS</h4>
<div class="paragraph">
<p>Elementwise cosine operation for values given in radians.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Subnormal bf16_t, fp16_t, and fp32_t input values may be flushed to zero before calculation.</p>
</li>
<li>
<p>Infinity, NaN, and Zero behavior as defined in the following table.</p>
</li>
<li>
<p>The following may be used to validate the result:</p>
<div class="ulist">
<ul>
<li>
<p>Let <code>x</code> be an input element.</p>
</li>
<li>
<p>Let <code>out_imp</code> the implementation output.</p>
</li>
<li>
<p>Let <code>out_ref</code> be the result calculated using fp64_t arithmetic.</p>
</li>
<li>
<p>Let <code>err_bnd = calcAbsErrorBound&lt;in_out_t&gt;(1+abs(x), 1, 0, 2)</code>.</p>
</li>
<li>
<p>Then <code>tosa_reference_check_fp_bnd&lt;in_out_t&gt;(out_imp, out_ref, err_bnd)</code> must be true.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type and shape as input</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Floating-point behavior:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Input</th>
<th class="tableblock halign-left valign-top">-infinity</th>
<th class="tableblock halign-left valign-top">+infinity</th>
<th class="tableblock halign-left valign-top">-0</th>
<th class="tableblock halign-left valign-top">+0</th>
<th class="tableblock halign-left valign-top">NaN</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">any NaN</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">any NaN</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">any NaN</p></td>
</tr>
</tbody>
</table>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">for_each_data_position(index in shape) {
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape, index);
    in_out_t value = cos&lt;in_out_t&gt;(value1);
    tensor_write&lt;in_out_t&gt;(output, shape, index, value);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_exp">2.6.6. EXP</h4>
<div class="paragraph">
<p>Elementwise e to the x operation</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Subnormal bf16_t, fp16_t, and fp32_t input values may be flushed to zero before calculation.</p>
</li>
<li>
<p>Infinity, NaN, and Zero behavior as defined in the following table.</p>
</li>
<li>
<p>The following may be used to validate the result:</p>
<div class="ulist">
<ul>
<li>
<p>Let <code>x</code> be an input element.</p>
</li>
<li>
<p>Let <code>out_imp</code> the implementation output.</p>
</li>
<li>
<p>Let <code>out_ref</code> be the result calculated using fp64_t arithmetic.</p>
</li>
<li>
<p>Let <code>err_base</code> be <code>is_same&lt;in_out_t, fp32_t&gt; ? 3 : 1</code>.</p>
</li>
<li>
<p>Let <code>err_bnd = calcAbsErrorBound&lt;in_out_t&gt;(out_ref, (err_base+2*abs(x)), 0, 1)</code>.</p>
</li>
<li>
<p>Then <code>tosa_reference_check_fp_bnd&lt;in_out_t&gt;(out_imp, out_ref, err_bnd)</code> must be true.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type, size as the input tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Floating-point behavior:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Input</th>
<th class="tableblock halign-left valign-top">-infinity</th>
<th class="tableblock halign-left valign-top">+infinity</th>
<th class="tableblock halign-left valign-top">-0</th>
<th class="tableblock halign-left valign-top">+0</th>
<th class="tableblock halign-left valign-top">NaN</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">any NaN</p></td>
</tr>
</tbody>
</table>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">for_each_data_position(index in shape) {
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape, index);
    in_out_t result = apply_exp&lt;in_out_t&gt;(value1);
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_floor">2.6.7. FLOOR</h4>
<div class="paragraph">
<p>Elementwise floor operation.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Subnormal bf16_t, fp16_t, and fp32_t input values may be flushed to zero before calculation.</p>
</li>
<li>
<p>Infinity, NaN, and Zero behavior as defined in the following table.</p>
</li>
<li>
<p>The following may be used to validate the result:</p>
<div class="ulist">
<ul>
<li>
<p>Let <code>out_imp</code> the implementation output.</p>
</li>
<li>
<p>Let <code>out_ref</code> be the result calculated using fp64_t arithmetic.</p>
</li>
<li>
<p>Then <code>tosa_reference_check_fp&lt;in_t&gt;(out_imp, out_ref, 0.5)</code> must be true.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type, size as the input tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Floating-point behavior:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Input</th>
<th class="tableblock halign-left valign-top">-infinity</th>
<th class="tableblock halign-left valign-top">+infinity</th>
<th class="tableblock halign-left valign-top">-0</th>
<th class="tableblock halign-left valign-top">+0</th>
<th class="tableblock halign-left valign-top">NaN</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">any NaN</p></td>
</tr>
</tbody>
</table>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">for_each_data_position(index in shape) {
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape, index);
    in_out_t result = apply_floor&lt;in_out_t&gt;(value1);
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_log">2.6.8. LOG</h4>
<div class="paragraph">
<p>Elementwise natural logarithm operation</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Subnormal bf16_t, fp16_t, and fp32_t input values may be flushed to zero before calculation.</p>
</li>
<li>
<p>Infinity, NaN, and Zero behavior as defined in the following table.</p>
</li>
<li>
<p>If the input to LOG is less than zero, then the result must be a NaN.</p>
</li>
<li>
<p>The following may be used to validate the result:</p>
<div class="ulist">
<ul>
<li>
<p>Let <code>out_imp</code> the implementation output.</p>
</li>
<li>
<p>Let <code>out_ref</code> be the result calculated using fp64_t arithmetic.</p>
</li>
<li>
<p>Let <code>err_bnd = calcAbsErrorBound&lt;in_out_t&gt;(out_ref, 5, 0.5, 1)</code>.</p>
</li>
<li>
<p>Then <code>tosa_reference_check_fp_bnd&lt;in_out_t&gt;(out_imp, out_ref, err_bnd)</code> must be true.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type, size as the input tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Floating-point behavior:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Input</th>
<th class="tableblock halign-left valign-top">-infinity</th>
<th class="tableblock halign-left valign-top">+infinity</th>
<th class="tableblock halign-left valign-top">-0</th>
<th class="tableblock halign-left valign-top">+0</th>
<th class="tableblock halign-left valign-top">NaN</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">any NaN</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">any NaN</p></td>
</tr>
</tbody>
</table>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">for_each_data_position(index in shape) {
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape, index);
    in_out_t result = apply_log&lt;in_out_t&gt;(value1);
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_logical_not">2.6.9. LOGICAL_NOT</h4>
<div class="paragraph">
<p>Elementwise logical NOT of input.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Results must be exact.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type, size as the input tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT or PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">for_each_data_position(index in shape) {
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape, index);
    in_out_t result = !value1;
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_negate">2.6.10. NEGATE</h4>
<div class="paragraph">
<p>Elementwise negation operation.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Integer Results must be exact.</p>
</div>
<div class="paragraph">
<p>For floating-point values, the following rules apply:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Subnormal bf16_t, fp16_t, and fp32_t input values may be flushed to zero before calculation.</p>
</li>
<li>
<p>Infinity, NaN, and Zero behavior as defined in the following table.</p>
</li>
<li>
<p>Otherwise floating-point results must be exact.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[1]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input 1 zero point. Must be zero for non-int8 types.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[1]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output zero point. Must be zero for non-int8 types.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type, size as the input tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Compile Time Constant Status:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">CTC enabled profile(s)</th>
<th class="tableblock halign-left valign-top">CTC disabled extension(s)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT, PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-DYNAMIC</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">output_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT, PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-DYNAMIC</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
<th class="tableblock halign-left valign-top">acc_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Floating-point behavior:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Input</th>
<th class="tableblock halign-left valign-top">-infinity</th>
<th class="tableblock halign-left valign-top">+infinity</th>
<th class="tableblock halign-left valign-top">-0</th>
<th class="tableblock halign-left valign-top">+0</th>
<th class="tableblock halign-left valign-top">NaN</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">any NaN</p></td>
</tr>
</tbody>
</table>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">ERROR_IF(!is_same&lt;in_out_t,i8_t&gt;() &amp;&amp; input1_zp != <span class="integer">0</span>); <span class="comment">// Zero point only for int8_t</span>
ERROR_IF(!is_same&lt;in_out_t,i8_t&gt;() &amp;&amp; output_zp != <span class="integer">0</span>); <span class="comment">// Zero point only for int8_t</span>
for_each_data_position(index in shape) {
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape, index);
    acc_t value = apply_sub_s&lt;acc_t&gt;(sign_extend&lt;acc_t&gt;(value1),
                                     sign_extend&lt;acc_t&gt;(input1_zp));
    value = apply_sub_s&lt;acc_t&gt;(<span class="integer">0</span>, value);
    value = apply_add_s&lt;acc_t&gt;(value, sign_extend&lt;acc_t&gt;(output_zp));
    in_out_t result = truncate&lt;in_out_t&gt;(apply_clip_s&lt;acc_t&gt;(value,
                                                             minimum_s&lt;in_out_t&gt;(),
                                                             maximum_s&lt;in_out_t&gt;()));
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_reciprocal">2.6.11. RECIPROCAL</h4>
<div class="paragraph">
<p>Elementwise reciprocal operation. For integer operation, a TABLE should be used with the appropriate ranges.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Subnormal bf16_t, fp16_t, and fp32_t input values may be flushed to zero before calculation.</p>
</li>
<li>
<p>Infinity, NaN, and Zero behave as defined in the following table.</p>
</li>
<li>
<p>Otherwise, the following may be used to validate the result:</p>
<div class="ulist">
<ul>
<li>
<p>Let <code>out_imp</code> the implementation output.</p>
</li>
<li>
<p>Let <code>out_ref</code> be the result calculated using fp64_t arithmetic.</p>
</li>
<li>
<p>Then <code>tosa_reference_check_fp&lt;in_t&gt;(out_imp, out_ref, 1)</code> must be true.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type, size as the input tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Floating-point behavior:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Input</th>
<th class="tableblock halign-left valign-top">-infinity</th>
<th class="tableblock halign-left valign-top">+infinity</th>
<th class="tableblock halign-left valign-top">-0</th>
<th class="tableblock halign-left valign-top">+0</th>
<th class="tableblock halign-left valign-top">NaN</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">any NaN</p></td>
</tr>
</tbody>
</table>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">for_each_data_position(index in shape) {
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape, index);
    in_out_t result = <span class="float">1</span><span class="float">.0</span> / value1;
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_rsqrt">2.6.12. RSQRT</h4>
<div class="paragraph">
<p>Elementwise reciprocal square root operation. For integer operation, a TABLE should be used with the appropriate ranges.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Subnormal bf16_t, fp16_t, and fp32_t input values may be flushed to zero before calculation.</p>
</li>
<li>
<p>Infinity, NaN, and Zero behave as defined in the following table.</p>
</li>
<li>
<p>Otherwise, the following may be used to validate the result:</p>
<div class="ulist">
<ul>
<li>
<p>Let <code>out_imp</code> the implementation output.</p>
</li>
<li>
<p>Let <code>out_ref</code> be the result calculated using fp64_t arithmetic.</p>
</li>
<li>
<p>Then <code>tosa_reference_check_fp&lt;in_t&gt;(out_imp, out_ref, 2)</code> must be true.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type, size as the input tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Floating-point behavior:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Input</th>
<th class="tableblock halign-left valign-top">-infinity</th>
<th class="tableblock halign-left valign-top">+infinity</th>
<th class="tableblock halign-left valign-top">-0</th>
<th class="tableblock halign-left valign-top">+0</th>
<th class="tableblock halign-left valign-top">any NaN</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">NaN</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">any NaN</p></td>
</tr>
</tbody>
</table>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">for_each_data_position(index in shape) {
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape, index);
    in_out_t result;
    <span class="keyword">if</span> (value1 &lt; <span class="integer">0</span>) {
        result = NaN;
    }
    <span class="keyword">else</span> {
        result = <span class="float">1</span><span class="float">.0</span> / apply_sqrt&lt;in_out_t&gt;(value1);
    }
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_sin">2.6.13. SIN</h4>
<div class="paragraph">
<p>Elementwise sine operation for values given in radians.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Subnormal bf16_t, fp16_t, and fp32_t input values may be flushed to zero before calculation.</p>
</li>
<li>
<p>Infinity, NaN, and Zero behavior as defined in the Floating-point behavior table.</p>
</li>
<li>
<p>Otherwise, the following may be used to validate the result:</p>
<div class="ulist">
<ul>
<li>
<p>Let <code>x</code> be an input element.</p>
</li>
<li>
<p>Let <code>out_imp</code> the implementation output.</p>
</li>
<li>
<p>Let <code>out_ref</code> be the result calculated using fp64_t arithmetic.</p>
</li>
<li>
<p>Let <code>err_bnd = max(calcAbsErrorBound&lt;in_out_t&gt;(x, 2, 0, 2), pi*normal_min&lt;in_out_t&gt;())</code>.</p>
</li>
<li>
<p>Then <code>tosa_reference_check_fp_bnd&lt;in_out_t&gt;(out_imp, out_ref, err_bnd)</code> must be true.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type and shape as input</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Floating-point behavior:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Input</th>
<th class="tableblock halign-left valign-top">-infinity</th>
<th class="tableblock halign-left valign-top">+infinity</th>
<th class="tableblock halign-left valign-top">-0</th>
<th class="tableblock halign-left valign-top">+0</th>
<th class="tableblock halign-left valign-top">NaN</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">any NaN</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">any NaN</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">any NaN</p></td>
</tr>
</tbody>
</table>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">for_each_data_position(index in shape) {
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape, index);
    in_out_t value = sin&lt;in_out_t&gt;(value1);
    tensor_write&lt;in_out_t&gt;(output, shape, index, value);
}</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_elementwise_ternary_operators">2.7. Elementwise Ternary Operators</h3>
<div class="sect3">
<h4 id="_select">2.7.1. SELECT</h4>
<div class="paragraph">
<p>Elementwise select of the output based on a condition.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Integer results must be exact.</p>
</div>
<div class="paragraph">
<p>For floating-point values in input2 and input3, the following rules apply:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Subnormal bf16_t, fp16_t, and fp32_t input values may be flushed to zero before calculation.</p>
</li>
<li>
<p>If an output is a NaN, any NaN is permitted.</p>
</li>
<li>
<p>Otherwise floating-point results must be exact.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;bool_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input selector tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input value tensor if input1 is True</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input value tensor if input1 is False</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type as input2 and input3</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT or PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">ERROR_IF(shape != broadcast_shape(broadcast_shape(shape1, shape2), shape3));
for_each_data_position(index in shape) {
    shape_t index1 = apply_broadcast(shape, shape1, index);
    shape_t index2 = apply_broadcast(shape, shape2, index);
    shape_t index3 = apply_broadcast(shape, shape3, index);
    bool_t value1 = tensor_read&lt;bool_t&gt;(input1, shape1, index1);
    in_out_t value2 = tensor_read&lt;in_out_t&gt;(input2, shape2, index2);
    in_out_t value3 = tensor_read&lt;in_out_t&gt;(input3, shape3, index3);
    in_out_t result;
    <span class="keyword">if</span> (value1) {
         result = value2;
    } <span class="keyword">else</span> {
         result = value3;
    }
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_comparison_operators">2.8. Comparison Operators</h3>
<div class="sect3">
<h4 id="_equal">2.8.1. EQUAL</h4>
<div class="paragraph">
<p>Elementwise comparison operation</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Integer results must be exact.</p>
</div>
<div class="paragraph">
<p>The following rules apply to floating-point inputs:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Comparison rules:</p>
<div class="ulist">
<ul>
<li>
<p>The sign of a zero is ignored.</p>
</li>
<li>
<p>Infinities of the same sign compare as equal.</p>
</li>
<li>
<p>If either or both input values are a NaN, the result is false.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Subnormal bf16_t, fp16_t, and fp32_t input values may be flushed to zero before calculation.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with the same rank as input1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_t</th>
<th class="tableblock halign-left valign-top">out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">ERROR_IF(shape != broadcast_shape(shape1, shape2));
for_each_data_position(index in shape) {
    shape_t index1 = apply_broadcast(shape, shape1, index);
    shape_t index2 = apply_broadcast(shape, shape2, index);
    in_t value1 = tensor_read&lt;in_t&gt;(input1, shape1, index1);
    in_t value2 = tensor_read&lt;in_t&gt;(input2, shape2, index2);
    out_t result;
    <span class="keyword">if</span> (isNaN(value1) || isNaN(value2))
        result = <span class="predefined-constant">false</span>;
    <span class="keyword">else</span>
        result = (value1 == value2) ? <span class="predefined-constant">true</span> : <span class="predefined-constant">false</span>;
    tensor_write&lt;out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_greater">2.8.2. GREATER</h4>
<div class="paragraph">
<p>Elementwise greater than comparison operation</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Integer results must be exact.</p>
</div>
<div class="paragraph">
<p>The following rules apply to floating-point inputs:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Comparison rules:</p>
<div class="ulist">
<ul>
<li>
<p>The sign of a zero is ignored.</p>
</li>
<li>
<p>Infinities of the same sign compare as equal.</p>
</li>
<li>
<p>If either or both input values are a NaN, the result is false.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Subnormal bf16_t, fp16_t, and fp32_t input values may be flushed to zero before calculation.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with the same rank as input1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_t</th>
<th class="tableblock halign-left valign-top">out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">ERROR_IF(shape != broadcast_shape(shape1, shape2));
for_each_data_position(index in shape) {
    shape_t index1 = apply_broadcast(shape, shape1, index);
    shape_t index2 = apply_broadcast(shape, shape2, index);
    in_t value1 = tensor_read&lt;in_t&gt;(input1, shape1, index1);
    in_t value2 = tensor_read&lt;in_t&gt;(input2, shape2, index2);
    out_t result;
    <span class="keyword">if</span> (isNaN(value1) || isNaN(value2))
        result = <span class="predefined-constant">false</span>;
    <span class="keyword">else</span>
        result = (value1 &gt; value2) ? <span class="predefined-constant">true</span> : <span class="predefined-constant">false</span>;
    tensor_write&lt;out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_greater_equal">2.8.3. GREATER_EQUAL</h4>
<div class="paragraph">
<p>Elementwise comparison operation</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Integer results must be exact.</p>
</div>
<div class="paragraph">
<p>The following rules apply to floating-point inputs:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Comparison rules:</p>
<div class="ulist">
<ul>
<li>
<p>The sign of a zero is ignored.</p>
</li>
<li>
<p>Infinities of the same sign compare as equal.</p>
</li>
<li>
<p>If either or both input values are a NaN, the result is false.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Subnormal bf16_t, fp16_t, and fp32_t input values may be flushed to zero before calculation.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with the same rank as input1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_t</th>
<th class="tableblock halign-left valign-top">out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">ERROR_IF(shape != broadcast_shape(shape1, shape2));
for_each_data_position(index in shape) {
    shape_t index1 = apply_broadcast(shape, shape1, index);
    shape_t index2 = apply_broadcast(shape, shape2, index);
    in_t value1 = tensor_read&lt;in_t&gt;(input1, shape1, index1);
    in_t value2 = tensor_read&lt;in_t&gt;(input2, shape2, index2);
    out_t result;
    <span class="keyword">if</span> (isNaN(value1) || isNaN(value2))
        result = <span class="predefined-constant">false</span>;
    <span class="keyword">else</span>
        result = (value1 &gt;= value2) ? <span class="predefined-constant">true</span> : <span class="predefined-constant">false</span>;
    tensor_write&lt;out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_reduction_operators">2.9. Reduction Operators</h3>
<div class="sect3">
<h4 id="_reduce_all">2.9.1. REDUCE_ALL</h4>
<div class="paragraph">
<p>Reduce a tensor along the given axis with a logical AND operation</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Results must be exact.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">axis</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Axis to reduce, in range from 0 to rank(shape1)-1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor. Same rank as the input tensor.</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT or PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c">ERROR_IF(axis &lt; <span class="integer">0</span>  || axis &gt;= rank(shape1));
ERROR_IF(shape[axis] != <span class="integer">1</span>);
shape_t left_shape  = (axis &gt; <span class="integer">1</span>) ? shape[<span class="integer">0</span>:axis-<span class="integer">1</span>] : [];
shape_t right_shape = (axis &lt; rank(shape)-<span class="integer">1</span>) ? shape[axis+<span class="integer">1</span>:rank(shape)-<span class="integer">1</span>] : [];
for_each_data_position(left_index in left_shape) {
    for_each_data_position(right_index in right_shape) {
        in_out_t acc = <span class="predefined-constant">true</span>;
        <span class="keyword">for</span> (tensor_size_t i = <span class="integer">0</span>; i &lt; shape1[axis]; i++) {
            shape_t index = flatten(left_index, [i], right_index);
            in_out_t value = tensor_read&lt;in_out_t&gt;(input, shape1, index);
            acc = acc &amp;&amp; value;
        }
        shape_t out_index = flatten(left_index, [<span class="integer">0</span>], right_index);
        tensor_write&lt;in_out_t&gt;(output, shape, out_index, acc);
    }
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_reduce_any">2.9.2. REDUCE_ANY</h4>
<div class="paragraph">
<p>Reduce a tensor along the given axis with a logical OR operation</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Results must be exact.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">axis</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Axis to reduce, in range from 0 to rank(shape1)-1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor. Same rank as the input tensor.</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT or PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c">ERROR_IF(axis &lt; <span class="integer">0</span>  || axis &gt;= rank(shape1));
ERROR_IF(shape[axis] != <span class="integer">1</span>);
shape_t left_shape  = (axis &gt; <span class="integer">1</span>) ? shape[<span class="integer">0</span>:axis-<span class="integer">1</span>] : [];
shape_t right_shape = (axis &lt; rank(shape)-<span class="integer">1</span>) ? shape[axis+<span class="integer">1</span>:rank(shape)-<span class="integer">1</span>] : [];
for_each_data_position(left_index in left_shape) {
    for_each_data_position(right_index in right_shape) {
        in_out_t acc = <span class="predefined-constant">false</span>;
        <span class="keyword">for</span> (tensor_size_t i = <span class="integer">0</span>; i &lt; shape1[axis]; i++) {
            shape_t index = flatten(left_index, [i], right_index);
            in_out_t value = tensor_read&lt;in_out_t&gt;(input, shape1, index);
            acc = acc || value;
        }
        shape_t out_index = flatten(left_index, [<span class="integer">0</span>], right_index);
        tensor_write&lt;in_out_t&gt;(output, shape, out_index, acc);
    }
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_reduce_max">2.9.3. REDUCE_MAX</h4>
<div class="paragraph">
<p>Reduce a tensor along the given axis with a maximum operation</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Integer results must be exact.</p>
</div>
<div class="paragraph">
<p>NaN propagation mode only affects floating-point types.
It indicates either propagating or ignoring NaN.</p>
</div>
<div class="paragraph">
<p>The following rules apply to floating-point inputs:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Comparison rules:</p>
<div class="ulist">
<ul>
<li>
<p>The sign of a zero is ignored.</p>
</li>
<li>
<p>Infinities of the same sign compare as equal.</p>
</li>
<li>
<p>In the NaN propagating mode, if any input value along the reduction axis is a NaN, the result is NaN.</p>
</li>
<li>
<p>In the NaN ignoring mode, if all input values along the reduction axis are NaN, the result is NaN.
Otherwise the result is the maximum non-NaN value.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Subnormal bf16_t, fp16_t, and fp32_t input values may be flushed to zero before calculation.</p>
</li>
<li>
<p>If a floating-point result is zero, then the result must be either +0.0 or -0.0 but either sign is permitted.</p>
</li>
<li>
<p>If the result is a subnormal value for bf16_t, fp16_t, or fp32_t, the result may be a zero of either sign.</p>
</li>
<li>
<p>Otherwise floating-point results must be exact.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">axis</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Axis to reduce, in range from 0 to rank(shape1)-1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">nan_propagation_mode_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">nan_mode</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PROPAGATE or IGNORE. Set to PROPAGATE by default.
                This attribute affects the floating-point NaN propagation approach. This attribute is ignored by non floating-point types.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor. Same rank as the input tensor.</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c">ERROR_IF(axis &lt; <span class="integer">0</span>  || axis &gt;= rank(shape1));
ERROR_IF(shape[axis] != <span class="integer">1</span>);
shape_t left_shape  = (axis &gt; <span class="integer">1</span>) ? shape[<span class="integer">0</span>:axis-<span class="integer">1</span>] : [];
shape_t right_shape = (axis &lt; rank(shape)-<span class="integer">1</span>) ? shape[axis+<span class="integer">1</span>:rank(shape)-<span class="integer">1</span>] : [];
for_each_data_position(left_index in left_shape) {
    for_each_data_position(right_index in right_shape) {
        in_out_t acc = (is_floating_point&lt;in_out_t&gt;() &amp;&amp; nan_mode == IGNORE)
                           ? nan&lt;in_out_t&gt;()
                           : minimum_s&lt;in_out_t&gt;();
        <span class="keyword">for</span> (tensor_size_t i = <span class="integer">0</span>; i &lt; shape1[axis]; i++) {
            shape_t index = flatten(left_index, [i], right_index);
            in_out_t value = tensor_read&lt;in_out_t&gt;(input, shape1, index);
            acc = apply_max_s&lt;in_out_t&gt;(acc, value, nan_mode);
        }
        shape_t out_index = flatten(left_index, [<span class="integer">0</span>], right_index);
        tensor_write&lt;in_out_t&gt;(output, shape, out_index, acc);
    }
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_reduce_min">2.9.4. REDUCE_MIN</h4>
<div class="paragraph">
<p>Reduce a tensor along the given axis with a minimum operation</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Integer results must be exact.</p>
</div>
<div class="paragraph">
<p>NaN propagation mode only affects floating-point types.
It indicates either propagating or ignoring NaN.</p>
</div>
<div class="paragraph">
<p>The following rules apply to floating-point inputs:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Comparison rules:</p>
<div class="ulist">
<ul>
<li>
<p>The sign of a zero is ignored.</p>
</li>
<li>
<p>Infinities of the same sign compare as equal.</p>
</li>
<li>
<p>In the NaN propagating mode, if any input value along the reduction axis is a NaN, the result is NaN.</p>
</li>
<li>
<p>In the NaN ignoring mode, if all input values along the reduction axis are NaN, the result is NaN.
Otherwise the result is the minimum non-NaN value.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Subnormal bf16_t, fp16_t, and fp32_t input values may be flushed to zero before calculation.</p>
</li>
<li>
<p>If a floating-point result is zero, then the result must be either +0.0 or -0.0 but either sign is permitted.</p>
</li>
<li>
<p>If the result is a subnormal value for bf16_t, fp16_t, or fp32_t, the result may be a zero of either sign.</p>
</li>
<li>
<p>Otherwise floating-point results must be exact.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">axis</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Axis to reduce, in range from 0 to rank(shape1)-1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">nan_propagation_mode_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">nan_mode</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PROPAGATE or IGNORE. Set to PROPAGATE by default.
                This attribute affects the floating-point NaN propagation approach. This attribute is ignored by non floating-point types.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor. Same rank as the input tensor.</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c">ERROR_IF(axis &lt; <span class="integer">0</span>  || axis &gt;= rank(shape1));
ERROR_IF(shape[axis] != <span class="integer">1</span>);
shape_t left_shape  = (axis &gt; <span class="integer">1</span>) ? shape[<span class="integer">0</span>:axis-<span class="integer">1</span>] : [];
shape_t right_shape = (axis &lt; rank(shape)-<span class="integer">1</span>) ? shape[axis+<span class="integer">1</span>:rank(shape)-<span class="integer">1</span>] : [];
for_each_data_position(left_index in left_shape) {
    for_each_data_position(right_index in right_shape) {
        in_out_t acc = (is_floating_point&lt;in_out_t&gt;() &amp;&amp; nan_mode == IGNORE)
                           ? nan&lt;in_out_t&gt;()
                           : maximum_s&lt;in_out_t&gt;();
        <span class="keyword">for</span> (tensor_size_t i = <span class="integer">0</span>; i &lt; shape1[axis]; i++) {
            shape_t index = flatten(left_index, [i], right_index);
            in_out_t value = tensor_read&lt;in_out_t&gt;(input, shape1, index);
            acc = apply_min_s&lt;in_out_t&gt;(acc, value, nan_mode);
        }
        shape_t out_index = flatten(left_index, [<span class="integer">0</span>], right_index);
        tensor_write&lt;in_out_t&gt;(output, shape, out_index, acc);
    }
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_reduce_product">2.9.5. REDUCE_PRODUCT</h4>
<div class="paragraph">
<p>Reduce a tensor along the given axis by computing the product of the axis.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Subnormal bf16_t, fp16_t, and fp32_t input values may be flushed to zero before calculation.</p>
</li>
<li>
<p>If the input is a NaN, the output must be a NaN.</p>
<div class="ulist">
<ul>
<li>
<p>Otherwise the following may be used to validate the result:</p>
</li>
<li>
<p>Let <code>n</code> be number of elements in the product.</p>
</li>
<li>
<p>Let <code>out_imp</code> be the implementation result.</p>
</li>
<li>
<p>Let <code>out_ref</code> be the result calculated using fp64_t arithmetic.</p>
</li>
<li>
<p>Let <code>err_bnd = max(abs(out_ref), normal_min&lt;in_out_t&gt;()) * (pow(1 + pow(2, -normal_frac&lt;in_out_t&gt;() - 1), n) - 1)</code>.</p>
</li>
<li>
<p>Then <code>tosa_reference_check_fp_bnd&lt;in_out_t&gt;(out_imp, out_ref, err_bnd)</code> must be true.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">axis</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Axis to reduce, in range from 0 to rank(shape1)-1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor. Same rank as the input tensor.</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c">ERROR_IF(axis &lt; <span class="integer">0</span>  || axis &gt;= rank(shape1));
ERROR_IF(shape[axis] != <span class="integer">1</span>);
shape_t left_shape  = (axis &gt; <span class="integer">1</span>) ? shape[<span class="integer">0</span>:axis-<span class="integer">1</span>] : [];
shape_t right_shape = (axis &lt; rank(shape)-<span class="integer">1</span>) ? shape[axis+<span class="integer">1</span>:rank(shape)-<span class="integer">1</span>] : [];
for_each_data_position(left_index in left_shape) {
    for_each_data_position(right_index in right_shape) {
        in_out_t acc = <span class="float">1</span><span class="float">.0</span>;
        <span class="keyword">for</span> (tensor_size_t i = <span class="integer">0</span>; i &lt; shape1[axis]; i++) {
            shape_t index = flatten(left_index, [i], right_index);
            in_out_t value = tensor_read&lt;in_out_t&gt;(input, shape1, index);
            acc = apply_mul_s&lt;in_out_t&gt;(acc, value);
        }
        shape_t out_index = flatten(left_index, [<span class="integer">0</span>], right_index);
        tensor_write&lt;in_out_t&gt;(output, shape, out_index, acc);
    }
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_reduce_sum">2.9.6. REDUCE_SUM</h4>
<div class="paragraph">
<p>Reduce a tensor along the given axis by computing the sum of the axis.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Integer results must be exact.</p>
</div>
<div class="paragraph">
<p>Floating-point outputs can be expressed as a dot product of an input vector with a vector of ones.
This dot product must meet the <a href="#_dot_product_accuracy_requirements">Dot product accuracy requirements</a>.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">axis</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Axis to reduce, in range from 0 to rank(shape1)-1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor. Same rank as the input tensor.</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
<th class="tableblock halign-left valign-top">acc_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c">ERROR_IF(axis &lt; <span class="integer">0</span>  || axis &gt;= rank(shape1));
ERROR_IF(shape[axis] != <span class="integer">1</span>);
shape_t left_shape  = (axis &gt; <span class="integer">1</span>) ? shape[<span class="integer">0</span>:axis-<span class="integer">1</span>] : [];
shape_t right_shape = (axis &lt; rank(shape)-<span class="integer">1</span>) ? shape[axis+<span class="integer">1</span>:rank(shape)-<span class="integer">1</span>] : [];
for_each_data_position(left_index in left_shape) {
    for_each_data_position(right_index in right_shape) {
        acc_t acc = <span class="integer">0</span>;
        <span class="keyword">for</span> (tensor_size_t i = <span class="integer">0</span>; i &lt; shape1[axis]; i++) {
            shape_t index = flatten(left_index, [i], right_index);
            acc_t value = tensor_read&lt;in_out_t&gt;(input, shape1, index);
            acc = apply_add_s&lt;acc_t&gt;(acc, value);
        }
        shape_t out_index = flatten(left_index, [<span class="integer">0</span>], right_index);
        in_out_t result = static_cast&lt;in_out_t&gt;(acc);
        tensor_write&lt;in_out_t&gt;(output, shape, out_index, result);
    }
}</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_data_layout">2.10. Data Layout</h3>
<div class="sect3">
<h4 id="_concat">2.10.1. CONCAT</h4>
<div class="paragraph">
<p>Concatenate a list of tensors along a given axis.
No data conversion happens during a concat operation.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Results must be exact.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">tensor_list_t&lt;T&lt;in_out_t&gt;&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shapes1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">List of input tensors. All inputs must have the same rank and data type</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">axis</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Axis along which concatenation is to occur, in range from 0 to rank(shape)-1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT or PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E4M3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E5M2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-INT16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(tensor_list_shape(input1) &lt;= MAX_TENSOR_LIST_SIZE);
LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c">ERROR_IF(input1 == []); <span class="comment">// There must be at least one input in the input list</span>
ERROR_IF(axis &lt; <span class="integer">0</span> || axis &gt;= max(<span class="integer">1</span>,rank(shapes1[<span class="integer">0</span>])));

<span class="comment">// The following checks ensure all inputs are compatible for concatenation</span>
<span class="comment">// Iterate over each shape and dimension</span>
<span class="comment">// All shapes must have the same rank</span>
<span class="comment">// If the dimension is the axis dimension, sum the size of this dimension to check</span>
<span class="comment">// that the size of the output equals the size of the concatenated shapes</span>
<span class="comment">// For all other dimensions, the size must match for all inputs</span>

tensor_size_t axis_sum = <span class="integer">0</span>;
<span class="keyword">for</span> (int32_t shape_index = <span class="integer">0</span>; shape_index &lt; length(shapes1); shape_index++) {
    ERROR_IF(rank(shapes1[shape_index]) != rank(shapes1[<span class="integer">0</span>]));
    <span class="keyword">for</span> (int32_t axis_index = <span class="integer">0</span>; axis_index &lt; length(shapes1[<span class="integer">0</span>]); axis_index++) {
        <span class="keyword">if</span> (axis_index == axis) {
            axis_sum += shapes1[shape_index][axis_index];
        }
        <span class="keyword">else</span> {
            ERROR_IF(shapes1[shape_index][axis_index] != shapes1[<span class="integer">0</span>][axis_index]);
        }
    }
}
ERROR_IF(axis_sum != shape[axis]);

for_each_data_position(index1 in shape) {
    shape_t index2 = index1;
    <span class="keyword">for</span> (int32_t t = <span class="integer">0</span>; t &lt; length(input1); t++) {
        <span class="comment">// Continue to concatenate along axis from each tensor</span>
        <span class="comment">// For each output location, we are looking for the</span>
        <span class="comment">// appropriate input tensor</span>
        <span class="keyword">if</span> (index2[axis] &gt;= <span class="integer">0</span> &amp;&amp; index2[axis] &lt; shape_dim(shapes1[t], axis)) {
            in_out_t value = tensor_read&lt;in_out_t&gt;(input1[t], shapes1[t], index2);
            tensor_write&lt;in_out_t&gt;(output, shape, index1, value);
        }
        index2[axis] = index2[axis] - shape_dim(shapes1[t], axis);
    }
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_pad">2.10.2. PAD</h4>
<div class="paragraph">
<p>Pads a tensor along the borders of each dimension with a supplied value.
Returns a new tensor with the padding included.
The pad_const value includes the zero point if the tensor uses a zero point.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Results must be exact.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape_t&lt;[2*rank(shape1)]&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">padding</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[2*rank(shape1)]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of pad elements at the start and end of each dimension.
            The values in padding are interpreted as start, end of each dimension.
            As an example for rank 2, the values would be interpreted as [start_dim0, end_dim0, start_dim1, end_dim1].</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">pad_const</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[1]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The value to be used as padding.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type as the input tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Compile Time Constant Status:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">CTC enabled profile(s)</th>
<th class="tableblock halign-left valign-top">CTC disabled extension(s)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">padding</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT, PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-DYNAMIC</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">pad_const</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT, PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-DYNAMIC</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT or PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E4M3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E5M2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++"><span class="comment">// Check output shape matches the padded input shape</span>
ERROR_IF(rank(shape) != rank(shape1));
<span class="keyword">for</span> (int32_t i = <span class="integer">0</span>; i &lt; rank(shape); i++) {
    ERROR_IF(padding[i * <span class="integer">2</span>] &lt; <span class="integer">0</span> || padding[(i * <span class="integer">2</span>) + <span class="integer">1</span>] &lt; <span class="integer">0</span>);
    ERROR_IF(shape[i] != padding[i * <span class="integer">2</span>] + shape1[i] + padding[(i * <span class="integer">2</span>) + <span class="integer">1</span>]);
}
for_each_data_position(index in shape) {
    shape_t index1 = index;
    bool_t is_pad = <span class="predefined-constant">false</span>;
    <span class="keyword">for</span>(int32_t i = <span class="integer">0</span>; i &lt; rank(shape); i++) {
        index1[i] = index1[i] - padding[i * <span class="integer">2</span>];
        <span class="keyword">if</span> (index1[i] &lt; <span class="integer">0</span> || index[i] &gt;= length(shape[i])) {
            is_pad = <span class="predefined-constant">true</span>;
        }
    }
    in_out_t value = is_pad ? pad_const : tensor_read&lt;in_out_t&gt;(input1, shape1, index1);
    tensor_write&lt;in_out_t&gt;(output, shape, index, value);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_reshape">2.10.3. RESHAPE</h4>
<div class="paragraph">
<p>Returns a tensor with the same type/values as the input, with a new shape specified by the shape argument. Reshape may operate on tensors of any rank. No data conversion happens during a reshape operation.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Results must be exact.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape_t&lt;[rank(shape)]&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[rank(shape)]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape_t giving the new shape.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type, size as the input tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Compile Time Constant Status:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">CTC enabled profile(s)</th>
<th class="tableblock halign-left valign-top">CTC disabled extension(s)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT, PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-DYNAMIC</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT or PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E4M3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E5M2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape1) &lt;= MAX_RANK);
LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">ERROR_IF(tensor_size(shape1) != tensor_size(shape));

for_each_data_position(index in shape) {
    <span class="comment">// Calculate flattened index for the output location (index)</span>
    tensor_size_t offset = tensor_index_to_offset(shape, index);
    <span class="comment">// Now convert to the location in the input</span>
    shape_t tmp_index = tensor_offset_to_index(shape1, offset);

    <span class="comment">// Now read/write the value</span>
    in_out_t val = tensor_read&lt;in_out_t&gt;(input1, shape1, tmp_index);
    tensor_write&lt;in_out_t&gt;(output, shape, index, val);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_reverse">2.10.4. REVERSE</h4>
<div class="paragraph">
<p>Returns a tensor with the same type/values as the input, with the data reversed along the given axis. No data conversion happens during a reverse operation.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Results must be exact.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">axis</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Axis to reverse, in range from 0 to rank(shape)-1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor. Same shape as input tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT or PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E4M3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E5M2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">ERROR_IF(axis &lt; <span class="integer">0</span> || axis &gt;= rank(shape));
for_each_data_position(index in shape) {
    shape_t tmp_index = index;
    tmp_index[axis] = shape[axis] - <span class="integer">1</span> - index[axis];
    in_out_t value = tensor_read&lt;in_out_t&gt;(input1, shape, tmp_index);
    tensor_write&lt;in_out_t&gt;(output, shape, index, value);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_slice">2.10.5. SLICE</h4>
<div class="paragraph">
<p>Extracts a slice of input1, beginning at the start coordinates, and extending for size elements in each direction.
No data conversion happens during a slice operation.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Results must be exact.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape_t&lt;[rank(shape1)]&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">start</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[rank(shape1)]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">List of integer coordinates, of length equal to the rank of input1. Start coordinate for slicing.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape_t&lt;[rank(shape1)]&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">size</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[rank(shape1)]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">List of integer size values, of length equal to the rank of input1. Size of the input to be
used.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type as the input tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Compile Time Constant Status:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">CTC enabled profile(s)</th>
<th class="tableblock halign-left valign-top">CTC disabled extension(s)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">start</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT, PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-DYNAMIC</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">size</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT, PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-DYNAMIC</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT or PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E4M3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E5M2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">ERROR_IF(rank(shape1) != length(start) || rank(shape1) != length(size));
ERROR_IF(rank(shape1) != rank(shape));
<span class="comment">// Sanity check the given coordinates, ensure start and end are</span>
<span class="comment">// within tensor bounds</span>
for_each(<span class="integer">0</span> &lt;= index &lt; rank(shape1)) {
    ERROR_IF(start[index] &lt; <span class="integer">0</span>);
    ERROR_IF(size[index] &lt;= <span class="integer">0</span>); <span class="comment">//Output must be positive size</span>
    ERROR_IF(start[index] + size[index] &gt; shape1[index]);
    ERROR_IF(shape[index] != size[index]);
}

for_each_data_position(index in shape) {
    shape_t tmp_index = index;
    <span class="keyword">for</span>(int32_t i = <span class="integer">0</span>; i &lt; rank(shape); i++) {
       tmp_index[i] = index[i] + start[i];
    }
    in_out_t value = tensor_read&lt;in_out_t&gt;(input1, shape1, tmp_index);
    tensor_write&lt;in_out_t&gt;(output, shape, index, value);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_tile">2.10.6. TILE</h4>
<div class="paragraph">
<p>Replicates input1 multiples times along each dimension.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Results must be exact.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape_t&lt;[rank(shape1)]&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">multiples</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[rank(shape1)]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of times to replicate input1 in each dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type, rank as the input tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Compile Time Constant Status:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">CTC enabled profile(s)</th>
<th class="tableblock halign-left valign-top">CTC disabled extension(s)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">multiples</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT, PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-DYNAMIC</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT or PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E4M3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E5M2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">ERROR_IF(rank(shape1) != rank(shape));

for_each_data_position(index in shape) {
    shape_t tmp_index = index;
    <span class="keyword">for</span>(int32_t i = <span class="integer">0</span>; i &lt; rank(shape); i++) {
        ERROR_IF(shape1[i] * multiples[i] != shape[i]);
        tmp_index[i] = index[i] % shape1[i];
    }
    in_out_t value = tensor_read&lt;in_out_t&gt;(input1, shape1, tmp_index);
    tensor_write&lt;in_out_t&gt;(output, shape, index, value);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_transpose">2.10.7. TRANSPOSE</h4>
<div class="paragraph">
<p>Permutes the dimensions of the input tensor input1 based on the perms argument.
Each value in the perms list must be a valid dimension of the input tensor and may not be repeated.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Results must be exact.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;i32_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">perms</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[rank(shape1)]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">List of integers of length equal to the rank of input1. Values must be valid dimensions within shape1, and may not be repeated.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type, rank as the input tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT or PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E4M3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E5M2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">ERROR_IF(rank(shape1) != rank(shape));
ERROR_IF(tensor_size(shape1) != tensor_size(shape));

bool_t indexes_used[rank(shape1)];
for_each_data_position(index in perms) {
    <span class="comment">// Ensure each perms value is a valid value</span>
    ERROR_IF(index &gt;= rank(shape1));
    ERROR_IF(index &lt; <span class="integer">0</span>);
    <span class="comment">// Ensure ranks aren't repeated</span>
    ERROR_IF(indexes_used[index] == <span class="predefined-constant">true</span>);
    indexes_used[index] = <span class="predefined-constant">true</span>;
}

<span class="comment">// Ensure that the output shapes have the properly</span>
<span class="comment">// permuted shapes</span>
<span class="keyword">for</span>(int32_t i = <span class="integer">0</span>; i &lt; rank(shape); i++) {
    ERROR_IF(shape1[perms[i]] != shape[i]);
}

for_each_data_position(index in shape) {
    shape_t tmp_index = index;
    <span class="keyword">for</span>(int32_t i = <span class="integer">0</span>; i &lt; rank(shape); i++) {
        tmp_index[perms[i]] = index[i];
    }
    in_out_t value = tensor_read&lt;in_out_t&gt;(input1, shape1, tmp_index);
    tensor_write&lt;in_out_t&gt;(output, shape, index, value);
}</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_scattergather_operators">2.11. Scatter/Gather Operators</h3>
<div class="sect3">
<h4 id="_gather">2.11.1. GATHER</h4>
<div class="paragraph">
<p>Generate a tensor for which each element in the output is a subtensor of the values tensor based on the indices.
N is the number of batches, W the number of indices in each batch, K the range of each index and C the number data channels for each index.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Results must be exact.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">values</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,K,C]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3D value tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;index_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">indices</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,W]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2D index tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,W,C]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3D output tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">index_t</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E4M3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E5M2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">for_each(<span class="integer">0</span> &lt;= n &lt; N, <span class="integer">0</span> &lt;= w &lt; W, <span class="integer">0</span> &lt;= c &lt; C) {
    index_t k = tensor_read&lt;index_t&gt;(indices, [N,W], [n,w]);
    REQUIRE(<span class="integer">0</span> &lt;= k &amp;&amp; k &lt; K);
    in_out_t value = tensor_read&lt;in_out_t&gt;(values, [N,K,C], [n,k,c]);
    tensor_write&lt;in_out_t&gt;(output, [N,W,C], [n,w,c], value);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_scatter">2.11.2. SCATTER</h4>
<div class="paragraph">
<p>The values_out tensor is set to the values_in tensor with data modified as follows: data from the input tensor is inserted at the positions specified by the indices tensor.
N is the number of batches, W the number of indices in each batch, K the range of each index and C the number data channels for each index.
It is not permitted to repeat the same output index within a single SCATTER operation and so each output index occurs at most once.
It follows that K &gt;= W.
In use cases that require multiple updates to the same output position, these must be decomposed into multiple SCATTER operations.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Results must be exact.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">values_in</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,K,C]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3D values in tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;index_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">indices</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,W]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2D index tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,W,C]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3D input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">values_out</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,K,C]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3D output tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">index_t</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E4M3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E5M2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++"><span class="comment">// The following array is used to check compliance that an output position</span>
<span class="comment">// is modified at most once.</span>
bool_t output_modified[N,K,C];

<span class="comment">// Copy the values_in tensor to the values_out tensor.</span>
<span class="comment">// Values not written by the scatter operation are unchanged in the output.</span>
for_each(<span class="integer">0</span> &lt;= n &lt; N, <span class="integer">0</span> &lt;= k &lt; K, <span class="integer">0</span> &lt;= c &lt; C) {
    in_out_t value = tensor_read&lt;in_out_t&gt;(values_in, [N,K,C], [n,k,c]);
    tensor_write&lt;in_out_t&gt;(values_out, [N,K,C], [n, k, c], value);
    output_modified[n,k,c]=<span class="predefined-constant">false</span>;
}

<span class="comment">// Now perform the SCATTER operation, modifying the positions from the indices tensor</span>
for_each(<span class="integer">0</span> &lt;= n &lt; N, <span class="integer">0</span> &lt;= w &lt; W, <span class="integer">0</span> &lt;= c &lt; C) {
    index_t k = tensor_read&lt;index_t&gt;(indices, [N,W], [n,w]);
    REQUIRE(<span class="integer">0</span> &lt;= k &amp;&amp; k &lt; K);
    REQUIRE(output_modified[n,k,c] == <span class="predefined-constant">false</span>);
    in_out_t value = tensor_read&lt;in_out_t&gt;(input, [N,W,C], [n,w,c]);
    tensor_write&lt;in_out_t&gt;(values_out, [N,K,C], [n, k, c], value);
    output_modified[n,k,c] = <span class="predefined-constant">true</span>;
}</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_image_operators">2.12. Image Operators</h3>
<div class="sect3">
<h4 id="_resize">2.12.1. RESIZE</h4>
<div class="paragraph">
<p>Resizes a tensor. Resize is only allowed in the H and W dimensions.</p>
</div>
<div class="paragraph">
<p>The height dimension is scaled by factor (scale_y_n/scale_y_d).
The width dimension is scaled by factor (scale_x_n/scale_x_d).</p>
</div>
<div class="paragraph">
<p>The NEAREST_NEIGHBOR mode returns the value of the input tensor closest to the
calculated sample position for both floating-point and integer data formats.</p>
</div>
<div class="paragraph">
<p>Floating-point BILINEAR mode returns a bilinearly interpolated output value
based on the four closest input sample positions.</p>
</div>
<div class="paragraph">
<p>For integer BILINEAR interpolation mode, the output value must
be scaled by 1/(scale_y_n * scale_x_n) in a following operation to
complete the interpolation (for example with a RESCALE operator).</p>
</div>
<div class="paragraph">
<p>The following examples show practical uses of the parameters:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>For approximate uniform input sampling between (0, 0) and (IH - 1, IW - 1) set</p>
<div class="ulist">
<ul>
<li>
<p>scale_y_n/scale_y_d = (OH - 1)/(IH - 1) as integer ratios</p>
</li>
<li>
<p>scale_x_n/scale_x_d = (OW - 1)/(IW - 1) as integer ratios</p>
</li>
<li>
<p>offset_x = 0, offset_y = 0, border_x = 0, border_y = 0</p>
</li>
</ul>
</div>
</li>
<li>
<p>For power of two upscale [OH - 1,OW - 1] = (1 &lt;&lt; k) * [IH - 1, IW - 1],
sampling between (0,0) and (IH - 1,IW - 1), set:</p>
<div class="ulist">
<ul>
<li>
<p>scale_y_n = (1 &lt;&lt; k), scale_y_d = 1, offset_y = 0, border_y = 0</p>
</li>
<li>
<p>scale_x_n = (1 &lt;&lt; k), scale_x_d = 1, offset_x = 0, border_x = 0</p>
</li>
</ul>
</div>
</li>
<li>
<p>For power of two upscale [OH,OW] = (1 &lt;&lt; k) * [IH,IW],
sampling range approximately (-0.5, -0.5) to (IH - 0.5, IW - 0.5), set:</p>
<div class="ulist">
<ul>
<li>
<p>scale_y_n = 2 &lt;&lt; k, scale_y_d = 2, offset_y = -(1 &lt;&lt; k) + 1, border_y = (1 &lt;&lt; k) - 1</p>
</li>
<li>
<p>scale_x_n = 2 &lt;&lt; k, scale_x_d = 2, offset_x = -(1 &lt;&lt; k) + 1, border_x = (1 &lt;&lt; k) - 1</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>The output dimensions can be derived from the input dimensions by inverting
the scale as described in the pseudocode. The [border_y, border_x] values
adjust the output size to allow fractional sampling beyond integer
input position (IH - 1,IW - 1).</p>
</div>
<div class="paragraph">
<p>The limit MAX_SCALE is applied to each scale ratio after reduction of the ratio.
Individual scale numerator and denominator values are allowed to be larger than MAX_SCALE.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>The result corresponds to a sequence of floating-point calculations.</p>
</li>
<li>
<p>The allowable error bound for the result of a resize is based on the maximum value of an element in the input tensor.</p>
</li>
<li>
<p>Let <code>out_imp</code> be the implementation output.</p>
</li>
<li>
<p>Let <code>out_ref</code> be the result calculated using fp64_t arithmetic.</p>
</li>
<li>
<p>Let <code>ulp_bnd = calcAbsErrorBound&lt;in_out_t&gt;(max(abs(input)), 20.0, 0, 1)</code>.</p>
</li>
<li>
<p>Let <code>relative_bnd = max(abs(input)) * 0.006</code>.</p>
</li>
<li>
<p>Let <code>err_bnd = max(ulp_bnd, relative_bnd)</code>.</p>
</li>
<li>
<p>Then <code>tosa_reference_check_fp_bnd&lt;out_t&gt;(out_imp, out_ref, err_bnd)</code> must be true.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,IH,IW,C]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape_t&lt;[4]&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">scale</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[4]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[scale_y_n, scale_y_d, scale_x_n, scale_x_d]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape_t&lt;[2]&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">offset</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[2]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[offset_y, offset_x]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape_t&lt;[2]&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">border</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[2]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[border_y, border_x]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">resize_mode_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">mode</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">BILINEAR or NEAREST</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,OH,OW,C]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Compile Time Constant Status:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">CTC enabled profile(s)</th>
<th class="tableblock halign-left valign-top">CTC disabled extension(s)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">scale</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT, PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-DYNAMIC</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">offset</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT, PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-DYNAMIC</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">border</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT, PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-DYNAMIC</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">resize_t</th>
<th class="tableblock halign-left valign-top">in_t</th>
<th class="tableblock halign-left valign-top">out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8, bilinear</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8, nearest</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-INT16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16, bilinear</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i48_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-INT16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16, nearest</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(scale_y_n/scale_y_d &lt;= MAX_SCALE);
LEVEL_CHECK(scale_x_n/scale_x_d &lt;= MAX_SCALE);</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Resize Modes:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">NEAREST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Nearest Neighbor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">BILINEAR</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Bilinear interpolation</p></td>
</tr>
</tbody>
</table>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++"><span class="comment">// Ensure the image size is supported by GPU APIs and that for integer</span>
<span class="comment">// implementations, position * stride does not overflow int32_t.</span>
ERROR_IF(max(OH,OW,IH,IW) &gt;= <span class="integer">16384</span>);
ERROR_IF(scale_y_n &lt;= <span class="integer">0</span> || scale_y_d &lt;= <span class="integer">0</span> || scale_x_n &lt;= <span class="integer">0</span> || scale_x_d &lt;= <span class="integer">0</span>);
<span class="comment">// if in_t=int8_t ensure that an int32_t accumulator can be used</span>
ERROR_IF(scale_y_n &gt; (<span class="integer">1</span> &lt;&lt; <span class="integer">11</span>) || scale_x_n &gt; (<span class="integer">1</span> &lt;&lt; <span class="integer">11</span>));
<span class="comment">// set a consistent lower limit of 1/16 downscale to simplify implementations</span>
ERROR_IF(scale_y_d &gt;= <span class="integer">16</span> * scale_y_n || scale_x_d &gt;= <span class="integer">16</span> * scale_x_n);
ERROR_IF(offset_y &lt; -scale_y_n || offset_y &gt;= <span class="integer">16</span> * scale_y_n);
ERROR_IF(offset_x &lt; -scale_x_n || offset_x &gt;= <span class="integer">16</span> * scale_x_n);
ERROR_IF(border_y &lt; -<span class="integer">16</span> * scale_y_n || border_y &gt;= scale_y_n);
ERROR_IF(border_x &lt; -<span class="integer">16</span> * scale_x_n || border_x &gt;= scale_x_n);
ERROR_IF(OH != idiv_check((IH - <span class="integer">1</span>) * scale_y_n - offset_y + border_y, scale_y_d) + <span class="integer">1</span>);
ERROR_IF(OW != idiv_check((IW - <span class="integer">1</span>) * scale_x_n - offset_x + border_x, scale_x_d) + <span class="integer">1</span>);
for_each(<span class="integer">0</span> &lt;= n &lt; N, <span class="integer">0</span> &lt;= oy &lt; OH, <span class="integer">0</span> &lt;= ox &lt; OW, <span class="integer">0</span> &lt;= c &lt; C) {
    out_t acc;
    resize_t dx, dy;
    resize_t unit_x, unit_y;

    unit_x = (is_floating_point&lt;resize_t&gt;()) ? <span class="float">1</span><span class="float">.0</span> : scale_x_n;
    unit_y = (is_floating_point&lt;resize_t&gt;()) ? <span class="float">1</span><span class="float">.0</span> : scale_y_n;

    int32_t y = oy * scale_y_d + offset_y;
    int32_t x = ox * scale_x_d + offset_x;
    int16_t iy = idiv_floor(y, scale_y_n);
    int16_t ix = idiv_floor(x, scale_x_n);
    int16_t ry = y - iy * scale_y_n;  <span class="comment">// (y % scale_y_n)</span>
    int16_t rx = x - ix * scale_x_n;  <span class="comment">// (x % scale_x_n)</span>

    <span class="keyword">if</span> (is_floating_point&lt;resize_t&gt;()) {
        dy = <span class="keyword">static_cast</span>&lt;resize_t&gt;(ry) / <span class="keyword">static_cast</span>&lt;resize_t&gt;(scale_y_n);
        dx = <span class="keyword">static_cast</span>&lt;resize_t&gt;(rx) / <span class="keyword">static_cast</span>&lt;resize_t&gt;(scale_x_n);
    } <span class="keyword">else</span> {
        dy = ry;
        dx = rx;
    }
    <span class="comment">// Note that -1 &lt;= iy &lt; IH and -1 &lt;= ix &lt; IW</span>
    int16_t iy0 = apply_max_s(iy, <span class="integer">0</span>);
    int16_t iy1 = apply_min_s(iy + <span class="integer">1</span>, IH - <span class="integer">1</span>);
    int16_t ix0 = apply_max_s(ix, <span class="integer">0</span>);
    int16_t ix1 = apply_min_s(ix + <span class="integer">1</span>, IW - <span class="integer">1</span>);
    <span class="keyword">if</span> (mode==BILINEAR) {
        <span class="directive">using</span> in_s_t = make_signed(in_t); <span class="comment">// Use signed calculations for i8/i16</span>
        in_s_t v00 = <span class="keyword">static_cast</span>&lt;in_s_t&gt;(tensor_read&lt;in_t&gt;(input, [N,IH,IW,C], [n,iy0,ix0,c]));
        in_s_t v01 = <span class="keyword">static_cast</span>&lt;in_s_t&gt;(tensor_read&lt;in_t&gt;(input, [N,IH,IW,C], [n,iy0,ix1,c]));
        in_s_t v10 = <span class="keyword">static_cast</span>&lt;in_s_t&gt;(tensor_read&lt;in_t&gt;(input, [N,IH,IW,C], [n,iy1,ix0,c]));
        in_s_t v11 = <span class="keyword">static_cast</span>&lt;in_s_t&gt;(tensor_read&lt;in_t&gt;(input, [N,IH,IW,C], [n,iy1,ix1,c]));
        acc  = v00 * (unit_y - dy) * (unit_x - dx);
        acc += v01 * (unit_y - dy) * dx;
        acc += v10 * dy * (unit_x - dx);
        acc += v11 * dy * dx;
        tensor_write&lt;out_t&gt;(output, [N,OH,OW,C], [n,oy,ox,c], acc);
    } <span class="keyword">else</span> <span class="keyword">if</span> (mode==NEAREST) {
        int32_t iy, ix;
        <span class="keyword">if</span> (is_floating_point&lt;resize_t&gt;()) {
            iy = (dy &gt;= <span class="float">0</span><span class="float">.5</span>) ? iy1 : iy0;
            ix = (dx &gt;= <span class="float">0</span><span class="float">.5</span>) ? ix1 : ix0;
        } <span class="keyword">else</span> {
            iy = (<span class="integer">2</span> * dy &gt;= scale_y_n) ? iy1 : iy0;
            ix = (<span class="integer">2</span> * dx &gt;= scale_x_n) ? ix1 : ix0;
        }
        in_t v = tensor_read&lt;in_t&gt;(input, [N,IH,IW,C], [n,iy,ix,c]);
        tensor_write&lt;out_t&gt;(output, [N,OH,OW,C], [n,oy,ox,c], v);
    }
}</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_type_conversion">2.13. Type Conversion</h3>
<div class="sect3">
<h4 id="_cast">2.13.1. CAST</h4>
<div class="paragraph">
<p>Casts a tensor from one data type to another.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_t</th>
<th class="tableblock halign-left valign-top">out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 to fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 to signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 to signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 to signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32 to fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32 to signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32 to signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32 to signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16 to fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16 to fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32 to fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32 to fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8 to fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8 to fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool to signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool to signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool to signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16 to bool</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16 to signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16 to signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32 to bool</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32 to signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32 to signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8 to bool</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8 to signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8 to signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16 to fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16 to signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16 to signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16 to signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32 to bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16 to bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32 to bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8 to bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16 and EXT-FP8E4M3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16 to fp8e4m3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16 and EXT-FP8E4M3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3 to bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16 and EXT-FP8E5M2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16 to fp8e5m2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16 and EXT-FP8E5M2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2 to bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E4M3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 to fp8e4m3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E4M3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32 to fp8e4m3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E4M3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3 to fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E4M3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3 to fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E5M2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 to fp8e5m2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E5M2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32 to fp8e5m2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E5M2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2 to fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E5M2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2 to fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>When casting between integer types, the results must be exact.</p>
</div>
<div class="paragraph">
<p>Rules when casting between floating-point types:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Subnormal bf16_t, fp16_t, and fp32_t input values may be flushed to zero before calculation.</p>
</li>
<li>
<p>If the input value is a NaN, a NaN of the output type must be returned.</p>
</li>
<li>
<p>The following sequence describes conversion between floating-point types:</p>
<div class="ulist">
<ul>
<li>
<p>The mantissa of the input value is converted to the mantissa size of the output format, with rounding if needed.</p>
</li>
<li>
<p>If the resulting value is below the minimum subnormal number magnitude for the target format, a zero of the appropriate sign must be returned.</p>
</li>
<li>
<p>For bf16_t, fp16_t, and fp32_t, if the resulting value is below the minimum normal number magnitude for the target format, either the corresponding subnormal value may be returned, or a zero of the appropriate sign may be returned.</p>
</li>
<li>
<p>If the output type is fp8e4m3_t or fp8e5m2_t the result must use the non-saturating conversion mode defined in <a href="#OCP-OFP8">OCP-OFP8</a>.</p>
</li>
<li>
<p>Otherwise if the resulting value is outside of the output representable range, an infinity of the appropriate sign must be returned.</p>
</li>
</ul>
</div>
</li>
<li>
<p>If the input value is inside the output representable range then the following accuracy must be met:</p>
<div class="ulist">
<ul>
<li>
<p>Let <code>x</code> be an input element.</p>
</li>
<li>
<p>Let <code>out_imp</code> be the implementation output.</p>
</li>
<li>
<p>Let <code>out_ref</code> be the result calculated using fp64_t arithmetic.</p>
</li>
<li>
<p>Let <code>ulp = tosa_reference_ulp&lt;out_t&gt;(out_ref)</code> define one ulp of error.</p>
</li>
<li>
<p>Then <code>abs(out_ref) - ulp &lt;= abs(x) &lt;= abs(out_ref) + 0.5*ulp</code> must be true and <code>x</code> must have the correct sign.</p>
</li>
<li>
<p>This allows for both round to zero and round to nearest rounding modes.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>Rules when casting between different types:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Casting from floating-point to integer:</p>
<div class="ulist">
<ul>
<li>
<p>Subnormal bf16_t, fp16_t, and fp32_t input values may be flushed to zero before calculation.</p>
</li>
<li>
<p>If any input is a NaN, the result is unpredictable.</p>
</li>
<li>
<p>Result overflows must be saturated.</p>
</li>
<li>
<p>Conversion must use the round to nearest, ties to even rounding mode.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Casting from integer to floating-point:</p>
<div class="ulist">
<ul>
<li>
<p>Let <code>out_imp</code> be the implementation output.</p>
</li>
<li>
<p>Let <code>out_ref</code> be the result calculated using fp64_t arithmetic.</p>
</li>
<li>
<p>Then <code>tosa_reference_check_fp&lt;out_t&gt;(out_imp, out_ref, 0.5)</code> must be true.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Casting to boolean type:</p>
<div class="ulist">
<ul>
<li>
<p>The result must be exact.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">for_each_data_position(index in shape) {
    in_t in = tensor_read&lt;in_t&gt;(input, shape, index);
    out_t out;
    <span class="keyword">if</span> (is_same&lt;out_t,bool_t&gt;()) {
        out = (in != <span class="integer">0</span>) ? <span class="predefined-constant">true</span> : <span class="predefined-constant">false</span>;
    } <span class="keyword">else</span> <span class="keyword">if</span> (is_floating_point&lt;out_t&gt;()) {
        <span class="comment">// Conversion to float cases</span>
        <span class="keyword">if</span> (is_same&lt;in_t,bool_t&gt;()) {
            out = (in) ? <span class="float">1</span><span class="float">.0</span> : <span class="float">0</span><span class="float">.0</span>;
        }
        out = round_to_nearest_float(in);
    } <span class="keyword">else</span> {
        <span class="comment">// Conversion to integer cases</span>
        <span class="keyword">if</span> (is_same&lt;in_t,bool_t&gt;()) {
            out = (in) ? <span class="integer">1</span> : <span class="integer">0</span>;
        } <span class="keyword">else</span> <span class="keyword">if</span> (is_floating_point&lt;in_t&gt;()) {
            out = truncate&lt;out_t&gt;(apply_clip_s&lt;i32_t&gt;(round_to_nearest_int(in), minimum_s&lt;out_t&gt;(), maximum_s&lt;out_t&gt;()));
        } <span class="keyword">else</span> <span class="keyword">if</span> (<span class="keyword">sizeof</span>&lt;out_t&gt;() &gt;= <span class="keyword">sizeof</span>&lt;in_t&gt;()) {
            out = sign_extend&lt;out_t&gt;(in);
        } <span class="keyword">else</span> {
            out = truncate&lt;out_t&gt;(in);
        }
    }
    tensor_write&lt;out_t&gt;(output, shape, index, out);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_rescale">2.13.2. RESCALE</h4>
<div class="paragraph">
<p>RESCALE is defined using an integer multiply, add, and shift.</p>
</div>
<div class="paragraph">
<p>Rescale supports two precisions of multiplier: 16-bit and 32-bit.
The 32-bit multiplier version supports two rounding modes to enable simpler lowering of existing frameworks that use two stage rounding.
All arithmetic is designed so that it does not overflow a 64-bit accumulator and that the result fits in 32 bits.
In particular, a 48-bit value cannot be scaled with the 32-bit multiplier because the accumulator would need to have 80 bits.</p>
</div>
<div class="paragraph">
<p>The apply_scale_* functions provide a scaling of approximately (multiplier / 2<sup>shift</sup>).</p>
</div>
<div class="paragraph">
<p>The shift and value range are limited to allow a variety of implementations.
The limit of 62 on shift allows the shift to be decomposed as two right shifts of 31.</p>
</div>
<div class="paragraph">
<p>For apply_scale_32, the value must be between <code>(-1 &lt;&lt; (shift - 1)) &lt;= value &lt; (1 &lt;&lt; (shift - 1))</code>.
This allows for implementations that left-shift the value before the multiply in the case of shifts of 32 or less.</p>
</div>
<div class="paragraph">
<p>For example, in the case shift=30 an implementation of the form <code>((value&lt;&lt;2) * multiplier + round)&gt;&gt;32</code> can be used.
A scaling range of 2<sup>+12</sup> down to 2<sup>-32</sup> is supported for both functions with a normalized multiplier.</p>
</div>
<div class="paragraph">
<p>In typical usage, a scaling of <code>m*2<sup>-n</sup></code> (where m is a fraction in the range <code>1.0 &lt;= m &lt; 2.0</code>) can be represented using <code>multiplier=(1&lt;&lt;30)*m, shift=(30+n)</code> for apply_scale_32() and <code>multiplier=(1&lt;&lt;14)*m, shift=(14+n)</code> for apply_scale_16().</p>
</div>
<div class="paragraph">
<p>The values to achieve a scaling of 1.0 are <code>shift=30, multiplier=1&lt;&lt;30</code> for apply_scale_32 and <code>shift=14, multiplier=1&lt;&lt;14</code> for apply_scale_16.</p>
</div>
<div class="paragraph">
<p>The right shift of result is an arithmetic shift.</p>
</div>
<div class="paragraph">
<p>For implementation details of the apply_scale_functions, see <a href="#_scaling_helpers">Scaling Helpers</a>.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>If rounding_mode is SINGLE_ROUND or DOUBLE_ROUND, results must be exact.</p>
</div>
<div class="paragraph">
<p>If rounding_mode is INEXACT_ROUND, the following must be true:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Let <code>x</code> be the input value to be rescaled.</p>
</li>
<li>
<p>Let <code>m</code> be the scaling multiplier.</p>
</li>
<li>
<p>Let <code>out_ref = (x - input_zp) * m * exp2(-shift)</code> be the result calculated using fp64_t arithmetic.</p>
</li>
<li>
<p>Note (informational): The error bound accounts for 3 rounding errors from casting the activation input, multiplier input, and floating-point multiply, plus 1 rounding error from adding <code>output_zp</code>
and 0.5 absolute error from the final output rounding.<br>
A SINGLE_ROUND exact implementation will automatically meet this error bound since its rounding error is at most 0.5.</p>
</li>
<li>
<p>Let <code>err_bnd = 0.5 + (3 * abs(out_ref) + abs(out_ref + output_zp)) * exp2(-normal_frac&lt;fp32&gt;() - 1)</code>.</p>
</li>
<li>
<p>Let <code>out_ref_min = apply_clip_s&lt;fp64_t&gt;(apply_ceil&lt;fp64_t&gt;(out_ref - err_bnd + output_zp), minimum_s&lt;out_t&gt;, maximum_s&lt;out_t&gt;)</code>.</p>
</li>
<li>
<p>Let <code>out_ref_max = apply_clip_s&lt;fp64_t&gt;(apply_floor&lt;fp64_t&gt;(out_ref + err_bnd + output_zp), minimum_s&lt;out_t&gt;, maximum_s&lt;out_t&gt;)</code>.</p>
</li>
<li>
<p>Let <code>out_ref_min_int = static_cast&lt;out_t&gt;(out_ref_min)</code>.</p>
</li>
<li>
<p>Let <code>out_ref_max_int = static_cast&lt;out_t&gt;(out_ref_max)</code>.</p>
</li>
<li>
<p>Let <code>out_imp</code> be the implementation output.</p>
</li>
<li>
<p>Then <code>out_ref_min_int &lt;= out_imp &lt;= out_ref_max_int</code> must be true.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;mul_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">multiplier</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[NC]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling multiplier array</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;i8_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shift</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[NC]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling shift array</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[1]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor zero point. int8/uint8 can have zero point within their valid range. uint16 zero point must be either 0 or 32768. All other types must have zero point equal to 0.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[1]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor zero point.int8/uint8 can have zero point within their valid range. uint16 zero point must be either 0 or 32768. All other types must have zero point equal to 0.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">scale32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">if (scale32) mul_t=i32_t else mul_t=i16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">rounding_mode_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">rounding_mode</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Select rounding mode</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">per_channel</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">if (per_channel) NC=shape[rank(shape)-1] else NC=1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input_unsigned</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">If True, treat the input values as unsigned.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output_unsigned</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">If True, treat the output values as unsigned.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor with the same shape as input</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Compile Time Constant Status:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">CTC enabled profile(s)</th>
<th class="tableblock halign-left valign-top">CTC disabled extension(s)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">multiplier</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-DYNAMIC</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">shift</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-DYNAMIC</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">input_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-DYNAMIC</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">output_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-DYNAMIC</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_t</th>
<th class="tableblock halign-left valign-top">out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">16-bit to 16-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">16-bit to 32-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">16-bit to 8-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">32-bit to 16-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">32-bit to 32-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">32-bit to 8-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">8-bit to 16-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">8-bit to 32-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">8-bit to 8-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-INT16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">48-bit to 16-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i48_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-INT16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">48-bit to 32-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i48_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-INT16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">48-bit to 8-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i48_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">for_each_data_position(index in shape) {
    <span class="comment">// uint16 values can have zero_point 0 or 32768</span>
    <span class="comment">// int8/uint8 can have zero point within their valid range</span>
    <span class="comment">// No other types can have zero point != 0</span>
    ERROR_IF(!is_same&lt;in_t,i8_t&gt;() &amp;&amp;
             (!is_same&lt;in_t,i16_t&gt;() || input_unsigned == <span class="predefined-constant">false</span>) &amp;&amp; input_zp != <span class="integer">0</span>);
    ERROR_IF(!is_same&lt;out_t,i8_t&gt;() &amp;&amp;
             (!is_same&lt;out_t,i16_t&gt;() || output_unsigned == <span class="predefined-constant">false</span>) &amp;&amp; output_zp != <span class="integer">0</span>);
    ERROR_IF(is_same&lt;in_t,i16_t&gt;() &amp;&amp; input_unsigned == <span class="predefined-constant">true</span> &amp;&amp; input_zp != <span class="integer">0</span> &amp;&amp; input_zp != <span class="integer">32768</span>);
    ERROR_IF(is_same&lt;out_t,i16_t&gt;() &amp;&amp; output_unsigned == <span class="predefined-constant">true</span> &amp;&amp; output_zp != <span class="integer">0</span> &amp;&amp; output_zp != <span class="integer">32768</span>);
    ERROR_IF(scale32 &amp;&amp; is_same&lt;in_t,i48_t&gt;());
    ERROR_IF(!scale32 &amp;&amp; (rounding_mode == DOUBLE_ROUND));
    ERROR_IF(input_unsigned &amp;&amp; output_unsigned);
    ERROR_IF(is_same&lt;out_t,i32_t&gt;() &amp;&amp; input_unsigned);
    ERROR_IF(is_same&lt;in_t,i32_t&gt;() &amp;&amp; output_unsigned);
    ERROR_IF(is_same&lt;in_t,i48_t&gt;() &amp;&amp; output_unsigned);
    ERROR_IF(is_same&lt;in_t, i48_t&gt; &amp;&amp; input_unsigned); <span class="comment">// No support for u48 inputs</span>
    ERROR_IF(is_same&lt;in_t, i32_t&gt; &amp;&amp; input_unsigned); <span class="comment">// No support for u32 inputs</span>
    ERROR_IF(is_same&lt;out_t, i32_t&gt; &amp;&amp; output_unsigned); <span class="comment">// No support for u32 outputs</span>
    ERROR_IF(per_channel &amp;&amp; rank(input) &lt; <span class="integer">1</span>);

    in_t in_value = tensor_read&lt;in_t&gt;(input, shape, index);

    int48_t value, extended_in_zp;
    <span class="keyword">if</span> (input_unsigned) {
        value = zero_extend&lt;int48_t&gt;(in_value);
        extended_in_zp = zero_extend&lt;int48_t&gt;(input_zp);
    }
    <span class="keyword">else</span> {
        value = sign_extend&lt;int48_t&gt;(value);
        extended_in_zp = sign_extend&lt;int48_t&gt;(input_zp);
    }

    value = value - extended_in_zp;
    <span class="predefined-type">int</span> c = (per_channel) ? index[rank(input) - <span class="integer">1</span>] : <span class="integer">0</span>;
    int32_t result = (scale32) ?
        apply_scale_32(value, multiplier[c], shift[c], rounding_mode == DOUBLE_ROUND) :
        apply_scale_16(value, multiplier[c], shift[c]);

    out_t out;
    <span class="keyword">if</span> (output_unsigned) {
        int32_t extended_out_zp = zero_extend&lt;int32_t&gt;(output_zp);
        result = apply_add_s&lt;int32_t&gt;(result, extended_out_zp);
        out = <span class="keyword">static_cast</span>&lt;out_t&gt;(apply_clip_u&lt;i32_t&gt;(result,
                                                     minimum_u&lt;out_t&gt;(),
                                                     maximum_u&lt;out_t&gt;()));
    }
    <span class="keyword">else</span> {
        int32_t extended_out_zp = sign_extend&lt;int32_t&gt;(output_zp);
        result = apply_add_s&lt;int32_t&gt;(result, extended_out_zp);
        out = <span class="keyword">static_cast</span>&lt;out_t&gt;(apply_clip_s&lt;i32_t&gt;(result,
                                                     minimum_s&lt;out_t&gt;(),
                                                     maximum_s&lt;out_t&gt;()));
    }
    tensor_write&lt;out_t&gt;(output, shape, index, out);
}</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_data_nodes">2.14. Data Nodes</h3>
<div class="sect3">
<h4 id="_const">2.14.1. CONST</h4>
<div class="paragraph">
<p>A node containing constant data for use as the input to an operation. May hold data in any of the supported data formats.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Integer results must be exact.</p>
</div>
<div class="paragraph">
<p>For floating-point values, the following rules apply:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Subnormal bf16_t, fp16_t, and fp32_t input values may be flushed to zero.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">values</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Constant values</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Compile Time Constant Status:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">CTC enabled profile(s)</th>
<th class="tableblock halign-left valign-top">CTC disabled extension(s)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT, PRO-FP</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT or PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">16-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT or PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">32-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT or PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">8-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT or PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E4M3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E5M2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-INT16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">48-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i48_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-INT4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">4-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i4_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">output = values;</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_identity">2.14.2. IDENTITY</h4>
<div class="paragraph">
<p>Returns a tensor with the same shape, type, and contents as the input.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Integer results must be exact.</p>
</div>
<div class="paragraph">
<p>For floating-point values, the following rules apply:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Subnormal bf16_t, fp16_t, and fp32_t input values may be flushed to zero.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of the same type, size as the input tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT or PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">16-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT or PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">32-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT or PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">8-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT or PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E4M3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-FP8E5M2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-INT16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">48-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i48_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-INT4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">4-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i4_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">output = input1;</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_custom_operators">2.15. Custom Operators</h3>
<div class="paragraph">
<p>Hardware implementing TOSA may choose to add additional custom operators that are not expressed in the existing TOSA operations. These operators are not expected to be portable across TOSA implementations. The input and output signatures must be expressed in the corresponding TOSA node.</p>
</div>
<div class="sect3">
<h4 id="_custom">2.15.1. CUSTOM</h4>
<div class="paragraph">
<p>Runs an implementation defined custom operator.
CUSTOM operators are not tested in the conformance suite as results will be implementation defined.
The <code>domain_name</code> attribute should be unique to each implementation.
To achieve this, using a domain name as the <code>domain_name</code> attribute is recommended.
No conformance testing is done for CUSTOM operators as they are implementation dependent.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">tensor_list_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input_list</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">List of input tensors</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">String</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">operator_name</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">String which tells the backend which custom operator is being called</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">String</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">domain_name</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">String identifier which can help avoid name collisions on the operator field.
            Different implementations of a given operator would be in different domains.
            Implementations can choose which domains they want to support.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">String</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">implementation_attrs</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">String value containing implementation specific attributes which apply to the operation</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">tensor_list_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output_list</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">List of output tensors</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT or PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">All</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(tensor_list_shape(input_list) &lt;= MAX_TENSOR_LIST_SIZE);
LEVEL_CHECK(tensor_list_shape(output_list) &lt;= MAX_TENSOR_LIST_SIZE);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++"><span class="comment">// Implementation defined behavior</span></code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_control_flow_operators">2.16. Control Flow Operators</h3>
<div class="paragraph">
<p>TOSA implements two control flow operators, for conditional branching and loop based control. Both have attributes that are TOSA sub-graphs.</p>
</div>
<div class="sect3">
<h4 id="_cond_if">2.16.1. COND_IF</h4>
<div class="paragraph">
<p>Evaluates a Boolean condition and then takes one of two distinct execution paths. This implements the semantic if-then-else structure.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;bool_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">condition</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input condition as a size 1 tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">tensor_list_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input_list</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">List of input tensors</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">tosa_graph_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">then_graph</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">TOSA graph to execute if condition is true</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">tosa_graph_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">else_graph</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">TOSA graph to execute if condition is false</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">tensor_list_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output_list</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">List of output tensors</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-CONTROLFLOW</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">All</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);
LEVEL_CHECK(tensor_list_shape(input_list) &lt;= MAX_TENSOR_LIST_SIZE);
LEVEL_CHECK(tensor_list_shape(output_list) &lt;= MAX_TENSOR_LIST_SIZE);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">ERROR_IF(tosa_nesting_depth &gt;= MAX_NESTING);
ERROR_IF(tensor_list_shape(input_list) != tosa_input_shape(then_graph));
ERROR_IF(tensor_list_shape(input_list) != tosa_input_shape(else_graph));
ERROR_IF(tensor_list_shape(output_list) != tosa_output_shape(then_graph));
ERROR_IF(tensor_list_shape(output_list) != tosa_output_shape(else_graph));
ERROR_IF(tensor_size(shape) != <span class="integer">1</span>);

tosa_nesting_depth++;
<span class="keyword">if</span> (condition[<span class="integer">0</span>]) {
    tosa_execute_graph(then_graph, input_list, output_list);
} <span class="keyword">else</span> {
    tosa_execute_graph(else_graph, input_list, output_list);
}
tosa_nesting_depth--;</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_while_loop">2.16.2. WHILE_LOOP</h4>
<div class="paragraph">
<p>Generates and evaluates a Boolean condition and either executes a loop body or exits the loop. This action is performed repeatedly after updating and re-evaluating the Boolean condition every iteration. This implements the semantic foreach or while iterative loop structure.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">tensor_list_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input_list</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">List of input tensors</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">tosa_graph_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">cond_graph</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">TOSA graph to evaluate the condition</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">tosa_graph_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">body_graph</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">TOSA graph to execute the loop body</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">tensor_list_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output_list</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">List of output tensors</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-CONTROLFLOW</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">All</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(tensor_list_shape(input_list) &lt;= MAX_TENSOR_LIST_SIZE);
LEVEL_CHECK(tensor_list_shape(output_list) &lt;= MAX_TENSOR_LIST_SIZE);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">ERROR_IF(tosa_nesting_depth &gt;= MAX_NESTING);
ERROR_IF(tensor_list_shape(input_list) != tensor_list_shape(output_list));
ERROR_IF(tensor_list_shape(input_list) != tosa_input_shape(cond_graph));
ERROR_IF(tensor_list_shape(input_list) != tosa_input_shape(body_graph));
ERROR_IF(tensor_list_shape(input_list) != tosa_output_shape(body_graph));
<span class="comment">// Condition graph output must be a single element tensor with a single bool value</span>
ERROR_IF(tensor_size(tosa_output_shape(cond_graph)) != <span class="integer">1</span>);
ERROR_IF(tosa_output_type(cond_graph) != bool_t);

<span class="comment">// The iteration number 'i' is included to give unique names to variables</span>
<span class="comment">// in each iteration of the loop and is not required by implementations</span>
int32_t i=<span class="integer">0</span>;             <span class="comment">// iteration number</span>
tensor_list_t list[];    <span class="comment">// array of tensor lists indexed by iteration</span>
bool_t *condition[];     <span class="comment">// array of condition tensors indexed by iteration</span>
list[i] = input_list;    <span class="comment">// copy input data as list[0]</span>
tosa_nesting_depth++;
tosa_execute_graph(cond_graph, list[i], [ condition[i] ]);   <span class="comment">// initial condition</span>
<span class="keyword">while</span> (condition[i][<span class="integer">0</span>]) {
    tosa_execute_graph(body_graph, list[i], list[i+<span class="integer">1</span>]);
    i = i+<span class="integer">1</span>;
    tosa_execute_graph(cond_graph, list[i], [ condition[i] ]);
}
tosa_nesting_depth--;
output_list = list[i];</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_variable_operators">2.17. Variable Operators</h3>
<div class="paragraph">
<p>TOSA implements three variable operators for expressing persistent mutable values across multiple TOSA graph invocations.</p>
</div>
<div class="sect3">
<h4 id="_variable">2.17.1. VARIABLE</h4>
<div class="paragraph">
<p>Defines a new TOSA variable.
This is a persistent mutable value across multiple TOSA graph invocations.
Modifications are expressed using read/write semantics.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Results must be exact.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">String</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">name</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Globally unique identifier for the declared variable tensor.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;tensor_size_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">var_shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">var_shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The variable tensor shape</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">var_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">type</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Type of the tensor variable elements.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">initial_value</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Initial value of the variable tensor. This argument is optional with default value NULL.</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-VARIABLE and PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-VARIABLE and PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-VARIABLE and PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">tensor_t var_tensor = variable_tensor_lookup(name);

<span class="comment">// Invocation for the first time</span>
<span class="keyword">if</span> (var_tensor == <span class="predefined-constant">NULL</span>) {
  <span class="comment">// Allocate the persistent mutable memory for the variable tensor</span>
  var_tensor = variable_tensor_allocate&lt;var_t&gt;(var_shape, name);

  <span class="keyword">if</span> (initial_value != <span class="predefined-constant">NULL</span>) {
    REQUIRE(var_t == in_t);
    REQUIRE(var_shape == shape);
    for_each_data_position (index in shape) {
      <span class="comment">// Copy data from initial_value to var_tensor</span>
      in_t value = tensor_read&lt;in_t&gt;(initial_value, shape, index);
      tensor_write&lt;in_t&gt;(var_tensor.data, var_shape, index, value);
    }
    var_tensor.is_written = <span class="predefined-constant">true</span>;
  }
} <span class="keyword">else</span> { <span class="comment">// Variable tensor has already been declared</span>
  <span class="comment">// It's invalid to declare the second variable with the same name in a single graph execution,</span>
  REQUIRE(!var_tensor.seen);
}

var_tensor.seen = <span class="predefined-constant">true</span>;</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_variable_write">2.17.2. VARIABLE_WRITE</h4>
<div class="paragraph">
<p>Assigns a value to the pseudo-buffer resource holding a persistent mutable tensor.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Results must be exact.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;in_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">String</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">name</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Globally unique identifier of the variable tensor that is writing to</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-VARIABLE and PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-VARIABLE and PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-VARIABLE and PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">tensor_t variable_tensor = variable_tensor_lookup(uid);
<span class="comment">// Check this variable tensor has been declared</span>
REQUIRE(variable_tensor);
<span class="comment">// The tensor has to be seen before to be written to</span>
<span class="comment">// The seen variable is cleared before each graph execution and set in declaration</span>
REQUIRE(variable_tensor.seen);
<span class="comment">//  Input tensor's shape and variable_tensor's shape have to match</span>
REQUIRE(variable_tensor.shape == shape);
<span class="comment">//  Input tensor's shape and variable_tensor's type have to match</span>
REQUIRE(is_same&lt;variable_tensor.type,in_t&gt;());

for_each_data_position (index in shape) {
    <span class="comment">// Write data from the input to the pseudo-buffer resource</span>
    in_t value = tensor_read&lt;in_t&gt;(input1, shape, index);
    tensor_write&lt;tensor_t&gt;(variable_tensor.data, variable_tensor.shape, index, value);
}

variable_tensor.is_written = <span class="predefined-constant">true</span>;</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_variable_read">2.17.3. VARIABLE_READ</h4>
<div class="paragraph">
<p>Reads the value from a pseudo-buffer resource holding a persistent mutable tensor.</p>
</div>
<div class="paragraph">
<p><strong>Precision Requirements</strong></p>
</div>
<div class="paragraph">
<p>Results must be exact.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">String</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">name</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Globally unique identifier of the variable tensor that is reading from</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">T&lt;out_t&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 to MAX_RANK</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-VARIABLE and PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-VARIABLE and PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-VARIABLE and PRO-INT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">i8_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">LEVEL_CHECK(rank(shape) &lt;= MAX_RANK);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">tensor_t variable_tensor = variable_tensor_lookup(name);
<span class="comment">// Check this variable tensor has been decalred</span>
REQUIRE(variable_tensor != <span class="predefined-constant">NULL</span>);
<span class="comment">// Check this variable tensor has been written</span>
REQUIRE(variable_tensor.is_written);
<span class="comment">// Output tensor's shape and variable_tensor's shape have to match</span>
REQUIRE(variable_tensor.shape == shape);
<span class="comment">//  Output tensor's shape and variable_tensor's type have to match</span>
REQUIRE(is_same&lt;variable_tensor.type,out_t&gt;());

for_each_data_position (index in shape) {
    <span class="comment">// Read data from pseudo-buffer resource to the output</span>
    out_t value = tensor_read&lt;tensor_t&gt;(variable_tensor.data, variable_tensor.shape, index);
    tensor_write&lt;out_t&gt;(output1, shape, index, value);
}</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_shape_operators">2.18. Shape Operators</h3>
<div class="paragraph">
<p>The shape operators are operators which describe the shapes of parameters and the corresponding transformations.</p>
</div>
<div class="paragraph">
<p>Having separate shape operations allows easier tracking of shape propagation than would be possible by using the existing TOSA operators.</p>
</div>
<div class="sect3">
<h4 id="_const_shape">2.18.1. CONST_SHAPE</h4>
<div class="paragraph">
<p>A node containing a constant shape.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 13.6363%;">
<col style="width: 13.6363%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1818%;">
<col style="width: 36.3638%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Rank</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape_t&lt;&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">values</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Constant shape</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape_t&lt;&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output shape</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Compile Time Constant Status:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">CTC enabled profile(s)</th>
<th class="tableblock halign-left valign-top">CTC disabled extension(s)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT, PRO-FP</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile/Extension</th>
<th class="tableblock halign-left valign-top">Mode</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PRO-INT or PRO-FP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">output = values;</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_enumerations">3. Enumerations</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Where enumerated types are specified for an operator, the provided value must be a valid enumerant for that type.
The included tables provide reference values for the enumerations.
Implementations do not need to use these values, they may substitute other values as long as they are functionally equivalent.
If no entry is listed in 'Required Extension' then the enumeration is always available.</p>
</div>
<div class="sect2">
<h3 id="_resize_mode_t">3.1. resize_mode_t</h3>
<div class="paragraph">
<p>Valid resize types</p>
</div>
<table class="tableblock frame-all grid-all" style="width: 99%;">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Value</th>
<th class="tableblock halign-left valign-top">Description</th>
<th class="tableblock halign-left valign-top">Required Extension</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">NEAREST_NEIGHBOR</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Nearest neighbor resize</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">BILINEAR</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Bilinear resize</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="_acc_type_t">3.2. acc_type_t</h3>
<div class="paragraph">
<p>Allowed accumulator types</p>
</div>
<table class="tableblock frame-all grid-all" style="width: 99%;">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Value</th>
<th class="tableblock halign-left valign-top">Description</th>
<th class="tableblock halign-left valign-top">Required Extension</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">INT32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">32-bit integer</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">FP16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">16-bit floating-point</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">FP32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">32-bit floating-point</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">INT48</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">48-bit integer</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="_var_t">3.3. var_t</h3>
<div class="paragraph">
<p>Variable tensor data type</p>
</div>
<table class="tableblock frame-all grid-all" style="width: 99%;">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Value</th>
<th class="tableblock halign-left valign-top">Description</th>
<th class="tableblock halign-left valign-top">Required Extension</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">BOOLEAN</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">INT8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">8-bit integer</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">INT16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">16-bit integer</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">INT32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">32-bit integer</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">FP16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">5</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">16-bit floating-point</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">BF16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">6</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">16-bit brain floating-point</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">FP32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">7</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">32-bit floating-point</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="_nan_propagation_mode_t">3.4. nan_propagation_mode_t</h3>
<div class="paragraph">
<p>NaN propagation policy</p>
</div>
<table class="tableblock frame-all grid-all" style="width: 99%;">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Value</th>
<th class="tableblock halign-left valign-top">Description</th>
<th class="tableblock halign-left valign-top">Required Extension</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PROPAGATE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">NaN is returned when the operation has a NaN</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">IGNORE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">NaN is ignored when the operation has a NaN. NaN is produced if and only if all operands are NaN</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="_rounding_mode_t">3.5. rounding_mode_t</h3>
<div class="paragraph">
<p>Rounding mode</p>
</div>
<table class="tableblock frame-all grid-all" style="width: 99%;">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Value</th>
<th class="tableblock halign-left valign-top">Description</th>
<th class="tableblock halign-left valign-top">Required Extension</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SINGLE_ROUND</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Perform single rounding.</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">INEXACT_ROUND</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Allow rounding results to be inexact.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-INEXACTROUND</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">DOUBLE_ROUND</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Perform double rounding.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXT-DOUBLEROUND</p></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_tosa_pseudocode">4. TOSA Pseudocode</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The TOSA pseudocode provides precise descriptions of TOSA operations.
Each operator contains pseudocode describing the operator&#8217;s functionality.
This section contains pseudocode functions shared across multiple operators in the specification.</p>
</div>
<div class="sect2">
<h3 id="_for_each">4.1. for_each</h3>
<div class="paragraph">
<p>The TOSA pseudocode uses the <code>for_each</code> loop to describe iterating over a multidimensional range.
<code>for_each</code> is specified as:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">for_each(Amin &lt;= a &lt; Amax, Bmin &lt;= b &lt; Bmax,  ...) {
    <span class="comment">// body statements</span>
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>The body of the <code>for_each</code> is executed for every possible combination of the iteration variables in the condition.
The variables <code>a</code> and <code>b</code> are defined within the scope of the <code>for_each</code> body.</p>
</div>
</div>
<div class="sect2">
<h3 id="_for_each_data_position">4.2. for_each_data_position</h3>
<div class="paragraph">
<p>The TOSA pseudocode uses the <code>for_each_data_position</code> to execute a body over each data position in a shape.
If the shape is empty, the body is executed a single time with the index being the empty list</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++"><span class="comment">// shape must be of type shape_t</span>
for_each_data_position(index in shape) {
    <span class="comment">// body statements</span>
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>is executed as</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++"><span class="keyword">if</span> (shape == []) {
    <span class="comment">// Execute body statements with index == []</span>
}
<span class="keyword">else</span> {
    <span class="comment">// Execute body statements with index iterating over all locations in the shape</span>
}</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_operator_validation_helpers">4.3. Operator Validation Helpers</h3>
<div class="paragraph">
<p>The following functions are used to define the valid conditions for TOSA operators.</p>
</div>
<div class="paragraph">
<p>The REQUIRE function defines the conditions required by the TOSA operator.
If the conditions are not met then the result of the TOSA graph is marked as unpredictable.
Once the tosa_graph_result is set to tosa_unpredictable, the whole graph is considered unpredictable.</p>
</div>
<div class="paragraph">
<p>The ERROR_IF function defines a condition that must set an error if the condition holds and the graph is not unpredictable.
Note that if a graph contains both unpredictable and error statements then result of tosa_execute_graph() is tosa_unpredictable.
This condition is captured in the ERROR_IF function.</p>
</div>
<div class="paragraph">
<p><strong>Implementation Notes</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>An implementation is not required to detect unpredictable behavior. If tosa_execute_graph() returns tosa_unpredictable then the tosa_test_compliance() function does not require any specific output from an implementation.</p>
</li>
<li>
<p>An implementation is required to detect errors in a graph that does not have unpredictable behavior (see tosa_test_compliance).</p>
</li>
<li>
<p>An acceptable implementation is to stop and report an error on the first ERROR_IF condition that occurs. This satisfies tosa_test_compliance() even if the tosa_execute_graph() was tosa_unpredictable.</p>
</li>
<li>
<p>If the tosa_execute_graphs() result is tosa_unpredictable or tosa_error, then there is no requirement on the implementation to execute any portion of the TOSA graph.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++"><span class="directive">void</span> REQUIRE(condition) {
    <span class="comment">// Unpredictable overrides any previous result</span>
    <span class="keyword">if</span> (!(condition)) {
        tosa_graph_result = tosa_unpredictable;
    }
}

<span class="directive">void</span> ERROR_IF(condition) {
    <span class="comment">// Error encodes a predictable error state and so is not registered</span>
    <span class="comment">// if the graph is marked as unpredictable.</span>
    <span class="keyword">if</span> (tosa_graph_result != tosa_unpredictable &amp;&amp; condition) {
        tosa_graph_result = tosa_error;
    }
}

<span class="directive">void</span> LEVEL_CHECK(condition) {
    <span class="comment">// If a level is specified and the level condition fails then</span>
    <span class="comment">// the result is unpredictable.</span>
    REQUIRE(condition);
}</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_tensor_access_helpers">4.4. Tensor Access Helpers</h3>
<div class="sect3">
<h4 id="_tensor_utilities">4.4.1. Tensor Utilities</h4>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++"><span class="comment">// Convert tensor index coordinates to an element offset</span>
tensor_size_t tensor_index_to_offset(shape_t shape, shape_t index) {
    tensor_size_t size = tensor_size(shape);  <span class="comment">// check tensor shape is valid</span>
    tensor_size_t offset = <span class="integer">0</span>;
    <span class="keyword">for</span> (int32_t i = <span class="integer">0</span>; i &lt; rank(shape); i++) {
        REQUIRE(index[i] &gt;= <span class="integer">0</span> &amp;&amp; index[i] &lt; shape[i]);
        offset = offset * shape[i] + index[i];
    }
    <span class="keyword">return</span> offset;
}

<span class="comment">// Convert an element offset to tensor index coordinates</span>
shape_t tensor_offset_to_index(shape_t shape, tensor_size_t offset) {
    tensor_size_t size = tensor_size(shape);  <span class="comment">// check tensor shape is valid</span>
    REQUIRE(offset &lt; size);
    REQUIRE(offset &gt;= <span class="integer">0</span>);
    shape_t index(rank(shape));    <span class="comment">// index has rank(shape) indicies</span>
    <span class="keyword">for</span>(int32_t i = rank(shape) - <span class="integer">1</span>; i &gt;= <span class="integer">0</span>; i--) {
        index[i] = offset % shape[i];
        offset /= shape[i];
    }
    <span class="keyword">return</span> index;
}

<span class="comment">// Check the tensor shape is valid and return the tensor size in elements</span>
tensor_size_t tensor_size(shape_t shape) {
    tensor_size_t size = <span class="integer">1</span>;
    <span class="keyword">for</span> (int32_t i = <span class="integer">0</span>; i &lt; rank(shape); i++) {
        REQUIRE(<span class="integer">1</span> &lt;= shape[i] &amp;&amp; shape[i] &lt;= maximum&lt;tensor_size_t&gt; / size);
        size *= shape[i];
    }
    <span class="keyword">return</span> size;
}

<span class="comment">// Return the size of the tensor in the given axis</span>
<span class="comment">// For a rank=0 tensor, returns 1 for all axes</span>
tensor_size_t shape_dim(shape_t shape, <span class="predefined-type">int</span> axis) {
    <span class="keyword">return</span> (axis &gt;= rank(shape)) ? <span class="integer">1</span> : shape[axis];
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_tensor_read">4.4.2. Tensor Read</h4>
<div class="paragraph">
<p>tensor_read reads a single data value out of the given tensor.
The shape argument contains the shape of the tensor.
Index is the coordinates within the tensor of the value to be read.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">in_t tensor_read&lt;in_t&gt;(in_t *address, shape_t shape, shape_t index) {
    tensor_size_t offset = tensor_index_to_offset(shape, index);
    <span class="keyword">return</span> address[offset];
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_tensor_write">4.4.3. Tensor Write</h4>
<div class="paragraph">
<p>tensor_write writes a single data value into the given tensor.
The shape argument contains the shape of the tensor.
Index is the coordinates within the tensor of the value to be written.
value is the value to be written to the given coordinate.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++"><span class="directive">void</span> tensor_write&lt;type&gt;(&lt;type&gt; *address, shape_t shape, shape_t index, &lt;type&gt; value) {
    tensor_size_t offset = tensor_index_to_offset(shape, index);
    address[offset] = value;
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_variable_tensor_allocate">4.4.4. Variable Tensor Allocate</h4>
<div class="paragraph">
<p>variable_tensor_allocate allocates the mutable persistent memory block for storing variable tensors.
The shape argument contains the shape of the allocated memory block for the variable_tensor.
The 'name' argument is a globally unique identifier for variable tensors.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">tensor_t* variable_tensor_allocate&lt;in_t&gt;(shape_t shape, String name) {
    tensor_size_t size = tensor_size(shape);
    tensor_t *allocated_tensor = <span class="keyword">new</span> tensor_t;
    allocated_tensor-&gt;data = <span class="keyword">new</span> in_t[size];
    allocated_tensor-&gt;name = name;
    allocated_tensor-&gt;is_written = <span class="predefined-constant">false</span>;
    allocated_tensor-&gt;shape = shape;
    allocated_tensor-&gt;type = in_t;
    <span class="keyword">return</span> allocated_tensor;
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_variable_tensor_lookup">4.4.5. Variable Tensor Lookup</h4>
<div class="paragraph">
<p>variable_tensor_lookup checks whether a variable tensor has been allocated or not.
The 'name' argument is a globally unique identifier for variable tensors.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">tensor_t variable_tensor_lookup(String name) {
    <span class="comment">// The global all_allocated_variable_tensors was instantiated at the first</span>
    <span class="comment">// time of executing the tosa graph</span>
    for_each(tensor_t allocated_tensor in all_allocated_variable_tensors) {
        <span class="keyword">if</span> (allocated_tensor.name == name) {
            <span class="keyword">return</span> allocated_tensor;
        }
    }
    <span class="keyword">return</span> <span class="predefined-constant">NULL</span>;
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_broadcast_helpers">4.4.6. Broadcast Helpers</h4>
<div class="paragraph">
<p>The following function derives the broadcast output shape from the input shapes.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">shape_t broadcast_shape(shape_t shape1, shape_t shape2) {
    ERROR_IF(rank(shape1) != rank(shape2));
    shape_t shape = shape1;
    <span class="keyword">for</span> (int32_t i = <span class="integer">0</span>; i &lt; rank(shape); i++) {
        <span class="keyword">if</span> (shape[i] == <span class="integer">1</span>) {
            shape[i] = shape2[i];
        } <span class="keyword">else</span> {
            ERROR_IF(shape2[i] != <span class="integer">1</span> &amp;&amp; shape2[i] != shape[i]);
        }
    }
    <span class="keyword">return</span> shape;
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>The following function maps an index in the output tensor to an index in the input tensor.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++"><span class="comment">// The index argument should be a valid location within out_shape.</span>
<span class="comment">// The function returns the location within in_shape that contributes</span>
<span class="comment">// to the output based on broadcasting rules.</span>

shape_t apply_broadcast(shape_t out_shape, shape_t in_shape, shape_t index) {
    ERROR_IF(rank(out_shape) != rank(in_shape));
    ERROR_IF(rank(out_shape) != rank(index));
    <span class="keyword">for</span> (int32_t i = <span class="integer">0</span>; i &lt; rank(out_shape); i++) {
        <span class="keyword">if</span> (out_shape[i] != in_shape[i]) {
            ERROR_IF(in_shape[i] != <span class="integer">1</span>);
            index[i] = <span class="integer">0</span>;
        }
    }
    <span class="keyword">return</span> index;
}</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_general_pseudocode_helpers">4.5. General Pseudocode Helpers</h3>
<div class="paragraph">
<p>This section contains general pseudocode utility functions used throughout the specification.</p>
</div>
<div class="sect3">
<h4 id="_arithmetic_helpers">4.5.1. Arithmetic Helpers</h4>
<div class="paragraph">
<p>The following functions provide arithmetic while defining requirements such that values stay in the valid range.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">in_t apply_add_s&lt;in_t&gt;(in_t a, in_t b) {
    <span class="keyword">if</span> (is_floating_point&lt;in_t&gt;()) <span class="keyword">return</span> a + b;
    int64_t c = sign_extend&lt;int64_t&gt;(a) + sign_extend&lt;int64_t&gt;(b);
    REQUIRE(c &gt;= minimum_s&lt;in_t&gt;() &amp;&amp; c &lt;= maximum_s&lt;in_t&gt;());
    <span class="keyword">return</span> <span class="keyword">static_cast</span>&lt;in_t&gt;(c);
}

in_t apply_add_u&lt;in_t&gt;(in_t a, in_t b) {
    <span class="keyword">if</span> (is_floating_point&lt;in_t&gt;()) <span class="keyword">return</span> a + b;
    uint64_t c = zero_extend&lt;uint64_t&gt;(a) + zero_extend&lt;uint64_t&gt;(b);
    REQUIRE(c &gt;= minimum_u&lt;in_t&gt;() &amp;&amp; c &lt;= maximum_u&lt;in_t&gt;());
    <span class="keyword">return</span> truncate&lt;in_t&gt;(c);
}

in_t apply_arith_rshift&lt;in_t&gt;(in_t a, in_t b) {
    int32_t c = sign_extend&lt;int32_t&gt;(a) &gt;&gt; sign_extend&lt;int32_t&gt;(b);
    <span class="keyword">return</span> <span class="keyword">static_cast</span>&lt;in_t&gt;(c);
}

in_t apply_intdiv_s&lt;in_t&gt;(in_t a, in_t b) {
    int64_t c = sign_extend&lt;int64_t&gt;(a) / sign_extend&lt;int64_t&gt;(b);
    REQUIRE(c &gt;= minimum_s&lt;in_t&gt;() &amp;&amp; c &lt;= maximum_s&lt;in_t&gt;());
    <span class="keyword">return</span> <span class="keyword">static_cast</span>&lt;in_t&gt;(c);
}

<span class="comment">// return input value rounded up to nearest integer</span>
in_t apply_ceil&lt;in_t&gt;(in_t input);

<span class="comment">// return e to the power input</span>
in_t apply_exp&lt;in_t&gt;(in_t input);

<span class="comment">// return input value rounded down to nearest integer</span>
in_t apply_floor&lt;in_t&gt;(in_t input);

<span class="comment">// return the natural logarithm of input</span>
in_t apply_log_positive_input&lt;in_t&gt;(in_t input);

in_t apply_log&lt;in_t&gt;(in_t input) {
    <span class="keyword">if</span> (input == <span class="integer">0</span>) {
        <span class="keyword">return</span> -INFINITY;
    }
    <span class="keyword">else</span> <span class="keyword">if</span> (input &lt; <span class="integer">0</span>) {
        <span class="keyword">return</span> NaN;
    }
    <span class="keyword">return</span> apply_log_positive_input(input);
}

in_t apply_logical_rshift&lt;in_t&gt;(in_t a, in_t b) {
    uint64_t c = zero_extend&lt;uint32_t&gt;(a) &gt;&gt; zero_extend&lt;uint32_t&gt;(b);
    <span class="keyword">return</span> <span class="keyword">static_cast</span>&lt;in_t&gt;(c);
}

in_t compare_nan&lt;in_t&gt;(in_t a, in_t b, nan_propagation_t nan_mode) {
    REQUIRE(isNaN(a) || isNaN(b));

    <span class="keyword">if</span> (nan_mode == PROPAGATE) {
          <span class="keyword">return</span> NaN;
    }

    <span class="comment">// Non NaN Propagation</span>
    <span class="keyword">return</span> isNaN(a) ? b : a;
}

in_t apply_max_s&lt;in_t&gt;(in_t a, in_t b, nan_propagation_t nan_mode=PROPAGATE) {
    <span class="keyword">if</span> (is_floating_point&lt;in_t&gt;()) {
        <span class="keyword">if</span> (isNaN(a) || isNaN(b)) {
            <span class="keyword">return</span> compare_nan(a, b, nan_mode);
        }
        <span class="keyword">if</span> (a &gt;= b) <span class="keyword">return</span> a; <span class="keyword">else</span> <span class="keyword">return</span> b;
    }
    <span class="comment">// Integer version</span>
    <span class="keyword">if</span> (sign_extend&lt;int64_t&gt;(a) &gt;= sign_extend&lt;int64_t&gt;(b)) <span class="keyword">return</span> a; <span class="keyword">else</span> <span class="keyword">return</span> b;
}

in_t apply_max_u&lt;in_t&gt;(in_t a, in_t b) {
    <span class="keyword">if</span> (zero_extend&lt;uint64_t&gt;(a) &gt;= zero_extend&lt;int64_t&gt;(b)) <span class="keyword">return</span> a; <span class="keyword">else</span> <span class="keyword">return</span> b;
}

in_t apply_min_s&lt;in_t&gt;(in_t a, in_t b, nan_propagation_t nan_mode=PROPAGATE) {
    <span class="keyword">if</span> (is_floating_point&lt;in_t&gt;()) {
        <span class="keyword">if</span> (isNaN(a) || isNaN(b)) {
            <span class="keyword">return</span> compare_nan(a, b, nan_mode);
        }
        <span class="keyword">if</span> (a &lt; b) <span class="keyword">return</span> a; <span class="keyword">else</span> <span class="keyword">return</span> b;
    }
    <span class="comment">// Integer version</span>
    <span class="keyword">if</span> (sign_extend&lt;int64_t&gt;(a) &lt; sign_extend&lt;int64_t&gt;(b)) <span class="keyword">return</span> a; <span class="keyword">else</span> <span class="keyword">return</span> b;
}

in_t apply_min_u&lt;in_t&gt;(in_t a, in_t b) {
    <span class="keyword">if</span> (zero_extend&lt;int64_t&gt;(a) &lt; zero_extend&lt;int64_t&gt;(b)) <span class="keyword">return</span> a; <span class="keyword">else</span> <span class="keyword">return</span> b;
}

in_t apply_clip_s&lt;in_t&gt;(in_t value, in_t min_val, in_t max_val, nan_propagation_t nan_mode=PROPAGATE) {
    <span class="keyword">if</span> (is_floating_point&lt;in_t&gt;()) {
        REQUIRE(min_val &lt;= max_val);
        REQUIRE(!isNaN(min_val) &amp;&amp; !isNaN(max_val));
    }
    <span class="keyword">else</span> {
        REQUIRE(sign_extend&lt;int64_t&gt;(min_val) &lt;= sign_extend&lt;int64_t&gt;(max_val));
    }
    value = apply_max_s&lt;in_t&gt;(value, min_val, nan_mode);
    value = apply_min_s&lt;in_t&gt;(value, max_val, nan_mode);
    <span class="keyword">return</span> value;
}

in_t apply_clip_u&lt;in_t&gt;(in_t value, in_t min_val, in_t max_val) {
    REQUIRE(zero_extend&lt;int64_t&gt;(min_val) &lt;= zero_extend&lt;int64_t&gt;(max_val));
    value = apply_max_u&lt;in_t&gt;(value, min_val);
    value = apply_min_u&lt;in_t&gt;(value, max_val);
    <span class="keyword">return</span> value;
}

in_t apply_mul_s&lt;in_t&gt;(in_t a, in_t b) {
    <span class="keyword">if</span> (is_floating_point&lt;in_t&gt;()) <span class="keyword">return</span> a * b;
    int64_t c = sign_extend&lt;int64_t&gt;(a) * sign_extend&lt;int64_t&gt;(b);
    <span class="keyword">return</span> <span class="keyword">static_cast</span>&lt;in_t&gt;(c);
}

in_t apply_pow&lt;in_t&gt;(in_t a, in_t b) {
    <span class="keyword">return</span> a ** b; <span class="comment">// a raised to the power b</span>
}

<span class="comment">// return the square root of input</span>
in_t apply_sqrt&lt;in_t&gt;(in_t input);

in_t apply_sub_s&lt;in_t&gt;(in_t a, in_t b) {
    <span class="keyword">if</span> (is_floating_point&lt;in_t&gt;()) <span class="keyword">return</span> a - b;
    int64_t c = sign_extend&lt;int64_t&gt;(a) - sign_extend&lt;int64_t&gt;(b);
    REQUIRE(c &gt;= minimum_s&lt;in_t&gt;() &amp;&amp; c &lt;= maximum_s&lt;in_t&gt;());
    <span class="keyword">return</span> <span class="keyword">static_cast</span>&lt;in_t&gt;(c);
}

in_t apply_sub_u&lt;in_t&gt;(in_t a, in_t b) {
    uint64_t c = zero_extend&lt;uint64_t&gt;(a) - zero_extend&lt;uint64_t&gt;(b);
    REQUIRE(c &gt;= minimum_u&lt;in_t&gt;() &amp;&amp; c &lt;= maximum_u&lt;in_t&gt;());
    <span class="keyword">return</span> truncate&lt;in_t&gt;(c);
}

int32_t count_leading_zeros(int32_t a) {
    int32_t acc = <span class="integer">32</span>;
    <span class="keyword">if</span> (a != <span class="integer">0</span>) {
        uint32_t mask;
        mask = <span class="integer">1</span> &lt;&lt; (<span class="integer">32</span> - <span class="integer">1</span>); <span class="comment">// width of int32_t - 1</span>
        acc = <span class="integer">0</span>;
        <span class="keyword">while</span> ((mask &amp; a) == <span class="integer">0</span>) {
            mask = mask &gt;&gt; <span class="integer">1</span>;
            acc = acc + <span class="integer">1</span>;
        }
    }
    <span class="keyword">return</span> acc;
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_type_conversion_helpers">4.5.2. Type Conversion Helpers</h4>
<div class="paragraph">
<p>The following definitions indicate the type to be used when the given parameters are provided.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++"><span class="comment">// Returns a signed version of the given type</span>
<span class="comment">// A no-op for floating-point types</span>
Type make_signed(Type in_t)
{
    <span class="keyword">if</span> (is_floating_point&lt;in_t&gt;()) {
        <span class="keyword">return</span> in_t;
    }
    <span class="keyword">if</span> (is_same&lt;in_t,bool_t&gt;()) {
        <span class="keyword">return</span> bool_t;
    } <span class="keyword">else</span> <span class="keyword">if</span> (is_same&lt;in_t,i8_t&gt;()) {
        <span class="keyword">return</span> int8_t;
    } <span class="keyword">else</span> <span class="keyword">if</span> (is_same&lt;in_t,i16_t&gt;()) {
        <span class="keyword">return</span> int16_t;
    } <span class="keyword">else</span> <span class="keyword">if</span> (is_same&lt;in_t,i32_t&gt;()) {
        <span class="keyword">return</span> int32_t;
    } <span class="keyword">else</span> <span class="keyword">if</span> (is_same&lt;in_t,i48_t&gt;()) {
        <span class="keyword">return</span> int48_t;
    }
}

<span class="comment">// Returns the usigned type of the given type</span>
<span class="comment">// Error to call this with anything but i8_t or i16_t</span>

Type make_unsigned(Type in_t)
{
    ERROR_IF(!is_same&lt;in_t,i8_t&gt;() &amp;&amp; !is_same&lt;in_t,i16_t&gt;());
    <span class="keyword">if</span> (is_same&lt;in_t,i8_t&gt;()) {
        <span class="keyword">return</span> uint8_t;
    } <span class="keyword">else</span> <span class="keyword">if</span> (is_same&lt;in_t,i16_t&gt;()) {
        <span class="keyword">return</span> uint16_t;
    }
}

out_t <span class="keyword">static_cast</span>&lt;out_t&gt;(in_t value)
{
    <span class="comment">// Operates similar to the c++ standard static_cast</span>
    <span class="comment">// Limited to simple numeric conversion for TOSA.</span>
    <span class="comment">// Sign extends signed integer input types if needed</span>
    <span class="comment">// Zero extends unsigned integer input types if needed</span>
    <span class="comment">// Truncates when converting to a smaller width data type</span>
    <span class="comment">// Conversion from integer to floating-point is exact if possible</span>
    <span class="comment">// If converting between signless integer types, treated as signed integer</span>
}

out_t bitcast&lt;out_t&gt;(in_t value)
{
    <span class="comment">// Treats the bits of value as if they were of type out_t</span>
    <span class="comment">// Only supported for integer types of the same bit width</span>
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_numeric_accuracy_helpers">4.5.3. Numeric Accuracy Helpers</h4>
<div class="paragraph">
<p>For a floating point number of type in_t a normal value is of the form (1.x * 2^e).
The fractional part 'x' has a number of fractional or mantissa bits depending on the type.
The exponent 'e' has a normal range depending on the type.
The functions below return the ranges according to type.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">fp64_t exp2(<span class="predefined-type">int</span> n) {
    <span class="keyword">if</span> (n &lt; -<span class="integer">1075</span>) {
        <span class="keyword">return</span> <span class="float">0</span><span class="float">.0</span>; <span class="comment">// smaller than smallest denormal</span>
    }
    REQUIRE(n &lt;= <span class="integer">1023</span>);
    fp64_t v = <span class="float">1</span><span class="float">.0</span>;
    <span class="keyword">while</span> (n &gt; <span class="integer">0</span>) { v = v*<span class="float">2</span><span class="float">.0</span>; n--; }
    <span class="keyword">while</span> (n &lt; <span class="integer">0</span>) { v = v/<span class="float">2</span><span class="float">.0</span>; n++; }
    <span class="keyword">return</span> v;
}

<span class="predefined-type">int</span> ilog2(fp64_t v) {
    REQUIRE(<span class="integer">0</span> &lt; v &amp;&amp; v &lt; infinity);
    <span class="predefined-type">int</span> n = <span class="integer">0</span>;
    <span class="keyword">while</span> (v &gt;= <span class="float">2</span><span class="float">.0</span>) { v = v/<span class="float">2</span><span class="float">.0</span>; n++; }
    <span class="keyword">while</span> (v &lt;  <span class="float">1</span><span class="float">.0</span>) { v = v*<span class="float">2</span><span class="float">.0</span>; n--; }
    <span class="keyword">return</span> n;
}

fp64_t normal_min&lt;in_t&gt;() {
  <span class="keyword">if</span> (is_same&lt;in_t,fp32_t&gt;()) {
    <span class="keyword">return</span> exp2(-<span class="integer">126</span>);
  } <span class="keyword">else</span> <span class="keyword">if</span> (is_same&lt;in_t,bf16_t&gt;()) {
    <span class="keyword">return</span> exp2(-<span class="integer">126</span>);
  } <span class="keyword">else</span> <span class="keyword">if</span> (is_same&lt;in_t,fp16_t&gt;()) {
    <span class="keyword">return</span> exp2( -<span class="integer">14</span>);
  } <span class="keyword">else</span> <span class="keyword">if</span> (is_same&lt;in_t,fp8e4m3_t&gt;()) {
    <span class="keyword">return</span> exp2(-<span class="integer">6</span>);
  } <span class="keyword">else</span> <span class="keyword">if</span> (is_same&lt;in_t,fp8e5m2_t&gt;()) {
    <span class="keyword">return</span> exp2(-<span class="integer">14</span>);
  }
}

fp64_t normal_max&lt;in_t&gt;() {
  <span class="keyword">if</span> (is_same&lt;in_t,fp32_t&gt;()) {
    <span class="keyword">return</span> exp2(<span class="integer">128</span>) - exp2(<span class="integer">127</span>-<span class="integer">23</span>);
  } <span class="keyword">else</span> <span class="keyword">if</span> (is_same&lt;in_t,bf16_t&gt;()) {
    <span class="keyword">return</span> exp2(<span class="integer">128</span>) - exp2(<span class="integer">127</span>- <span class="integer">7</span>);
  } <span class="keyword">else</span> <span class="keyword">if</span> (is_same&lt;in_t,fp16_t&gt;()) {
    <span class="keyword">return</span> exp2( <span class="integer">16</span>) - exp2( <span class="integer">15</span>-<span class="integer">10</span>);
  } <span class="keyword">else</span> <span class="keyword">if</span> (is_same&lt;in_t,fp8e4m3_t&gt;()) {
    <span class="keyword">return</span> exp2( <span class="integer">9</span>) - exp2( <span class="integer">8</span>-<span class="integer">2</span>);
  } <span class="keyword">else</span> <span class="keyword">if</span> (is_same&lt;in_t,fp8e5m2_t&gt;()) {
    <span class="keyword">return</span> exp2( <span class="integer">16</span>) - exp2( <span class="integer">15</span>-<span class="integer">2</span>);
  }
}

<span class="comment">// Number of fractional (mantissa bits)</span>
<span class="predefined-type">int</span> normal_frac&lt;in_t&gt; () {
  <span class="keyword">if</span> (is_same&lt;in_t,fp32_t&gt;()) {
    <span class="keyword">return</span> <span class="integer">23</span>;
  } <span class="keyword">else</span> <span class="keyword">if</span> (is_same&lt;in_t,bf16_t&gt;()) {
    <span class="keyword">return</span>  <span class="integer">7</span>;
  } <span class="keyword">else</span> <span class="keyword">if</span> (is_same&lt;in_t,fp16_t&gt;()) {
    <span class="keyword">return</span> <span class="integer">10</span>;
  } <span class="keyword">else</span> <span class="keyword">if</span> (is_same&lt;in_t,fp8e4m3_t&gt;()) {
    <span class="keyword">return</span> <span class="integer">3</span>;
  } <span class="keyword">else</span> <span class="keyword">if</span> (is_same&lt;in_t,fp8e5m2_t&gt;()) {
    <span class="keyword">return</span> <span class="integer">2</span>;
  }
}

fp64_t calcAbsErrorBound&lt;in_t&gt;(fp64_t bound_magnitude, fp64_t bounds_value,
                               fp64_t lower_bound, fp64_t normal_divisor) {
    fp64_t error_bound = <span class="float">0</span><span class="float">.0</span>;
    <span class="comment">// Avoid cases where we generate an error_bound of NaN by multiplying inf * 0</span>
    <span class="keyword">if</span> (is_finite(bounds_value) || abs(bound_magnitude) != <span class="float">0</span><span class="float">.0</span>) {
      fp64_t value_bound = max(abs(bound_magnitude), normal_min&lt;in_t&gt;());
      <span class="keyword">if</span> (lower_bound &gt; <span class="integer">0</span>) {
        value_bound = max(lower_bound / bounds_value, value_bound);
      }
      error_bound = exp2(-normal_frac&lt;in_t&gt;() / normal_divisor) * value_bound;
      error_bound = error_bound * bounds_value;
    }
    <span class="keyword">return</span> error_bound;
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>The following functions check if a test value in floating-point format in_t is within an error range compared to a reference value.
The functions assume that subnormal values for bf16, fp16, and fp32 may be flushed to zero.
For the first function, the permitted error range is specified as num_ulp which is converted to an error bound as specified by the code.
For the second function, the permitted error range is specified as an absolute error bound.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">bool_t tosa_reference_check_fp_bnd&lt;in_t&gt;(in_t test_value, fp64_t ref_value, fp64_t err_bnd) {
  <span class="keyword">if</span> (isNaN(ref_value)) {
    <span class="comment">// If the reference value is a NaN, the test value must also be any NaN.</span>
    <span class="keyword">return</span> isNaN(test_value);
  }
  <span class="keyword">if</span> (!is_finite(err_bnd)) {
    <span class="keyword">return</span> <span class="predefined-constant">true</span>;
  }
  REQUIRE(err_bnd &gt;= <span class="float">0</span><span class="float">.0</span>);
  <span class="keyword">if</span> (ref_value &lt; <span class="integer">0</span>) {
    ref_value  = -ref_value;
    test_value = -test_value;
  }

  fp64_t ref_max = ref_value + err_bnd;
  fp64_t ref_min = ref_value - err_bnd;

  <span class="keyword">if</span> (ref_max &gt; normal_max&lt;in_t&gt;()) ref_max = infinity;
  <span class="keyword">if</span> (ref_min &gt; normal_max&lt;in_t&gt;()) ref_min = infinity;
  <span class="keyword">if</span> (ref_min &lt; -normal_max&lt;in_t&gt;()) ref_min = -infinity;

  <span class="keyword">if</span> (is_same&lt;in_t,bf16_t&gt;() || is_same&lt;in_t,fp16_t&gt;() || is_same&lt;in_t,fp32_t&gt;()) {
    <span class="comment">// Allow subnormal values to be flushed to zero for non-fp8</span>
    <span class="keyword">if</span> (test_value == <span class="integer">0</span>) <span class="keyword">return</span> (ref_min &lt; normal_min());
  }

  <span class="keyword">if</span> (is_same&lt;in_t,fp8e4m3_t&gt;() &amp;&amp; isNaN(test_value)) {
    <span class="comment">// The case where ref is NaN is handled at the beginning of the function</span>
    <span class="comment">// The following check is enough because `abs(ref_max) &gt;= abs(ref_min)` and</span>
    <span class="comment">// `ref_max &gt;= 0`.</span>
    <span class="keyword">return</span> ref_max == infinity;
  }

  <span class="comment">// Overflow/subnormals have been handled, can do a standard check</span>
  <span class="comment">// at this point.</span>
  <span class="keyword">return</span> (<span class="keyword">static_cast</span>&lt;fp64_t&gt;(test_value) &gt;= ref_min &amp;&amp;
          <span class="keyword">static_cast</span>&lt;fp64_t&gt;(test_value) &lt;= ref_max);
}

fp64_t tosa_reference_ulp&lt;in_t&gt;(fp64_t ref_value) {
  <span class="keyword">if</span> (is_normal_fp64(ref_value) &amp;&amp; abs(ref_value) != <span class="integer">0</span>) {
    <span class="predefined-type">int</span> ref_exp = ilog2(abs(ref_value));
    fp64_t ref_pow2 = max(exp2(ref_exp), normal_min&lt;in_t&gt;());
    <span class="keyword">return</span> ref_pow2 * exp2(-normal_frac&lt;in_t&gt;());
  }
  <span class="keyword">return</span> <span class="float">0</span><span class="float">.0</span>;
}

bool_t tosa_reference_check_fp&lt;in_t&gt;(in_t test_value, fp64_t ref_value, fp64_t num_ulp) {
  fp64_t err_bnd = tosa_reference_ulp&lt;in_t&gt;(ref_value) * num_ulp;
  <span class="keyword">return</span> tosa_reference_check_fp_bnd&lt;in_t&gt;(test_value, ref_value, err_bnd);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_numeric_conversion_helpers">4.5.4. Numeric Conversion Helpers</h4>
<div class="paragraph">
<p>The following definitions are used in pseudocode to do numeric conversions.
Where the <strong>float_t</strong> type is used, it represents all of the floating-point data types supported by the given profile.
See <a href="#Number formats">[Number formats]</a> for details on the floating-point formats.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++"><span class="comment">// Converts the floating-point value to an integer value using round to nearest rounding.</span>
<span class="predefined-type">int</span> round_to_nearest_int(float_t f);

<span class="comment">// Converts the input value into floating-point, using round to nearest rounding.</span>
<span class="comment">// Values that are not NaN outside of the representable range of the destination type must be set to infinity of the correct sign.</span>
<span class="comment">// If the destination floating point type does not have an infinity representation, values outside of the representable range must be set to NaN.</span>
float_t round_to_nearest_float(in_t f);

<span class="comment">// Floating point values are unchanged.</span>
<span class="comment">// For two's complement integer values where out_t has more bits than in_t, replicate the top bit of input for all bits between the top bit of input and the top bit of output.</span>
out_t sign_extend&lt;out_t&gt;(in_t input);

<span class="comment">// Floating point values are unchanged.</span>
<span class="comment">// For two's complement integer values where out_t has more bits than in_t, insert zero values for all bits between the top bit of input and the top bit of output.</span>
out_t zero_extend&lt;out_t&gt;(in_t input);

<span class="comment">// output is the sizeof(out_t) least significant bits in input.</span>
<span class="comment">// Nop for floating-point types</span>
out_t truncate(in_t input);</code></pre>
</div>
</div>
<div class="paragraph">
<p>The following definition is used to flatten a list of lists into a single list.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">shape_t flatten(shape_t shapes[]) {
    shape_t output = [];
    for_each(shape in shapes) {
        for_each(element in shapes) {
            output.append(element);
        }
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Generic helper functions used to keep the pseudocode concise.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">bool_t is_floating_point&lt;type&gt;() {
    <span class="keyword">if</span> (is_same&lt;type,fp16_t&gt;() || is_same&lt;type,fp32_t&gt;() || is_same&lt;type,bf16_t&gt;() || is_same&lt;type,fp8e4m3_t&gt;() || is_same&lt;type,fp8e5m2_t&gt;()) {
        <span class="keyword">return</span> <span class="predefined-constant">true</span>;
    }
    <span class="keyword">return</span> <span class="predefined-constant">false</span>;
}

int32_t idiv(int32_t input1, int32_t input2) {
    <span class="keyword">return</span> input1 / input2; <span class="comment">// Integer divide that truncates towards zero</span>
}

<span class="comment">// Integer division that checks input1 is a multiple of input2</span>

int32_t idiv_check(int32_t input1, int32_t input2) {
    ERROR_IF(input1 % input2 != <span class="integer">0</span>); <span class="comment">// input1 must be a multiple of input2</span>
    <span class="keyword">return</span> input1 / input2;         <span class="comment">// exact quotient without rounding</span>
}

<span class="comment">// perform an integer division with rounding towards minus infinity</span>

int32_t idiv_floor(int32_t input1, int32_t input2) {
    int32_t rval = input1 / input2;
    <span class="keyword">if</span> (rval * input2 &gt; input1) {
        rval--;
    }
    <span class="keyword">return</span> rval;
}

<span class="comment">// return number of elements in input list</span>
int32_t length(in_t input);

<span class="comment">// return rank of an input tensor</span>
int32_t rank(in_t input);

<span class="comment">// return the sum of values of an input list</span>
int32_t sum(in_t input[]);

<span class="comment">// returns value of pi</span>
float_t pi();

<span class="comment">// return sine of angle given in radians</span>
float_t sin(float_t angle);

<span class="comment">// return cosine of angle given in radians</span>
float_t cos(float_t angle);

<span class="comment">// return true if value is a power of two, false otherwise</span>
bool_t power_of_two(int32_t value);

<span class="comment">// return the maximum value when interpreting type in_out_t as a signed value as returned by the make_signed helper.</span>
in_out_t maximum_s&lt;in_out_t&gt;();

<span class="comment">// return the minimum value when interpreting type in_out_t as a signed value as returned by the make_signed helper.</span>
in_out_t minimum_s&lt;in_out_t&gt;();

<span class="comment">// return the maximum value when interpreting type in_out_t as an unsigned value as returned by the make_unsigned helper.</span>
in_out_t maximum_u&lt;in_out_t&gt;();

<span class="comment">// return the minimum value when interpreting type in_out_t as an unsigned value as returned by the make_unsigned helper.</span>
in_out_t minimum_u&lt;in_out_t&gt;();

<span class="comment">// return true if the given value is a NaN. Only valid for floating-point types</span>
bool_t isNaN(in_t value);

<span class="comment">// return true if the given value is an Infinity. Only valid for floating-point types</span>
bool_t isInf(in_t input);

<span class="comment">// return true if value is a normal fp64 value (Not zero, subnormal, infinite or NaN)</span>
bool_t is_normal_fp64(fp64_t value);</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_scaling_helpers">4.5.5. Scaling Helpers</h4>
<div class="paragraph">
<p>Helper functions used to scale between different integer domains</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">int32_t apply_scale_32(int32_t value, int32_t multiplier, int8_t shift, bool_t double_round=<span class="predefined-constant">false</span>) {
    REQUIRE(multiplier &gt;= <span class="integer">0</span>);
    REQUIRE(<span class="integer">2</span> &lt;= shift &amp;&amp; shift &lt;= <span class="integer">62</span>);
    REQUIRE(value &gt;= (-<span class="integer">1</span> &lt;&lt; (shift - <span class="integer">1</span>)) &amp;&amp; value &lt; (<span class="integer">1</span> &lt;&lt; (shift - <span class="integer">1</span>)));
    int64_t round = <span class="integer">1</span> &lt;&lt; (shift - <span class="integer">1</span>);
    <span class="keyword">if</span> (double_round) {
        <span class="keyword">if</span> (shift &gt; <span class="integer">31</span> &amp;&amp; value &gt;= <span class="integer">0</span>) round += <span class="integer">1</span>&lt;&lt;<span class="integer">30</span>;
        <span class="keyword">if</span> (shift &gt; <span class="integer">31</span> &amp;&amp; value &lt; <span class="integer">0</span>)  round -= <span class="integer">1</span>&lt;&lt;<span class="integer">30</span>;
    }
    int64_t result = (<span class="keyword">static_cast</span>&lt;int64_t&gt;(value) * multiplier) + round;
    result &gt;&gt;= shift;
    <span class="comment">// result will fit a 32-bit range due to the REQUIRE on value</span>
    <span class="keyword">return</span> <span class="keyword">static_cast</span>&lt;int32_t&gt;(result);
}

int32_t apply_scale_16(int48_t value, int16_t multiplier, int8_t shift) {
    REQUIRE(multiplier &gt;= <span class="integer">0</span>);
    REQUIRE(<span class="integer">2</span> &lt;= shift &amp;&amp; shift &lt;= <span class="integer">62</span>);
    int64_t round = <span class="integer">1</span> &lt;&lt; (shift - <span class="integer">1</span>);
    int64_t result = (<span class="keyword">static_cast</span>&lt;int64_t&gt;(value) * multiplier) + round;
    result &gt;&gt;= shift;
    REQUIRE(result &gt;= minimum&lt;int32_t&gt; &amp;&amp; result &lt;= maximum&lt;int32_t&gt;);
    <span class="keyword">return</span> <span class="keyword">static_cast</span>&lt;int32_t&gt;(result);
}

<span class="comment">// Struct which describes the scale factors</span>
<span class="keyword">typedef</span> <span class="keyword">struct</span> {
    int32_t multiplier;
    int8_t shift;
} scale_t;

<span class="comment">// Calculate an appropriate scale factor to use when a divide is required</span>
scale_t reciprocal_scale(uint32_t value) {
    REQUIRE(value &gt; <span class="integer">0</span>);
    scale_t scale;
    int32_t k = <span class="integer">32</span> - count_leading_zeros(value - <span class="integer">1</span>); <span class="comment">// (1 &lt;&lt; k) / 2 &lt; value &lt;= (1 &lt;&lt; k)</span>
    int64_t numerator = ((<span class="integer">1</span> &lt;&lt; <span class="integer">30</span>) + <span class="integer">1</span>) &lt;&lt; k;
    scale.multiplier = numerator / value; <span class="comment">// (1 &lt;&lt; 30) &lt;= multiplier &lt; (1 &lt;&lt; 31)</span>
    scale.shift = <span class="integer">30</span> + k;
    <span class="keyword">return</span> scale;
}</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_appendix_a">5. Appendix A</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_random_data_generation">5.1. Random Data Generation</h3>
<div class="paragraph">
<p>The following function generates a pseudo-random floating-point value in the range -1.0 to +1.0 for use as test data.
It uses a modulo (1&lt;&lt;32) recurrent sequence with multiplier derived from "TOSASETS" and the set number.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++"><span class="predefined-type">float</span> set_data(uint32_t set, uint32_t index)
{
    uint32_t m = (<span class="integer">8</span>*set + <span class="integer">1</span>) * <span class="hex">0x705A5E75</span>;   <span class="comment">// mod (1&lt;&lt;32) calculation</span>
    uint32_t r = m + <span class="integer">1</span>;                      <span class="comment">// mod (1&lt;&lt;32) calculation</span>
    <span class="keyword">for</span> (uint32_t i = <span class="integer">0</span>; i &lt; index; i++) {
        r = r * m + <span class="integer">1</span>;                       <span class="comment">// mod (1&lt;&lt;32) calculation</span>
    }
    <span class="predefined-type">float</span>  sign = (r&gt;&gt;<span class="integer">31</span>)==<span class="integer">0</span> ? +<span class="integer">1</span> : -<span class="integer">1</span>;
    <span class="keyword">return</span> sign * (<span class="predefined-type">float</span>)(r &amp; <span class="hex">0x7FFFFFFF</span>) / (<span class="predefined-type">float</span>)(<span class="hex">0x7FFFFFFF</span>);
}</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_floating_point_test_data_generator">5.2. Floating-Point Test Data Generator</h3>
<div class="paragraph">
<p>This section describes the function tosa_pro_fp_data(S, KS, p, k, i) that generates test data for floating-point profile compliance.
This function takes the following arguments:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>S is the test set number which identifies which generator is used</p>
</li>
<li>
<p>KS is the kernel size</p>
</li>
<li>
<p>p is the parameter number of:</p>
<div class="ulist">
<ul>
<li>
<p>0 for the first input (usually data)</p>
</li>
<li>
<p>1 for the second input (usually weights)</p>
</li>
<li>
<p>2 for the third input if present (usually bias)</p>
</li>
</ul>
</div>
</li>
<li>
<p>k is the index within the kernel in the range 0 &lt;= k &lt; KS</p>
</li>
<li>
<p>i is the index within the tensor to write</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Some test data values are scaled by the bound parameter B which is defined in the table below.
B is set to be the largest value that is both representable by the input type and such that B*B does not overflow the output precision.
In the case of mixed input types, B is the largest value that is representable by both input types such that B*B does not overflow the output precision.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">inputs type</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output type</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">B value</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">(1&lt;&lt;8) - (1&lt;&lt;4)  = 240</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">448</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">(1&lt;&lt;8) - (1&lt;&lt;5)  = 224</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">57344</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3 and fp8e5m2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">224</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3 and fp8e5m2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">448</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">20</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">224</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">(1&lt;&lt;8)  - (1/8)  = 255.875</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">(1&lt;&lt;16) - (1&lt;&lt;5) = 65504</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">(1&lt;&lt;64) - (1&lt;&lt;56)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">(1&lt;&lt;64) - (1&lt;&lt;56)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">(1&lt;&lt;64) - (1&lt;&lt;40)</p></td>
</tr>
</tbody>
</table>
<div class="sect3">
<h4 id="_test_set_s0_generator">5.2.1. Test Set S=0 Generator</h4>
<div class="paragraph">
<p>The aim of this generator is to check that sum of products with zero gives zero result.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 10%;">
<col style="width: 90%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">p</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">tosa_pro_fp_data(S, KS, p, k, i) =</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">set_data(3*S, i) &lt; 0 ? 0.0 : set_data(3*S+1, i)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">set_data(3*S, i) &lt; 0 ? set_data(3*S+1, i) : 0.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.0</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_test_set_s1">5.2.2. Test Set S=1</h4>
<div class="paragraph">
<p>The aim of this test set is to check values with large exponents.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 10%;">
<col style="width: 90%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">p</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">tosa_pro_fp_data(S, KS, p, k, i) =</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">(B/sqrt(KS+1))*((set_data(3*S+0, i*2) &lt; 0 ? -0.75 : 0.75) + 0.25*set_data(3*S+0, 2*i+1) )</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">(B/sqrt(KS+1))*((set_data(3*S+1, i*2) &lt; 0 ? -0.75 : 0.75) + 0.25*set_data(3*S+1, 2*i+1) )</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">(B*B/(KS+1))*((set_data(3*S+2, i*2) &lt; 0 ? -0.75 : 0.75) + 0.25*set_data(3*S+2, 2*i+1) )</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_test_set_s2">5.2.3. Test Set S=2</h4>
<div class="paragraph">
<p>The aim of this test set is to check rounding error when accumulating small values onto a large value.
In this case the small values are of similar magnitude.
If the implementation changes the order of the sum, then the test data must also be reordered so that the largest values occur first in the sum.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 10%;">
<col style="width: 90%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">p</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">tosa_pro_fp_data(S, KS, p, k, i) =</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">(k==0) ? 1.0 : set_data(3*S+0, i)/sqrt(KS)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">(k==0) ? 1.0 : set_data(3*S+1, i)/sqrt(KS)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.0</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_test_set_s3">5.2.4. Test Set S=3</h4>
<div class="paragraph">
<p>The aim of this test set is to check rounding error when accumulating small values onto a large value.
In this case the small values are of varying magnitude.
If the implementation changes the order of the sum, then the test data must also be reordered so that the largest values occur first in the sum.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 10%;">
<col style="width: 90%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">p</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">tosa_pro_fp_data(S, KS, p, k, i) =</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">(k==0) ? ((set_data(3*S+0, 2*i+0) &lt; 0) ? -16.0 : 16.0) : exp(2*set_data(3*S+0, 2*i+0) ) * set_data(3*S+0, 2*i+1)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">(k==0) ? ((set_data(3*S+1, 2*i+0) &lt; 0) ? -16.0 : 16.0) : exp(2*set_data(3*S+1, 2*i+0) ) * set_data(3*S+1, 2*i+1)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.0</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_test_set_s4">5.2.5. Test Set S=4</h4>
<div class="paragraph">
<p>The aim of this test set is to check a mixture of zero and non-zero products.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 10%;">
<col style="width: 90%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">p</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">tosa_pro_fp_data(S, KS, p, k, i) =</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">(k==KS/2) ? (set_data(3*S, i) &lt; 0 ? -0.5 : +0.5) : (set_data(3*S, i) &lt; 0 ? 0.0 : (B/sqrt(KS))*set_data(3*S+1, i))</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">(k==KS/2) ? (set_data(3*S, i) &lt; 0 ? +0.5 : -0.5) : (set_data(3*S, i) &lt; 0 ? (B/sqrt(KS))*set_data(3*S+1, i) : 0.0)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.0</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_test_set_s5">5.2.6. Test Set S=5</h4>
<div class="paragraph">
<p>The aim of this test set is to check signed inputs of large range.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 10%;">
<col style="width: 90%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">p</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">tosa_pro_fp_data(S, KS, p, k, i) =</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">(B/sqrt(KS))*set_data(3*S+0, i)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">(B/sqrt(KS))*set_data(3*S+1, i)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.0</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_floating_point_operator_test_data">5.3. Floating-Point Operator Test Data</h3>
<div class="paragraph">
<p>For each operator, this section defines how to generate test data for test set S.
For the results to be statistically significant the operation must calculate at least MIN_DOT_PRODUCTS dot products.
For most operations this means that the output tensor must have at least MIN_DOT_PRODUCTS output values.
For most operations batch size can be increased if necessary so that this holds.
For this version of the specification, MIN_DOT_PRODUCTS is set to 1000.</p>
</div>
<div class="sect3">
<h4 id="_conv2d_2">5.3.1. CONV2D</h4>
<div class="paragraph">
<p>The following generates input test data for test set S.
For compliant implementation, the test must pass whenever the attributes satisfy:
<code>N*OH*OW*OC &gt;= MIN_DOT_PRODUCTS</code></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">KS = KW*KH*IC;
<span class="keyword">for</span> (<span class="integer">0</span> &lt;= n &lt; N, <span class="integer">0</span> &lt;= iy &lt; IH, <span class="integer">0</span> &lt;= ix &lt; IW, <span class="integer">0</span> &lt;= ic &lt; IC) {
  input [ n, iy, ix, ic] = tosa_pro_fp_data(S, KS, <span class="integer">0</span>, ((iy % KH)*KW+(ix % KW))*IC+ic, ((n*IH+iy)*IW+ix)*IC+ic);
}
<span class="keyword">for</span> (<span class="integer">0</span> &lt;= oc &lt; OC, <span class="integer">0</span> &lt;= ky &lt; KH, <span class="integer">0</span> &lt;= kx &lt; KW, <span class="integer">0</span> &lt;= ic &lt; IC) {
  weight[oc, ky, kx, ic] = tosa_pro_fp_data(S, KS, <span class="integer">1</span>, (ky*KW+kx)*IC+ic, ((oc*KH+ky)*KW+kx)*IC+ic);
}
<span class="keyword">for</span> (<span class="integer">0</span> &lt;= oc &lt; BC) {
  bias[oc] = tosa_pro_fp_data(S, KS, <span class="integer">2</span>, oc)
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_conv3d_2">5.3.2. CONV3D</h4>
<div class="paragraph">
<p>The following generates input test data for test set S.
For compliant implementation, the test must pass whenever the attributes satisfy:
<code>N*OD*OH*OW*OC &gt;= MIN_DOT_PRODUCTS</code></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">KS = KD*KW*KH*IC;
<span class="keyword">for</span> (<span class="integer">0</span> &lt;= n &lt; N, <span class="integer">0</span> &lt;= id &lt; UD, <span class="integer">0</span> &lt;= iy &lt; IH, <span class="integer">0</span> &lt;= ix &lt; IW, <span class="integer">0</span> &lt;= ic &lt; IC) {
  input [ n, id, iy, ix, ic] = tosa_pro_fp_data(S, KS, <span class="integer">0</span>, (((id % KD)*KH+(iy % KH))*KW+(ix % KW))*IC+ic, (((n*ID+id)*IH+iy)*IW+ix)*IC+ic);
}
<span class="keyword">for</span> (<span class="integer">0</span> &lt;= oc &lt; OC, <span class="integer">0</span> &lt;= kd &lt; KD, <span class="integer">0</span> &lt;= ky &lt; KH, <span class="integer">0</span> &lt;= kx &lt; KW, <span class="integer">0</span> &lt;= ic &lt; IC) {
  weight[oc, kd, ky, kx, ic] = tosa_pro_fp_data(S, KS, <span class="integer">1</span>, ((kd*KH+ky)*KW+kx)*IC+ic, (((oc*KD+kd)*KH+ky)*KW+kx)*IC+ic);
}
<span class="keyword">for</span> (<span class="integer">0</span> &lt;= oc &lt; BC) {
  bias[oc] = tosa_pro_fp_data(S, KS, <span class="integer">2</span>, oc)
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_depthwise_conv2d_2">5.3.3. DEPTHWISE_CONV2D</h4>
<div class="paragraph">
<p>The following generates input test data for test set S.
For compliant implementation, the test must pass whenever the attributes satisfy:
<code>N*OH*OW*C*M &gt;= MIN_DOT_PRODUCTS</code></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">KS = KW*KH;
<span class="keyword">for</span> (<span class="integer">0</span> &lt;= n &lt; N, <span class="integer">0</span> &lt;= iy &lt; IH, <span class="integer">0</span> &lt;= ix &lt; IW, <span class="integer">0</span> &lt;= c &lt; C) {
  input [ n, iy, ix, c] = tosa_pro_fp_data(S, KS, <span class="integer">0</span>, (iy % KH)*KW+(ix % KW), ((n*IH+iy)*IW+ix)*C+c);
}
<span class="keyword">for</span> (<span class="integer">0</span> &lt;= ky &lt; KH, <span class="integer">0</span> &lt;= kx &lt; KW, <span class="integer">0</span> &lt;= c &lt; C, <span class="integer">0</span> &lt;= m &lt; M) {
  weight[ky, kx,  c, m] = tosa_pro_fp_data(S, KS, <span class="integer">1</span>, (ky*KW+kx), ((ky*KW+kx)*C+c)*M+m);
}
<span class="keyword">for</span> (<span class="integer">0</span> &lt;= oc &lt; C*M) {
  bias[oc] = tosa_pro_fp_data(S, KS, <span class="integer">2</span>, oc)
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_matmul_2">5.3.4. MATMUL</h4>
<div class="paragraph">
<p>The following generates input test data for test set S.
For compliant implementation, the test must pass whenever the attributes satisfy:
<code>N*H*W &gt;= MIN_DOT_PRODUCTS</code></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">KS = C;
<span class="keyword">for</span> (<span class="integer">0</span> &lt;= n &lt; N, <span class="integer">0</span> &lt;= y &lt; H, <span class="integer">0</span> &lt;= c &lt; C) {
  A[n, y, c] = tosa_pro_fp_data(S, KS, <span class="integer">0</span>, c, (n*H+y)*C+c);
}
<span class="keyword">for</span> (<span class="integer">0</span> &lt;= n &lt; N, <span class="integer">0</span> &lt;= c &lt; C, <span class="integer">0</span> &lt;= x &lt; W) {
  B[n, c, x] = tosa_pro_fp_data(S, KS, <span class="integer">1</span>, c, (n*C+c)*W+x);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_transpose_conv2d_2">5.3.5. TRANSPOSE_CONV2D</h4>
<div class="paragraph">
<p>The following generates input test data for test set S.
For compliant implementation, the test must pass whenever the attributes satisfy:
<code>N*OH*OW*OC &gt;= MIN_DOT_PRODUCTS</code></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">KS = KW*KH*IC;
<span class="keyword">for</span> (<span class="integer">0</span> &lt;= n &lt; N, <span class="integer">0</span> &lt;= iy &lt; IH, <span class="integer">0</span> &lt;= ix &lt; IW, <span class="integer">0</span> &lt;= ic &lt; IC) {
  input [ n, iy, ix, ic] = tosa_pro_fp_data(S, KS, <span class="integer">0</span>, ((iy % KH)*KW+(ix % KW))*IC+ic, ((n*IH+iy)*IW+ix)*IC+ic);
}
<span class="keyword">for</span> (<span class="integer">0</span> &lt;= oc &lt; OC, <span class="integer">0</span> &lt;= ky &lt; KH, <span class="integer">0</span> &lt;= kx &lt; KW, <span class="integer">0</span> &lt;= ic &lt; IC) {
  weight[oc, ky, kx, ic] = tosa_pro_fp_data(S, KS, <span class="integer">1</span>, (ky*KW+kx)*IC+ic, ((oc*KH+ky)*KW+kx)*IC+ic);
}
<span class="keyword">for</span> (<span class="integer">0</span> &lt;= oc &lt; BC) {
  bias[oc] = tosa_pro_fp_data(S, KS, <span class="integer">2</span>, oc)
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_fft2d_2">5.3.6. FFT2D</h4>
<div class="paragraph">
<p>The following generates input test data for test set S.
For compliant implementation, the test must pass whenever the attributes satisfy:
<code>N*H*W &gt;= MIN_DOT_PRODUCTS</code></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">KS = <span class="integer">2</span>*H*W;
<span class="keyword">for</span> (<span class="integer">0</span> &lt;= n &lt; N, <span class="integer">0</span> &lt;= y &lt; H, <span class="integer">0</span> &lt;= x &lt; W) {
  input_real[n, y, x] = tosa_pro_fp_data(S, KS, <span class="integer">0</span>, y*W+x, ((<span class="integer">0</span>*N+n)*H+y)*IW+x);
  input_imag[n, y, x] = tosa_pro_fp_data(S, KS, <span class="integer">0</span>, y*W+x, ((<span class="integer">1</span>*N+n)*H+y)*IW+x);
}
<span class="keyword">for</span> (<span class="integer">0</span> &lt;= y &lt; H, <span class="integer">0</span> &lt;= x &lt; W, <span class="integer">0</span> &lt;= m &lt; H, <span class="integer">0</span> &lt;= n &lt; W) {
  weight_real[y, x, m, n] = real(exp(<span class="integer">2</span>*pi*i*((m*h/H) + (n*w/W))));
  weight_imag[y, x, m, n] = imag(exp(<span class="integer">2</span>*pi*i*((m*h/H) + (n*w/W))));
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_rfft2d_2">5.3.7. RFFT2D</h4>
<div class="paragraph">
<p>The following generates input test data for test set S.
For compliant implementation, the test must pass whenever the attributes satisfy:
<code>N*H*W &gt;= MIN_DOT_PRODUCTS</code></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">KS = H*W;
<span class="keyword">for</span> (<span class="integer">0</span> &lt;= n &lt; N, <span class="integer">0</span> &lt;= y &lt; H, <span class="integer">0</span> &lt;= x &lt; W) {
  input_real[n, y, x] = tosa_pro_fp_data(S, KS, <span class="integer">0</span>, y*W+x, ((<span class="integer">0</span>*N+n)*H+y)*IW+x);
}
<span class="keyword">for</span> (<span class="integer">0</span> &lt;= y &lt; H, <span class="integer">0</span> &lt;= x &lt; W, <span class="integer">0</span> &lt;= m &lt; H, <span class="integer">0</span> &lt;= n &lt; W) {
  weight_real[y, x, m, n] = real(exp(<span class="integer">2</span>*pi*i*((m*h/H) + (n*w/W))));
  weight_imag[y, x, m, n] = imag(exp(<span class="integer">2</span>*pi*i*((m*h/H) + (n*w/W))));
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_reduce_sum_2">5.3.8. REDUCE_SUM</h4>
<div class="paragraph">
<p>The following generates input test data for test set S.
For compliant implementation, the test must pass whenever the attributes satisfy:
<code>tensor_size(shape) &gt;= MIN_DOT_PRODUCTS</code></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">KS = shape1[axis];
<span class="keyword">for</span> (index in shape1) {
  input[index] = tosa_pro_fp_data(S, KS, <span class="integer">0</span>, index[axis], tensor_index_to_offset(index));
}
<span class="keyword">for</span> (<span class="integer">0</span> &lt;= c &lt; KS) {
  weight[c] = <span class="integer">1</span>;
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_avg_pool2d_2">5.3.9. AVG_POOL2D</h4>
<div class="paragraph">
<p>The following generates input test data for test set S.
For compliant implementation, the test must pass whenever the attributes satisfy:
<code>N*OH*OW*C &gt;= MIN_DOT_PRODUCTS</code></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="c++">KX = kernel_x;
KY = kernel_y;
KS = KX*KY;
<span class="keyword">for</span> (<span class="integer">0</span> &lt;= n &lt; N, <span class="integer">0</span> &lt;= iy &lt; IH, <span class="integer">0</span> &lt;= ix &lt; IW, <span class="integer">0</span> &lt;= c &lt; C) {
  input [ n, iy, ix, c] = tosa_pro_fp_data(S, KS, <span class="integer">0</span>, ((iy % KY)*KX+(ix % KX))*C+c, ((n*IH+iy)*IW+ix)*C+c);
}
<span class="keyword">for</span> (<span class="integer">0</span> &lt;= ky &lt; KY, <span class="integer">0</span> &lt;= kx &lt; KX, <span class="integer">0</span> &lt;= c &lt; C, <span class="integer">0</span> &lt;= m &lt; M) {
  weight[ky, kx] = <span class="integer">1</span>/KS;
}</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_appendix_b_profile_operator_tables">6. Appendix B - Profile operator tables</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_profiles_2">6.1. Profiles</h3>
<div class="sect3">
<h4 id="_integer">6.1.1. Integer</h4>
<div class="paragraph">
<p>Integer operations, primarily 8- and 32-bit values</p>
</div>
<div class="paragraph">
<p>Status: Complete</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Operator</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">Version Added</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ABS</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ADD</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ARGMAX</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ARITHMETIC_RIGHT_SHIFT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ARITHMETIC_RIGHT_SHIFT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ARITHMETIC_RIGHT_SHIFT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">AVG_POOL2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8 with int32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">BITWISE_AND</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">BITWISE_AND</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">BITWISE_AND</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">BITWISE_NOT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">BITWISE_NOT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">BITWISE_NOT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">BITWISE_OR</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">BITWISE_OR</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">BITWISE_OR</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">BITWISE_XOR</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">BITWISE_XOR</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">BITWISE_XOR</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool to signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool to signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool to signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8 to bool</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8 to signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8 to signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16 to bool</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16 to signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16 to signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32 to bool</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32 to signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32 to signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CLAMP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CLZ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONCAT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONCAT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONCAT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">8-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">16-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">32-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONST_SHAPE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONV2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8x8 with int32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONV3D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8x8 with int32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CUSTOM</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">All</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">DEPTHWISE_CONV2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8x8 with int32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EQUAL</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">GATHER</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">GATHER</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">GATHER</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">GREATER</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">GREATER_EQUAL</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">IDENTITY</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">IDENTITY</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">8-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">IDENTITY</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">16-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">IDENTITY</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">32-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">INTDIV</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">LOGICAL_AND</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">LOGICAL_LEFT_SHIFT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">LOGICAL_LEFT_SHIFT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">LOGICAL_LEFT_SHIFT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">LOGICAL_NOT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">LOGICAL_OR</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">LOGICAL_RIGHT_SHIFT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">LOGICAL_RIGHT_SHIFT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">LOGICAL_RIGHT_SHIFT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">LOGICAL_XOR</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MATMUL</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8x8 with int32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MAXIMUM</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MAX_POOL2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MINIMUM</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MUL</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MUL</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MUL</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">NEGATE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">NEGATE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">NEGATE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PAD</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PAD</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PAD</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PAD</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">REDUCE_ALL</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">REDUCE_ANY</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">REDUCE_MAX</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">REDUCE_MAX</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">REDUCE_MAX</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">REDUCE_MIN</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">REDUCE_MIN</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">REDUCE_MIN</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">REDUCE_SUM</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RESCALE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">8-bit to 8-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RESCALE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">8-bit to 16-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RESCALE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">8-bit to 32-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RESCALE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">16-bit to 8-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RESCALE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">16-bit to 16-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RESCALE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">16-bit to 32-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RESCALE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">32-bit to 8-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RESCALE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">32-bit to 16-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RESCALE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">32-bit to 32-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RESHAPE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RESHAPE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RESHAPE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RESHAPE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RESIZE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8, bilinear</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RESIZE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8, nearest</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">REVERSE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">REVERSE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">REVERSE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">REVERSE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SCATTER</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SCATTER</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SCATTER</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SELECT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SELECT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SELECT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SELECT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SLICE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SLICE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SLICE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SLICE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SUB</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TABLE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TILE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TILE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TILE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TILE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TRANSPOSE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TRANSPOSE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TRANSPOSE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TRANSPOSE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TRANSPOSE_CONV2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8x8 with int32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_floating_point">6.1.2. Floating-Point</h4>
<div class="paragraph">
<p>FP16 and FP32 operations</p>
</div>
<div class="paragraph">
<p>Status: Complete</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Operator</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">Version Added</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ABS</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ABS</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ADD</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ADD</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ADD</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ARGMAX</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ARGMAX</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">AVG_POOL2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 with fp16 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">AVG_POOL2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">AVG_POOL2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8 to fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8 to fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16 to fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16 to fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32 to fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32 to fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 to signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 to signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 to signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 to fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32 to signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32 to signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32 to signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32 to fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CEIL</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CEIL</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CLAMP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CLAMP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONCAT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONCAT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONCAT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">8-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">16-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">32-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONST_SHAPE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONV2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 with fp16 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONV2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONV2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONV3D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 with fp16 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONV3D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONV3D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">COS</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">COS</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CUSTOM</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">All</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">DEPTHWISE_CONV2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 with fp16 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">DEPTHWISE_CONV2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">DEPTHWISE_CONV2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EQUAL</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EQUAL</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ERF</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ERF</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">FLOOR</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">FLOOR</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">GATHER</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">GATHER</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">GREATER</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">GREATER</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">GREATER_EQUAL</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">GREATER_EQUAL</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">IDENTITY</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">IDENTITY</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">8-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">IDENTITY</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">16-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">IDENTITY</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">32-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">IDENTITY</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">IDENTITY</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">INTDIV</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">LOG</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">LOG</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">LOGICAL_AND</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">LOGICAL_LEFT_SHIFT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">LOGICAL_LEFT_SHIFT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">LOGICAL_LEFT_SHIFT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">LOGICAL_NOT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">LOGICAL_OR</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">LOGICAL_RIGHT_SHIFT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">LOGICAL_RIGHT_SHIFT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">LOGICAL_RIGHT_SHIFT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">LOGICAL_XOR</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MATMUL</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 with fp16 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MATMUL</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MATMUL</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MAXIMUM</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MAXIMUM</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MAX_POOL2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MAX_POOL2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MINIMUM</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MINIMUM</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MUL</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MUL</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MUL</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">NEGATE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">NEGATE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PAD</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PAD</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PAD</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">POW</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">POW</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RECIPROCAL</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RECIPROCAL</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">REDUCE_ALL</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">REDUCE_ANY</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">REDUCE_MAX</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">REDUCE_MAX</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">REDUCE_MIN</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">REDUCE_MIN</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">REDUCE_PRODUCT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">REDUCE_PRODUCT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">REDUCE_SUM</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">REDUCE_SUM</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RESHAPE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RESHAPE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RESHAPE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RESIZE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RESIZE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">REVERSE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">REVERSE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">REVERSE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RSQRT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RSQRT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SCATTER</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SCATTER</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SELECT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SELECT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SELECT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SIGMOID</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SIGMOID</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SIN</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SIN</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SLICE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SLICE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SLICE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SUB</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SUB</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SUB</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TANH</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TANH</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TILE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TILE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TILE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TRANSPOSE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TRANSPOSE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TRANSPOSE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TRANSPOSE_CONV2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 with fp16 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TRANSPOSE_CONV2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TRANSPOSE_CONV2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_profile_extensions">6.2. Profile Extensions</h3>
<div class="sect3">
<h4 id="_ext_int16_extension">6.2.1. EXT-INT16 extension</h4>
<div class="paragraph">
<p>16-bit integer operations</p>
</div>
<div class="paragraph">
<p>Status: Complete</p>
</div>
<div class="paragraph">
<p>Compatible profiles: PRO-INT</p>
</div>
<div class="paragraph">
<p><strong>Operator Change Table</strong></p>
</div>
<table class="tableblock frame-all grid-all" style="width: 99%;">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Operator</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">Version Added</th>
<th class="tableblock halign-left valign-top">Note</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ARGMAX</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">AVG_POOL2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16 with int32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CLAMP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONCAT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">48-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONV2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16x8 with int48 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONV3D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16x8 with int48 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">DEPTHWISE_CONV2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16x8 with int48 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">IDENTITY</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">48-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MATMUL</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16x16 with int48 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MAX_POOL2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RESCALE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">48-bit to 8-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RESCALE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">48-bit to 16-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RESCALE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">48-bit to 32-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RESIZE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16, bilinear</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RESIZE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16, nearest</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TABLE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TRANSPOSE_CONV2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16x8 with int48 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_ext_int4_extension">6.2.2. EXT-INT4 extension</h4>
<div class="paragraph">
<p>4-bit integer weights</p>
</div>
<div class="paragraph">
<p>Status: Complete</p>
</div>
<div class="paragraph">
<p>Compatible profiles: PRO-INT</p>
</div>
<div class="paragraph">
<p><strong>Operator Change Table</strong></p>
</div>
<table class="tableblock frame-all grid-all" style="width: 99%;">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Operator</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">Version Added</th>
<th class="tableblock halign-left valign-top">Note</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">4-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONV2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8x4 with int32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONV3D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8x4 with int32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">DEPTHWISE_CONV2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8x4 with int32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">IDENTITY</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">4-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TRANSPOSE_CONV2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8x4 with int32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_ext_bf16_extension">6.2.3. EXT-BF16 extension</h4>
<div class="paragraph">
<p>BFloat16 operations</p>
</div>
<div class="paragraph">
<p>Status: Experimental</p>
</div>
<div class="paragraph">
<p>Compatible profiles: PRO-FP</p>
</div>
<div class="paragraph">
<p><strong>Operator Change Table</strong></p>
</div>
<table class="tableblock frame-all grid-all" style="width: 99%;">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Operator</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">Version Added</th>
<th class="tableblock halign-left valign-top">Note</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ABS</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ADD</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ARGMAX</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">AVG_POOL2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8 to bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16 to bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32 to bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16 to signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16 to signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16 to signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16 to fp8e4m3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">If EXT-FP8E4M3 is also supported</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16 to fp8e5m2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">If EXT-FP8E5M2 is also supported</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16 to fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3 to bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">If EXT-FP8E4M3 is also supported</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2 to bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">If EXT-FP8E5M2 is also supported</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32 to bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CEIL</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CLAMP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONCAT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONV2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONV3D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">COS</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">DEPTHWISE_CONV2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EQUAL</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ERF</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EXP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">FLOOR</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">GATHER</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">GREATER</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">GREATER_EQUAL</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">IDENTITY</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">LOG</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MATMUL</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MAXIMUM</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MAX_POOL2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MINIMUM</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MUL</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">NEGATE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PAD</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">POW</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RECIPROCAL</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">REDUCE_MAX</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">REDUCE_MIN</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">REDUCE_PRODUCT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">REDUCE_SUM</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RESHAPE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RESIZE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">REVERSE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RSQRT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SCATTER</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SELECT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SIGMOID</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SIN</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SLICE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SUB</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TANH</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TILE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TRANSPOSE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TRANSPOSE_CONV2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_ext_fp8e4m3_extension">6.2.4. EXT-FP8E4M3 extension</h4>
<div class="paragraph">
<p>8-bit floating-point operations E4M3</p>
</div>
<div class="paragraph">
<p>Status: Experimental</p>
</div>
<div class="paragraph">
<p>Compatible profiles: PRO-FP</p>
</div>
<div class="paragraph">
<p><strong>Operator Change Table</strong></p>
</div>
<table class="tableblock frame-all grid-all" style="width: 99%;">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Operator</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">Version Added</th>
<th class="tableblock halign-left valign-top">Note</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ARGMAX</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">AVG_POOL2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3 with fp16 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16 to fp8e4m3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">If EXT-BF16 is also supported</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3 to fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3 to bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">If EXT-BF16 is also supported</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3 to fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 to fp8e4m3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32 to fp8e4m3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONCAT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONV2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3 with fp16 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONV3D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3 with fp16 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">DEPTHWISE_CONV2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3 with fp16 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">GATHER</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">IDENTITY</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MATMUL</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3 with fp16 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MAX_POOL2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PAD</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RESHAPE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">REVERSE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SCATTER</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SLICE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TILE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TRANSPOSE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TRANSPOSE_CONV2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e4m3 with fp16 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_ext_fp8e5m2_extension">6.2.5. EXT-FP8E5M2 extension</h4>
<div class="paragraph">
<p>8-bit floating-point operations E5M2</p>
</div>
<div class="paragraph">
<p>Status: Experimental</p>
</div>
<div class="paragraph">
<p>Compatible profiles: PRO-FP</p>
</div>
<div class="paragraph">
<p><strong>Operator Change Table</strong></p>
</div>
<table class="tableblock frame-all grid-all" style="width: 99%;">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Operator</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">Version Added</th>
<th class="tableblock halign-left valign-top">Note</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ARGMAX</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">AVG_POOL2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2 with fp16 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16 to fp8e5m2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">If EXT-BF16 is also supported</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2 to fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2 to bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">If EXT-BF16 is also supported</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2 to fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 to fp8e5m2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CAST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32 to fp8e5m2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONCAT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONV2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2 with fp16 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONV3D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2 with fp16 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">DEPTHWISE_CONV2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2 with fp16 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">GATHER</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">IDENTITY</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MATMUL</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2 with fp16 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MAX_POOL2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PAD</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RESHAPE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">REVERSE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SCATTER</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SLICE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TILE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TRANSPOSE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TRANSPOSE_CONV2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp8e5m2 with fp16 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_ext_fft_extension">6.2.6. EXT-FFT extension</h4>
<div class="paragraph">
<p>Fast Fourier Transform operations</p>
</div>
<div class="paragraph">
<p>Status: Complete</p>
</div>
<div class="paragraph">
<p>Compatible profiles: PRO-FP</p>
</div>
<div class="paragraph">
<p><strong>Operator Change Table</strong></p>
</div>
<table class="tableblock frame-all grid-all" style="width: 99%;">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Operator</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">Version Added</th>
<th class="tableblock halign-left valign-top">Note</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">FFT2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RFFT2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_ext_variable_extension">6.2.7. EXT-VARIABLE extension</h4>
<div class="paragraph">
<p>Stateful variable operations</p>
</div>
<div class="paragraph">
<p>Status: Experimental</p>
</div>
<div class="paragraph">
<p>Compatible profiles: PRO-INT, PRO-FP</p>
</div>
<div class="paragraph">
<p><strong>Operator Change Table</strong></p>
</div>
<table class="tableblock frame-all grid-all" style="width: 99%;">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Operator</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">Version Added</th>
<th class="tableblock halign-left valign-top">Note</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">VARIABLE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">If PRO-INT is also supported</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">VARIABLE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">If PRO-FP is also supported</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">VARIABLE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">If PRO-FP is also supported</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">VARIABLE_READ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">If PRO-INT is also supported</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">VARIABLE_READ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">If PRO-FP is also supported</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">VARIABLE_READ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">If PRO-FP is also supported</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">VARIABLE_WRITE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">If PRO-INT is also supported</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">VARIABLE_WRITE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">If PRO-FP is also supported</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">VARIABLE_WRITE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">If PRO-FP is also supported</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_ext_controlflow_extension">6.2.8. EXT-CONTROLFLOW extension</h4>
<div class="paragraph">
<p>Control Flow operations</p>
</div>
<div class="paragraph">
<p>Status: Experimental</p>
</div>
<div class="paragraph">
<p>Compatible profiles: PRO-INT, PRO-FP</p>
</div>
<div class="paragraph">
<p><strong>Operator Change Table</strong></p>
</div>
<table class="tableblock frame-all grid-all" style="width: 99%;">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Operator</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">Version Added</th>
<th class="tableblock halign-left valign-top">Note</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">COND_IF</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">All</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">WHILE_LOOP</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">All</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_ext_dynamic_extension">6.2.9. EXT-DYNAMIC extension</h4>
<div class="paragraph">
<p>Removes all Compile Time Constant state for CTC inputs</p>
</div>
<div class="paragraph">
<p>Status: Experimental</p>
</div>
<div class="paragraph">
<p>Compatible profiles: PRO-INT, PRO-FP</p>
</div>
<div class="paragraph">
<p><strong>Operator Change Table</strong></p>
</div>
<table class="tableblock frame-all grid-all" style="width: 99%;">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Operator</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">Version Added</th>
<th class="tableblock halign-left valign-top">Note</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">AVG_POOL2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">all</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Remove CTC from input_zp</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">AVG_POOL2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">all</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Remove CTC from output_zp</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONV2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">all</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Remove CTC from input_zp</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONV2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">all</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Remove CTC from weight_zp</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONV3D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">all</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Remove CTC from input_zp</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CONV3D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">all</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Remove CTC from weight_zp</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">DEPTHWISE_CONV2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">all</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Remove CTC from input_zp</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">DEPTHWISE_CONV2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">all</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Remove CTC from weight_zp</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MATMUL</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">all</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Remove CTC from A_zp</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MATMUL</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">all</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Remove CTC from B_zp</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MUL</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">all</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Remove CTC from shift</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">NEGATE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">all</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Remove CTC from input1_zp</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">NEGATE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">all</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Remove CTC from output_zp</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PAD</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">all</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Remove CTC from padding</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PAD</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">all</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Remove CTC from pad_const</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RESCALE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">all</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Remove CTC from multiplier</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RESCALE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">all</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Remove CTC from shift</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RESCALE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">all</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Remove CTC from input_zp</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RESCALE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">all</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Remove CTC from output_zp</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RESHAPE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">all</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Remove CTC from shape</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RESIZE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">all</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Remove CTC from scale</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RESIZE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">all</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Remove CTC from offset</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RESIZE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">all</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Remove CTC from border</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SLICE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">all</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Remove CTC from start</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SLICE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">all</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Remove CTC from size</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TABLE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">all</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Remove CTC from table</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TILE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">all</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Remove CTC from multiples</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TRANSPOSE_CONV2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">all</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Remove CTC from input_zp</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TRANSPOSE_CONV2D</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">all</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Remove CTC from weight_zp</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_ext_doubleround_extension">6.2.10. EXT-DOUBLEROUND extension</h4>
<div class="paragraph">
<p>Adds double rounding support to the RESCALE operator</p>
</div>
<div class="paragraph">
<p>Status: Complete</p>
</div>
<div class="paragraph">
<p>Compatible profiles: PRO-INT</p>
</div>
<div class="paragraph">
<p><strong>Operator Change Table</strong></p>
</div>
<table class="tableblock frame-all grid-all" style="width: 99%;">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Operator</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">Version Added</th>
<th class="tableblock halign-left valign-top">Note</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">No changes</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Enum Changes</strong></p>
</div>
<table class="tableblock frame-all grid-all" style="width: 99%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Enum</th>
<th class="tableblock halign-left valign-top">Value</th>
<th class="tableblock halign-left valign-top">Note</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">rounding_mode_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">DOUBLE_ROUND</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">New Value</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_ext_inexactround_extension">6.2.11. EXT-INEXACTROUND extension</h4>
<div class="paragraph">
<p>Adds inexact rounding support to the RESCALE operator</p>
</div>
<div class="paragraph">
<p>Status: Experimental</p>
</div>
<div class="paragraph">
<p>Compatible profiles: PRO-INT</p>
</div>
<div class="paragraph">
<p><strong>Operator Change Table</strong></p>
</div>
<table class="tableblock frame-all grid-all" style="width: 99%;">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Operator</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">Version Added</th>
<th class="tableblock halign-left valign-top">Note</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">No changes</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Enum Changes</strong></p>
</div>
<table class="tableblock frame-all grid-all" style="width: 99%;">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Enum</th>
<th class="tableblock halign-left valign-top">Value</th>
<th class="tableblock halign-left valign-top">Note</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">rounding_mode_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">INEXACT_ROUND</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">New Value</p></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_appendix_c_rationale">7. Appendix C - Rationale</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This appendix documents the rationale behind decisions made while creating the TOSA specification.
Explanations and definitions contained in this appendix are non-normative.</p>
</div>
<div class="sect2">
<h3 id="_fp8">7.1. FP8</h3>
<div class="paragraph">
<p>The operators that perform calculations on FP8 data types are limited.
Fewer mantissa bits in FP8 make it inappropriate for use in most elementwise operations such as <a href="#_add">ADD</a>.
Support was also added to the data layout and movement operations on the understanding that no calculations are performed.
Two extensions for the FP8 types were created in order to cover both formats defined by <a href="#OCP-OFP8">OCP-OFP8</a>.</p>
</div>
</div>
<div class="sect2">
<h3 id="_transcendental_functions">7.2. Transcendental Functions</h3>
<div class="paragraph">
<p>In the TOSA specification, a limited number of transcendental operations are supported.
The operators supported are sufficient for common networks while minimizing the number of operations an implementation must support.
Originally, SIGMOID and TANH were added as the common functions used for activations.
ERF was added to support GELU style activation functions.
SIN and COS were added to provide a base level of trigonometric functionality as well as support for Rotary Position Embedding.</p>
</div>
</div>
<div class="sect2">
<h3 id="_removed_operators">7.3. Removed Operators</h3>
<div class="paragraph">
<p>In version 0.90, a set of shape operators were introduced to attempt to allow dynamically shaped network to be expressed completely with TOSA.
There are gaps in this implementation, and as such the shape operators have been removed.
This removes the requirement on future implementations retain compatibility with these operators.
The shape_t type remains, and the CONST_SHAPE operator allows creating instances of shape_t type.</p>
</div>
<div class="paragraph">
<p>FULLY_CONNECTED has been removed from TOSA.
FULLY_CONNECTED functionality can be achieved by using the CONV2D operator.
Using CONV2D allows the bias add to be included in the operator, where MATMUL does not include bias support.</p>
</div>
</div>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Last updated 2024-11-20 09:11:04 -0800
</div>
</div>
</body>
</html>
