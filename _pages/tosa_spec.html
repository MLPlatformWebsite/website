---
layout: none
permalink: /tosa/tosa_spec.html
---
<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 2.0.17">
<title>TOSA 0.30.0 specification</title>
<style>
/* Asciidoctor default stylesheet | MIT License | https://asciidoctor.org */
/* Remove comment around @import statement below when using as a custom stylesheet */
article,aside,details,figcaption,figure,footer,header,hgroup,main,nav,section,summary{display:block}
audio,canvas,video{display:inline-block}
audio:not([controls]){display:none;height:0}
[hidden],template{display:none}
script{display:none!important}
html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}
body{margin:0}
a{background:transparent}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
abbr[title]{border-bottom:1px dotted}
b,strong{font-weight:bold}
dfn{font-style:italic}
hr{-moz-box-sizing:content-box;box-sizing:content-box;height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type="button"],input[type="reset"],input[type="submit"]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type="checkbox"],input[type="radio"]{box-sizing:border-box;padding:0}
input[type="search"]{-webkit-appearance:textfield;-moz-box-sizing:content-box;-webkit-box-sizing:content-box;box-sizing:content-box}
input[type="search"]::-webkit-search-cancel-button,input[type="search"]::-webkit-search-decoration{-webkit-appearance:none}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,*:before,*:after{-moz-box-sizing:border-box;-webkit-box-sizing:border-box;box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Helvetica Neue", "Helvetica", Helvetica, Arial, sans-serif; font-weight: normal;font-style:normal;line-height:1;position:relative;cursor:auto}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
body{-webkit-font-smoothing:antialiased}
img,object,svg{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
.center{margin-left:auto;margin-right:auto}
.spread{width:100%}
p.lead,.paragraph.lead>p,#preamble>.sectionbody>.paragraph:first-of-type p{font-size:1.21875em;line-height:1.6}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#002b49;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0;direction:ltr}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:none}
p{font-family:inherit;font-weight:400;font-size:1em;line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#002b49;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #ddddd8;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em;height:0}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:Consolas,"Liberation Mono", Courier, monospace;font-weight:normal;color:rgba(0,0,0,.9)}
ul,ol,dl{font-size:1em;line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol,ul.no-bullet,ol.no-bullet{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0;font-size:1em}
ul.square li ul,ul.circle li ul,ul.disc li ul{list-style:inherit}
ul.square{list-style-type:square}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ul.no-bullet{list-style:none}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
abbr,acronym{text-transform:uppercase;font-size:90%;color:rgba(0,0,0,.8);border-bottom:1px dotted #ddd;cursor:help}
abbr{text-transform:none}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote cite{display:block;font-size:.9375em;color:rgba(0,0,0,.6)}
blockquote cite:before{content:"\2014 \0020"}
blockquote cite a,blockquote cite a:visited{color:rgba(0,0,0,.6)}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media only screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}
table{background:#fff;margin-bottom:1.25em;border:solid 1px #dedede}
table thead,table tfoot{background:#f7f8f7;font-weight:bold}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt,table tr:nth-of-type(even){background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{display:table-cell;line-height:1.6}
body{tab-size:4}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.clearfix:before,.clearfix:after,.float-group:before,.float-group:after{content:" ";display:table}
.clearfix:after,.float-group:after{clear:both}
*:not(pre)>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background-color:#f7f7f8;-webkit-border-radius:4px;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed}
pre,pre>code{line-height:1.45;color:rgba(0,0,0,.9);font-family:Consolas, "Liberation Mono", Courier, monospace;font-weight:normal;text-rendering:optimizeSpeed}
.keyseq{color:rgba(51,51,51,.8)}
kbd{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;display:inline-block;color:rgba(0,0,0,.8);font-size:.65em;line-height:1.45;background-color:#f7f7f7;border:1px solid #ccc;-webkit-border-radius:3px;border-radius:3px;-webkit-box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em white inset;box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em #fff inset;margin:0 .15em;padding:.2em .5em;vertical-align:middle;position:relative;top:-.1em;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menu{color:rgba(0,0,0,.8)}
b.button:before,b.button:after{position:relative;top:-1px;font-weight:400}
b.button:before{content:"[";padding:0 3px 0 2px}
b.button:after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin-left:auto;margin-right:auto;margin-top:0;margin-bottom:0;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header:before,#header:after,#content:before,#content:after,#footnotes:before,#footnotes:after,#footer:before,#footer:after{content:" ";display:table}
#header:after,#content:after,#footnotes:after,#footer:after{clear:both}
#content{margin-top:1.25em}
#content:before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #ddddd8}
#header>h1:only-child,body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #ddddd8;padding-bottom:8px}
#header .details{border-bottom:1px solid #ddddd8;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:-ms-flexbox;display:-webkit-flex;display:flex;-ms-flex-flow:row wrap;-webkit-flex-flow:row wrap;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span:before{content:"\00a0\2013\00a0"}
#header .details br+span.author:before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark:before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber:after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #ddddd8;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #efefed;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Noto",sans-serif;list-style-type:none}
#toc li{line-height:1.3334;margin-top:.3334em}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#002b49;font-size:1.2em}
@media only screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
#toc.toc2{margin-top:0!important;background-color:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #efefed;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;margin-bottom:.8rem;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #efefed;left:auto;right:0}}
@media only screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}
#content #toc{border-style:solid;border-width:1px;border-color:#e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;-webkit-border-radius:4px;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:100%;background-color:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:rgba(255,255,255,.8);line-height:1.44}
.sect1{padding-bottom:.625em}
@media only screen and (min-width:768px){.sect1{padding-bottom:1.25em}}
.sect1+.sect1{border-top:1px solid #efefed}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor:before,h2>a.anchor:before,h3>a.anchor:before,#toctitle>a.anchor:before,.sidebarblock>.content>.title>a.anchor:before,h4>a.anchor:before,h5>a.anchor:before,h6>a.anchor:before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem}
table.tableblock>caption.title{white-space:nowrap;overflow:visible;max-width:0}
.paragraph.lead>p,#preamble>.sectionbody>.paragraph:first-of-type p{color:rgba(0,0,0,.85)}
table.tableblock #preamble>.sectionbody>.paragraph:first-of-type p{font-size:inherit}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #ddddd8;color:rgba(0,0,0,.6)}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border-style:solid;border-width:1px;border-color:#e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;-webkit-border-radius:4px;border-radius:4px}
.exampleblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child{margin-bottom:0}
.sidebarblock{border-style:solid;border-width:1px;border-color:#e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;-webkit-border-radius:4px;border-radius:4px}
.sidebarblock>:first-child{margin-top:0}
.sidebarblock>:last-child{margin-bottom:0}
.sidebarblock>.content>.title{color:#002b49;margin-top:0;text-align:center}
.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock pre:not(.highlight),.listingblock pre[class="highlight"],.listingblock pre[class^="highlight "],.listingblock pre.CodeRay,.listingblock pre.prettyprint{background:#f7f7f8}
.sidebarblock .literalblock pre,.sidebarblock .listingblock pre:not(.highlight),.sidebarblock .listingblock pre[class="highlight"],.sidebarblock .listingblock pre[class^="highlight "],.sidebarblock .listingblock pre.CodeRay,.sidebarblock .listingblock pre.prettyprint{background:#f2f1f1}
.literalblock pre,.literalblock pre[class],.listingblock pre,.listingblock pre[class]{-webkit-border-radius:4px;border-radius:4px;word-wrap:break-word;padding:1em;font-size:.8125em}
.literalblock pre.nowrap,.literalblock pre[class].nowrap,.listingblock pre.nowrap,.listingblock pre[class].nowrap{overflow-x:auto;white-space:pre;word-wrap:normal}
@media only screen and (min-width:768px){.literalblock pre,.literalblock pre[class],.listingblock pre,.listingblock pre[class]{font-size:.90625em}}
@media only screen and (min-width:1280px){.literalblock pre,.literalblock pre[class],.listingblock pre,.listingblock pre[class]{font-size:1em}}
.literalblock.output pre{color:#f7f7f8;background-color:rgba(0,0,0,.9)}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;-webkit-border-radius:4px;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.listingblock>.content{position:relative}
.listingblock code[data-lang]:before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:#999}
.listingblock:hover code[data-lang]:before{display:block}
.listingblock.terminal pre .command:before{content:attr(data-prompt);padding-right:.5em;color:#999}
.listingblock.terminal pre .command:not([data-prompt]):before{content:"$"}
table.pyhltable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.pyhltable td{vertical-align:top;padding-top:0;padding-bottom:0;line-height:1.45}
table.pyhltable td.code{padding-left:.75em;padding-right:0}
pre.pygments .lineno,table.pyhltable td:not(.code){color:#999;padding-left:0;padding-right:.5em;border-right:1px solid #ddddd8}
pre.pygments .lineno{display:inline-block;margin-right:.25em}
table.pyhltable .linenodiv{background:none!important;padding-right:0!important}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock blockquote p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote:before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#002b49;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.5em;margin-right:.5ex;text-align:right}
.quoteblock .quoteblock{margin-left:0;margin-right:0;padding:.5em 0;border-left:3px solid rgba(0,0,0,.6)}
.quoteblock .quoteblock blockquote{padding:0 0 0 .75em}
.quoteblock .quoteblock blockquote:before{display:none}
.verseblock{margin:0 1em 1.25em 1em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.025em;color:rgba(0,0,0,.6)}
.quoteblock.abstract{margin:0 0 1.25em 0;display:block}
.quoteblock.abstract blockquote,.quoteblock.abstract blockquote p{text-align:left;word-spacing:0}
.quoteblock.abstract blockquote:before,.quoteblock.abstract blockquote p:first-of-type:before{display:none}
table.tableblock{max-width:100%;border-collapse:separate}
table.tableblock td>.paragraph:last-child p>p:last-child,table.tableblock th>p:last-child,table.tableblock td>p:last-child{margin-bottom:0}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table thead tr th{background:rgba(0,145,189,0.6); color:white}
table.grid-all th.tableblock,table.grid-all td.tableblock{border-width:0 1px 1px 0}
table.grid-all tfoot>tr>th.tableblock,table.grid-all tfoot>tr>td.tableblock{border-width:1px 1px 0 0}
table.grid-cols th.tableblock,table.grid-cols td.tableblock{border-width:0 1px 0 0}
table.grid-all *>tr>.tableblock:last-child,table.grid-cols *>tr>.tableblock:last-child{border-right-width:0}
table.grid-rows th.tableblock,table.grid-rows td.tableblock{border-width:0 0 1px 0}
table.grid-all tbody>tr:last-child>th.tableblock,table.grid-all tbody>tr:last-child>td.tableblock,table.grid-all thead:last-child>tr>th.tableblock,table.grid-rows tbody>tr:last-child>th.tableblock,table.grid-rows tbody>tr:last-child>td.tableblock,table.grid-rows thead:last-child>tr>th.tableblock{border-bottom-width:0}
table.grid-rows tfoot>tr>th.tableblock,table.grid-rows tfoot>tr>td.tableblock{border-width:1px 0 0 0}
table.frame-all{border-width:1px}
table.frame-sides{border-width:0 1px}
table.frame-topbot{border-width:1px 0}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{display:table-cell;line-height:1.6;background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
td>div.verse{white-space:pre}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
ol>li p,ul>li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.unstyled,ol.unnumbered,ul.checklist,ul.none{list-style-type:none}
ul.unstyled,ol.unnumbered,ul.checklist{margin-left:.625em}
ul.checklist li>p:first-child>.fa-square-o:first-child,ul.checklist li>p:first-child>.fa-check-square-o:first-child{width:1em;font-size:.85em}
ul.checklist li>p:first-child>input[type="checkbox"]:first-child{width:1em;position:relative;top:1px}
ul.inline{margin:0 auto .625em auto;margin-left:-1.375em;margin-right:0;padding:0;list-style:none;overflow:hidden}
ul.inline>li{list-style:none;float:left;margin-left:1.375em;display:block}
ul.inline>li>*{display:block}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1,td.hdlist2{vertical-align:top;padding:0 .625em}
td.hdlist1{font-weight:bold;padding-bottom:1.25em}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist>table tr>td:first-of-type{padding:0 .75em;line-height:1}
.colist>table tr>td:last-of-type{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:solid 4px #fff;-webkit-box-shadow:0 0 0 1px #ddd;box-shadow:0 0 0 1px #ddd}
.imageblock.left,.imageblock[style*="float: left"]{margin:.25em .625em 1.25em 0}
.imageblock.right,.imageblock[style*="float: right"]{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none;display:inline-block}
a.image object{pointer-events:none}
sup.footnote,sup.footnoteref{font-size:.875em;position:static;vertical-align:super}
sup.footnote a,sup.footnoteref a{text-decoration:none}
sup.footnote a:active,sup.footnoteref a:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em 0;border-width:1px 0 0 0}
#footnotes .footnote{padding:0 .375em 0 .225em;line-height:1.3334;font-size:.875em;margin-left:1.2em;text-indent:-1.05em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
.gist .file-data>table{border:0;background:#fff;width:100%;margin-bottom:0}
.gist .file-data>table td.line-data{width:99%}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background-color:#00fafa}
.black{color:#000}
.black-background{background-color:#000}
.blue{color:#0000bf}
.blue-background{background-color:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background-color:#fa00fa}
.gray{color:#606060}
.gray-background{background-color:#7d7d7d}
.green{color:#006000}
.green-background{background-color:#007d00}
.lime{color:#00bf00}
.lime-background{background-color:#00fa00}
.maroon{color:#600000}
.maroon-background{background-color:#7d0000}
.navy{color:#000060}
.navy-background{background-color:#00007d}
.olive{color:#606000}
.olive-background{background-color:#7d7d00}
.purple{color:#600060}
.purple-background{background-color:#7d007d}
.red{color:#bf0000}
.red-background{background-color:#fa0000}
.silver{color:#909090}
.silver-background{background-color:#bcbcbc}
.teal{color:#006060}
.teal-background{background-color:#007d7d}
.white{color:#bfbfbf}
.white-background{background-color:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background-color:#fafa00}
span.icon>.fa{cursor:default}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note:before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip:before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning:before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution:before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important:before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background-color:rgba(0,0,0,.8);-webkit-border-radius:100px;border-radius:100px;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]:after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
dt,th.tableblock,td.content,div.footnote{text-rendering:optimizeLegibility}
h1,h2,p,td.content,span.alt{letter-spacing:-.01em}
p strong,td.content strong,div.footnote strong{letter-spacing:-.005em}
p,blockquote,dt,td.content,span.alt{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background-color:#fffef7;border-color:#e0e0dc;-webkit-box-shadow:0 1px 4px #e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@media print{@page{margin:1.25cm .75cm}
*{-webkit-box-shadow:none!important;box-shadow:none!important;text-shadow:none!important}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^=";http:"]:not(.bare):after,a[href^="https:"]:not(.bare):after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]:after{content:" (" attr(title) ")"}
pre,blockquote,tr,img,object,svg{page-break-inside:avoid}
thead{display:table-header-group}
svg{max-width:100%}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #ddddd8!important;padding-bottom:0!important}
.sect1{padding-bottom:0!important}
.sect1+.sect1{border:0!important}
#header>h1:first-child{margin-top:1.25rem}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em 0}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span:before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]:before{display:block}
#footer{background:none!important;padding:0 .9375em}
#footer-text{color:rgba(0,0,0,.6)!important;font-size:.9em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}

</style>
</head>
<body class="article toc2 toc-left">
<div id="header">
<h1>TOSA 0.30.0 specification</h1>
<div class="details">
<span id="revnumber">version 0.30.0</span>
</div>
<div id="toc" class="toc2">
<div id="toctitle">Table of Contents</div>
<ul class="sectlevel1">
<li><a href="#_introduction">1. Introduction</a>
<ul class="sectlevel2">
<li><a href="#_overview">1.1. Overview</a></li>
<li><a href="#_goals">1.2. Goals</a></li>
<li><a href="#_specification">1.3. Specification</a></li>
<li><a href="#_operator_selection_principles">1.4. Operator Selection Principles</a></li>
<li><a href="#_profiles">1.5. Profiles</a></li>
<li><a href="#_status">1.6. Status</a></li>
<li><a href="#_compliance">1.7. Compliance</a>
<ul class="sectlevel3">
<li><a href="#_baseline_inference_profile_compliance">1.7.1. Baseline Inference Profile Compliance</a></li>
<li><a href="#_main_inference_and_main_training_profile">1.7.2. Main Inference and Main Training Profile</a></li>
</ul>
</li>
<li><a href="#_tensor_definitions">1.8. Tensor Definitions</a>
<ul class="sectlevel3">
<li><a href="#_tensors">1.8.1. Tensors</a></li>
<li><a href="#_tensor_size_limit">1.8.2. Tensor size limit</a></li>
<li><a href="#_data_layouts">1.8.3. Data Layouts</a></li>
<li><a href="#_broadcasting">1.8.4. Broadcasting</a></li>
<li><a href="#_supported_number_formats">1.8.5. Supported Number Formats</a></li>
</ul>
</li>
<li><a href="#_integer_behavior">1.9. Integer Behavior</a>
<ul class="sectlevel3">
<li><a href="#_quantization">1.9.1. Quantization</a></li>
<li><a href="#_precision_scaling">1.9.2. Precision scaling</a></li>
<li><a href="#_integer_convolutions">1.9.3. Integer Convolutions</a></li>
<li><a href="#_integer_elementwise_operators">1.9.4. Integer Elementwise Operators</a></li>
<li><a href="#_general_unary_functions">1.9.5. General Unary Functions</a></li>
</ul>
</li>
<li><a href="#_floating_point">1.10. Floating-point</a></li>
</ul>
</li>
<li><a href="#_operators">2. Operators</a>
<ul class="sectlevel2">
<li><a href="#_operator_parameters">2.1. Operator Parameters</a></li>
<li><a href="#_operator_graphs">2.2. Operator Graphs</a></li>
<li><a href="#_tensor_operators">2.3. Tensor Operators</a>
<ul class="sectlevel3">
<li><a href="#_argmax">2.3.1. ARGMAX</a></li>
<li><a href="#_avg_pool2d">2.3.2. AVG_POOL2D</a></li>
<li><a href="#_conv2d">2.3.3. CONV2D</a></li>
<li><a href="#_conv3d">2.3.4. CONV3D</a></li>
<li><a href="#_depthwise_conv2d">2.3.5. DEPTHWISE_CONV2D</a></li>
<li><a href="#_fft2d">2.3.6. FFT2D</a></li>
<li><a href="#_fully_connected">2.3.7. FULLY_CONNECTED</a></li>
<li><a href="#_matmul">2.3.8. MATMUL</a></li>
<li><a href="#_max_pool2d">2.3.9. MAX_POOL2D</a></li>
<li><a href="#_rfft2d">2.3.10. RFFT2D</a></li>
<li><a href="#_transpose_conv2d">2.3.11. TRANSPOSE_CONV2D</a></li>
</ul>
</li>
<li><a href="#_activation_functions">2.4. Activation Functions</a>
<ul class="sectlevel3">
<li><a href="#_clamp">2.4.1. CLAMP</a></li>
<li><a href="#_sigmoid">2.4.2. SIGMOID</a></li>
<li><a href="#_tanh">2.4.3. TANH</a></li>
</ul>
</li>
<li><a href="#_elementwise_binary_operators">2.5. Elementwise Binary Operators</a>
<ul class="sectlevel3">
<li><a href="#_add">2.5.1. ADD</a></li>
<li><a href="#_arithmetic_right_shift">2.5.2. ARITHMETIC_RIGHT_SHIFT</a></li>
<li><a href="#_bitwise_and">2.5.3. BITWISE_AND</a></li>
<li><a href="#_bitwise_or">2.5.4. BITWISE_OR</a></li>
<li><a href="#_bitwise_xor">2.5.5. BITWISE_XOR</a></li>
<li><a href="#_intdiv">2.5.6. INTDIV</a></li>
<li><a href="#_logical_and">2.5.7. LOGICAL_AND</a></li>
<li><a href="#_logical_left_shift">2.5.8. LOGICAL_LEFT_SHIFT</a></li>
<li><a href="#_logical_right_shift">2.5.9. LOGICAL_RIGHT_SHIFT</a></li>
<li><a href="#_logical_or">2.5.10. LOGICAL_OR</a></li>
<li><a href="#_logical_xor">2.5.11. LOGICAL_XOR</a></li>
<li><a href="#_maximum">2.5.12. MAXIMUM</a></li>
<li><a href="#_minimum">2.5.13. MINIMUM</a></li>
<li><a href="#_mul">2.5.14. MUL</a></li>
<li><a href="#_pow">2.5.15. POW</a></li>
<li><a href="#_sub">2.5.16. SUB</a></li>
<li><a href="#_table">2.5.17. TABLE</a></li>
</ul>
</li>
<li><a href="#_elementwise_unary_operators">2.6. Elementwise Unary Operators</a>
<ul class="sectlevel3">
<li><a href="#_abs">2.6.1. ABS</a></li>
<li><a href="#_bitwise_not">2.6.2. BITWISE_NOT</a></li>
<li><a href="#_ceil">2.6.3. CEIL</a></li>
<li><a href="#_clz">2.6.4. CLZ</a></li>
<li><a href="#_exp">2.6.5. EXP</a></li>
<li><a href="#_floor">2.6.6. FLOOR</a></li>
<li><a href="#_log">2.6.7. LOG</a></li>
<li><a href="#_logical_not">2.6.8. LOGICAL_NOT</a></li>
<li><a href="#_negate">2.6.9. NEGATE</a></li>
<li><a href="#_reciprocal">2.6.10. RECIPROCAL</a></li>
<li><a href="#_rsqrt">2.6.11. RSQRT</a></li>
</ul>
</li>
<li><a href="#_elementwise_ternary_operators">2.7. Elementwise Ternary Operators</a>
<ul class="sectlevel3">
<li><a href="#_select">2.7.1. SELECT</a></li>
</ul>
</li>
<li><a href="#_comparison_operators">2.8. Comparison Operators</a>
<ul class="sectlevel3">
<li><a href="#_equal">2.8.1. EQUAL</a></li>
<li><a href="#_greater">2.8.2. GREATER</a></li>
<li><a href="#_greater_equal">2.8.3. GREATER_EQUAL</a></li>
</ul>
</li>
<li><a href="#_reduction_operators">2.9. Reduction Operators</a>
<ul class="sectlevel3">
<li><a href="#_reduce_all">2.9.1. REDUCE_ALL</a></li>
<li><a href="#_reduce_any">2.9.2. REDUCE_ANY</a></li>
<li><a href="#_reduce_max">2.9.3. REDUCE_MAX</a></li>
<li><a href="#_reduce_min">2.9.4. REDUCE_MIN</a></li>
<li><a href="#_reduce_product">2.9.5. REDUCE_PRODUCT</a></li>
<li><a href="#_reduce_sum">2.9.6. REDUCE_SUM</a></li>
</ul>
</li>
<li><a href="#_data_layout">2.10. Data Layout</a>
<ul class="sectlevel3">
<li><a href="#_concat">2.10.1. CONCAT</a></li>
<li><a href="#_pad">2.10.2. PAD</a></li>
<li><a href="#_reshape">2.10.3. RESHAPE</a></li>
<li><a href="#_reverse">2.10.4. REVERSE</a></li>
<li><a href="#_slice">2.10.5. SLICE</a></li>
<li><a href="#_tile">2.10.6. TILE</a></li>
<li><a href="#_transpose">2.10.7. TRANSPOSE</a></li>
</ul>
</li>
<li><a href="#_scattergather_operators">2.11. Scatter/Gather Operators</a>
<ul class="sectlevel3">
<li><a href="#_gather">2.11.1. GATHER</a></li>
<li><a href="#_scatter">2.11.2. SCATTER</a></li>
</ul>
</li>
<li><a href="#_image_operators">2.12. Image Operators</a>
<ul class="sectlevel3">
<li><a href="#_resize">2.12.1. RESIZE</a></li>
</ul>
</li>
<li><a href="#_type_conversion">2.13. Type Conversion</a>
<ul class="sectlevel3">
<li><a href="#_cast">2.13.1. CAST</a></li>
<li><a href="#_rescale">2.13.2. RESCALE</a></li>
</ul>
</li>
<li><a href="#_data_nodes">2.14. Data Nodes</a>
<ul class="sectlevel3">
<li><a href="#_const">2.14.1. CONST</a></li>
<li><a href="#_identity">2.14.2. IDENTITY</a></li>
</ul>
</li>
<li><a href="#_custom_operators">2.15. Custom Operators</a>
<ul class="sectlevel3">
<li><a href="#_custom">2.15.1. CUSTOM</a></li>
</ul>
</li>
<li><a href="#_control_flow_operators">2.16. Control Flow Operators</a>
<ul class="sectlevel3">
<li><a href="#_cond_if">2.16.1. COND_IF</a></li>
<li><a href="#_while_loop">2.16.2. WHILE_LOOP</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_tosa_pseudocode">3. TOSA Pseudocode</a>
<ul class="sectlevel2">
<li><a href="#_operator_validation_helpers">3.1. Operator Validation Helpers</a></li>
<li><a href="#_tensor_access_helpers">3.2. Tensor Access Helpers</a>
<ul class="sectlevel3">
<li><a href="#_tensor_utilities">3.2.1. Tensor Utilities</a></li>
<li><a href="#_tensor_read">3.2.2. Tensor Read</a></li>
<li><a href="#_tensor_write">3.2.3. Tensor Write</a></li>
<li><a href="#_broadcast_helper">3.2.4. Broadcast Helper</a></li>
</ul>
</li>
<li><a href="#_general_pseudocode_helpers">3.3. General Pseudocode Helpers</a>
<ul class="sectlevel3">
<li><a href="#_arithmetic_helpers">3.3.1. Arithmetic Helpers</a></li>
<li><a href="#_numeric_conversion_helpers">3.3.2. Numeric Conversion Helpers</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<div id="content">
<div id="preamble">
<div class="sectionbody">
<div style="page-break-after: always;"></div>
<div class="paragraph">
<p><strong>TOSA Specification License ("License")</strong></p>
</div>
<div class="paragraph">
<p>This Licence is a legal agreement between you and Arm Limited (“Arm”) for the use of Arm’s intellectual property (including, without limitation, any copyright) embodied in the relevant TOSA Specification accompanying this Licence (“Specification”). Arm licenses its intellectual property in the Specification to you on condition that you agree to the terms of this Licence. By using or copying the Specification you indicate that you agree to be bound by the terms of this Licence.</p>
</div>
<div class="paragraph">
<p>“Subsidiary” means any company the majority of whose voting shares is now or hereafter owner or controlled, directly or indirectly, by you. A company shall be a Subsidiary only for the period during which such control exists.</p>
</div>
<div class="paragraph">
<p>This Specification is NON-CONFIDENTIAL and any use by you and your Subsidiaries (“Licensee”) is subject to the terms of this Licence between you and Arm.</p>
</div>
<div class="paragraph">
<p>Subject to the terms and conditions of this Licence, Arm hereby grants to Licensee under the intellectual property in the Specification owned or controlled by Arm, a perpetual, a non-exclusive, non-transferable, non-sub-licensable, royalty-free, worldwide licence to:</p>
</div>
<div class="olist lowerroman">
<ol class="lowerroman" type="i">
<li>
<p>use and copy the Specification solely for the purpose of designing and having designed products that fully complies with the Specification;</p>
</li>
<li>
<p>manufacture and have manufactured products which have been created under the licence granted in (i) above; and</p>
</li>
<li>
<p>sell, supply and distribute products which have been created under the licence granted in (i) above.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Licensee hereby agrees that the licenses granted above are conditional on implementing the Specification in products in its entirety and shall not extend to any portion or function of a product that is not itself fully compliant with the Specification.</p>
</div>
<div class="paragraph">
<p>Except as expressly licensed above, Licensee acquires no right, title or interest in any Arm technology or any intellectual property embodied therein.</p>
</div>
<div class="paragraph">
<p>Your access to the information in the Specification is conditional upon your acceptance that you will not use or permit others to use the information for the purposes of determining whether implementations infringe any third party patents.</p>
</div>
<div class="paragraph">
<p>THE SPECIFICATION IS PROVIDED “AS IS”. ARM PROVIDES NO REPRESENTATIONS AND NO WARRANTIES, EXPRESS, IMPLIED OR STATUTORY, INCLUDING, WITHOUT LIMITATION, THE IMPLIED WARRANTIES OF MERCHANTABILITY, SATISFACTORY QUALITY, NON-INFRINGEMENT OR FITNESS FOR A PARTICULAR PURPOSE WITH RESPECT TO THE SPECIFICATION. Arm may make changes to the Specification at any time and without notice. For the avoidance of doubt, Arm makes no representation with respect to, and has undertaken no analysis to identify or understand the scope and content of, third party patents, copyrights, trade secrets, or other rights.</p>
</div>
<div class="paragraph">
<p>NOTWITHSTANDING ANYTHING TO THE CONTRARY CONTAINED IN THIS LICENCE, TO THE FULLEST EXTENT PERMITTED BY LAW, IN NO EVENT WILL ARM BE LIABLE FOR ANY DAMAGES, IN CONTRACT, TORT OR OTHERWISE, IN CONNECTION WITH THE SUBJECT MATTER OF THIS LICENCE (INCLUDING WITHOUT LIMITATION: (I) LICENSEE’S USE OF THE SPECIFICATION; AND (II) THE IMPLEMENTATION OF THE SPECIFICATION IN ANY PRODUCT CREATED BY LICENSEE UNDER THIS LICENCE). THE EXISTENCE OF MORE THAN ONE CLAIM OR SUIT WILL NOT ENLARGE OR EXTEND THE LIMIT. LICENSEE RELEASES ARM FROM ALL OBLIGATIONS, LIABILITY, CLAIMS OR DEMANDS IN EXCESS OF THIS LIMITATION.</p>
</div>
<div class="paragraph">
<p>This Licence shall remain in force until terminated by Licensee or by Arm. Without prejudice to any of its other rights, if Licensee is in breach of any of the terms and conditions of this Licence then Arm may terminate this Licence immediately upon giving written notice to Licensee. Licensee may terminate this Licence at any time. Upon termination of this Licence by Licensee or by Arm, Licensee shall stop using the Specification and destroy all copies of the Specification in its possession. Upon termination of this Licence, all terms shall survive except for the licence grants.</p>
</div>
<div class="paragraph">
<p>Any breach of this Licence by a Subsidiary shall entitle Arm to terminate this Licence as if you were the party in breach. Any termination of this Licence shall be effective in respect of all Subsidiaries. Any rights granted to any Subsidiary hereunder shall automatically terminate upon such Subsidiary ceasing to be a Subsidiary.</p>
</div>
<div class="paragraph">
<p>The Specification consists solely of commercial items. Licensee shall be responsible for ensuring that any use, duplication or disclosure of the Specification complies fully with any relevant export laws and regulations to assure that the Specification or any portion thereof is not exported, directly or indirectly, in violation of such export laws.</p>
</div>
<div class="paragraph">
<p>This Licence may be translated into other languages for convenience, and Licensee agrees that if there is any conflict between the English version of this Licence and any translation, the terms of the English version of this Licence shall prevail.</p>
</div>
<div class="paragraph">
<p>The Arm corporate logo and words marked with ® or ™ are registered trademarks or trademarks of Arm Limited (or its subsidiaries) in the US and/or elsewhere. All rights reserved.  Other brands and names mentioned in this Specification may be the trademarks of their respective owners. No licence, express, implied or otherwise, is granted to Licensee under this Licence, to use the Arm trade marks in connection with the Specification or any products based thereon. Visit Arm’s website at <a href="https://www.arm.com/company/policies/trademarks" class="bare">https://www.arm.com/company/policies/trademarks</a> for more information about Arm’s trademarks.</p>
</div>
<div class="paragraph">
<p>The validity, construction and performance of this Licence shall be governed by English Law.</p>
</div>
<div class="paragraph">
<p>Copyright © 2020-2022 Arm Limited (or its affiliates). All rights reserved.</p>
</div>
<div class="paragraph">
<p>Arm Limited. Company 02557590 registered in England.
110 Fulbourn Road, Cambridge, England CB1 9NJ.</p>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
<div class="sect1">
<h2 id="_introduction">1. Introduction</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_overview">1.1. Overview</h3>
<div class="paragraph">
<p>Tensor Operator Set Architecture (TOSA) provides a set of whole-tensor
operations commonly employed by Deep Neural Networks. The intent is to enable a
variety of implementations running on a diverse range of processors, with the
results at the TOSA level consistent across those implementations. Applications
or frameworks which target TOSA can therefore be deployed on a wide range of
different processors, such as SIMD CPUs, GPUs and custom hardware such as
NPUs/TPUs, with defined accuracy and compatibility constraints. Most operators
from the common ML frameworks (TensorFlow, PyTorch, etc.) should be expressible
in TOSA. It is expected that there will be tools to lower from ML frameworks
into TOSA.</p>
</div>
</div>
<div class="sect2">
<h3 id="_goals">1.2. Goals</h3>
<div class="paragraph">
<p>The goals of TOSA include the following:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>A minimal and stable set of tensor-level operators to which machine learning
framework operators can be reduced.</p>
</li>
<li>
<p>Full support for both quantized integer and floating-point content.</p>
</li>
<li>
<p>Precise functional description of the behavior of every operator, including
the treatment of their numerical behavior in the case of precision, saturation,
scaling, and range as required by quantized datatypes.</p>
</li>
<li>
<p>Agnostic to any single high-level framework, compiler backend stack or
particular target.</p>
</li>
<li>
<p>The detailed functional and numerical description enables precise code
construction for a diverse range of targets – SIMD CPUs, GPUs and custom
hardware such as NPUs/TPUs.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_specification">1.3. Specification</h3>
<div class="paragraph">
<p>The TOSA Specification is written as AsciiDoc mark-up and developed in its raw
mark-up form, managed through a git repository here:
<a href="https://git.mlplatform.org/tosa/specification.git/" class="bare">https://git.mlplatform.org/tosa/specification.git/</a>.
The specification is developed and versioned much like software.
While the mark-up is legible and can be read fairly easily in its raw form, it is recommended to build or “render” the mark-up into PDF or HTML.
To do this, please follow the instructions in the README.md in the root of the specification repository.</p>
</div>
</div>
<div class="sect2">
<h3 id="_operator_selection_principles">1.4. Operator Selection Principles</h3>
<div class="paragraph">
<p>TOSA defines a set of primitive operators to which higher level operators can be lowered in a consistent way.
To remain effective and efficient to implement, the set of operators must be constrained to a reasonably small set of primitive operations out of which others can be constructed.
The following principles govern the selection of operators within TOSA.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 1. Principles</caption>
<colgroup>
<col style="width: 9.0909%;">
<col style="width: 45.4545%;">
<col style="width: 45.4546%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">ID</th>
<th class="tableblock halign-left valign-top">Principle</th>
<th class="tableblock halign-left valign-top">Reason for this</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">P0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">An operator shall be a primitive operation or building block that cannot be decomposed into simpler whole tensor operations.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">If the operator can be broken down, then we should look at the component operators.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">P1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">An operator shall be a usable as a component out of which more complex operations can be constructed.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Single use operators have a high architectural cost and a more reusable version should be considered instead.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">P2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Precision should be appropriate for the input and output data types.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Precision higher than that needed to calculate the result leads to extra implementation cost.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">P3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Numerical definition of common sub-operations should be consistent between operators (for example: value scaling).</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Consistent sub-operation definition reduces the operator implementation cost.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">P4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The valid input and output ranges for all operands shall be specified.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Ranges are required to make consistent (numerically agreeing) implementations possible.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">P5</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Integer operators shall be implementable in a bit-exact form with good efficiency on CPU, GPU and hardware targets.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Reduces implementation cost and gives consistent inference results.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="_profiles">1.5. Profiles</h3>
<div class="paragraph">
<p>TOSA supports three profiles that enable efficient implementation on different classes of device.
The Base Inference profile is intended for embedded integer/fixed-point designs performing inference only.
The Main Inference profile is intended for general inference functionality including integer and floating-point data types.
The Main Training profile adds training operators in addition to inference operators.
This version of the specification covers the Base Inference and Main Inference profiles.
Main Training profile is expected in a later version of the specification.
The following table summarizes the three profiles:</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 2. Profiles</caption>
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Integer Inference</th>
<th class="tableblock halign-left valign-top">Floating-point Inference</th>
<th class="tableblock halign-left valign-top">Training</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Base Inference</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">TOSA-BI</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Yes</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">No</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">No</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Main Inference</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">TOSA-MI</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Yes</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Yes</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">No</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Main Training</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">TOSA-MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Yes</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Yes</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Yes</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="_status">1.6. Status</h3>
<div class="paragraph">
<p>The TOSA specification is a work in progress.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The Base Inference profile should be considered to be near release quality, with conformance tests available.</p>
</li>
<li>
<p>The Main Inference profile has most of the expected operators in place, but is still subject to change.</p>
</li>
<li>
<p>The reference model and conformance tests do not yet support all of the floating point types that have been defined.</p>
</li>
<li>
<p>There is not currently a conformance test suite available for Main Inference.</p>
</li>
<li>
<p>Main Training profile is pre-alpha, significant work still needs to be done for the profile, and no conformance tests are available.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_compliance">1.7. Compliance</h3>
<div class="paragraph">
<p>This section defines when a TOSA implementation is compliant to a given TOSA specification profile.
The term conformant will mean the same as compliant.</p>
</div>
<div class="sect3">
<h4 id="_baseline_inference_profile_compliance">1.7.1. Baseline Inference Profile Compliance</h4>
<div class="paragraph">
<p>The <a href="#_operator_graphs">Operator Graphs</a> section of this specification defines a TOSA graph and the behavior defined for a TOSA graph.
This behavior is captured in the pseudo-code function tosa_execute_graph().
For a given input graph (with attributes) and input tensors there are three possible tosa_graph_result values after executing the graph:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>tosa_unpredictable: The result of the graph on the given inputs cannot be relied upon.</p>
</li>
<li>
<p>tosa_error: The graph does not meet the specification and is recognised as an illegal graph.</p>
</li>
<li>
<p>tosa_valid: The result is defined and predictable and the list of output tensors defines the result.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>An implementation is compliant to the TOSA Baseline Inference Profile if it matches the above results as follows:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>For tosa_unpredictable, the implementation can return whatever result it chooses (including error)</p>
</li>
<li>
<p>For tosa_error, the implementation must return an error result (and there is no requirement on how much of the graph is executed, if any)</p>
</li>
<li>
<p>For tosa_valid, the implementation must execute the entire graph without error and return the result defined by this specification.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>In terms of psuedo-code, if <strong>graph</strong> is a TOSA graph consisting of Baseline Inference Profile operators and <strong>input_list</strong> is a list of input tensors then the following test must pass.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">bool tosa_test_compliance(tosa_graph_t graph, tosa_list_t input_list) {
    shape_list_t output_list_spec = tosa_allocate_list(tosa_output_shape(graph));
    shape_list_t output_list_test = tosa_allocate_list(tosa_output_shape(graph));
    tosa_graph_result = tosa_valid    // result starts as valid
    tosa_execute_graph(graph, input_list, output_list_spec);
    if (tosa_graph_result == tosa_unpredictable) {
        return true;    // No requirement to match an unpredictable result
    }
    result_test = execute_implementation_under_test(graph, input_list, output_list_test);
    if (tosa_graph_result == tosa_error) {
        return result_test == tosa_error;   // result must be an error
    }
    if (exact_tensor_match(output_list_spec, output_list_test)) {
       // Predictable bit-exact value match required
       return true;
    }
    return false;
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_main_inference_and_main_training_profile">1.7.2. Main Inference and Main Training Profile</h4>
<div class="paragraph">
<p>An implementation is compliant to the Main Inference or Main Training profiles if the following both hold for that respective profile:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>For a graph returning tosa_error the implementation must also return an error</p>
</li>
<li>
<p>For a graph returning tosa_valid the implementation must execute the entire graph without error</p>
</li>
<li>
<p>For a graph returning tosa_valid and consisting only of integer operators the results must match exactly</p>
</li>
<li>
<p>The implementation must report the maximum relative error on a set of standard graphs that contain floating point operators. These graphs will be provided as a future appendix to this specification.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Note that for graphs containing floating point there is no strict precision requirement that must be met, but that the precision achieved must be reported.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_tensor_definitions">1.8. Tensor Definitions</h3>
<div class="sect3">
<h4 id="_tensors">1.8.1. Tensors</h4>
<div class="paragraph">
<p>Tensors are multidimensional arrays of data.
Tensors have metadata associated with them that describe characteristics of the tensor, including:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Data Type</p>
</li>
<li>
<p>Shape</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The number of dimensions in a shape is called the rank.
A tensor with rank equal to zero is permitted.
In that case, the tensor has a single entry.
A tensor shape is an array of integers of size equal to the rank of the tensor.
Each element in the tensor shape describes the number of elements in the dimension.
The tensor shape in each dimension must be greater than or equal to 1.
For tensor access information, see <a href="#_tensor_access_helpers">Tensor Access Helpers</a>.
Tensor dimensions are given in the pseudocode as type dim_t.
dim_t is a vector of int32_t values, with the length of the vector defining the rank of the tensor.
Tensor elements are addressed using dim_t values, where each element of the vector indicates the offset of the requested element within the corresponding dimension.</p>
</div>
</div>
<div class="sect3">
<h4 id="_tensor_size_limit">1.8.2. Tensor size limit</h4>
<div class="paragraph">
<p>Tensor size is limited by the data type size_t. In this version of the specification, size_t is defined as (1&lt;&lt;32) - 1, and can be represented with an unsigned 32-bit integer.</p>
</div>
</div>
<div class="sect3">
<h4 id="_data_layouts">1.8.3. Data Layouts</h4>
<div class="paragraph">
<p>The following data layouts are supported in TOSA.
TOSA operations are defined in terms of a linear packed tensor layout.
In a linear packed layout a rank r tensor has elements of dimension (r-1) consecutive.
The next to increment is dimension (r-2) and so on.
For a specification of this layout see the tensor read and write functions in section <a href="#_tensor_access_helpers">Tensor Access Helpers</a>.</p>
</div>
<div class="paragraph">
<p>An implementation of TOSA can choose a different tensor memory layout provided that the operation behavior is maintained.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 3. Data Layouts</caption>
<colgroup>
<col style="width: 11.1111%;">
<col style="width: 44.4444%;">
<col style="width: 44.4445%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Description of dimensions</th>
<th class="tableblock halign-left valign-top">Usage</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">NHWC</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch, Height, Width, Channels</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Feature maps</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">NDHWC</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch, Depth, Height, Width, Channels</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Feature maps for 3D convolution</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">OHWI</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output channels, Filter Height, Filter Width, Input channels</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">HWIM</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Filter Height, Filter Width, Input channels, Channel Multiplier</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Weights for depthwise convolutions</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">DOHWI</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Depth, Output Channels, Filter Height, Filter Width, Input Channels</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Weights for 3D convolution</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_broadcasting">1.8.4. Broadcasting</h4>
<div class="paragraph">
<p>In operations where broadcasting is supported, an input shape dimension can be broadcast to an output shape dimension if the input shape dimension is 1.
TOSA broadcast requires the rank of both tensors to be the same.
A RESHAPE can be done to create a compatible tensor with appropriate dimensions of size 1.
To map indexes in an output tensor to that of an input tensor, see <a href="#_broadcast_helper">Broadcast Helper</a>.</p>
</div>
</div>
<div class="sect3">
<h4 id="_supported_number_formats">1.8.5. Supported Number Formats</h4>
<div class="paragraph">
<p>The following number formats are defined in TOSA.
The number formats supported by a given operator are listed in its table of supported types.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 4. Number formats</caption>
<colgroup>
<col style="width: 12.5%;">
<col style="width: 12.5%;">
<col style="width: 12.5%;">
<col style="width: 62.5%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Format</th>
<th class="tableblock halign-left valign-top">Minimum</th>
<th class="tableblock halign-left valign-top">Maximum</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean value. Size implementation defined. The TOSA reference model implements this as int8_t with 0 for false and 1 for true. All non-zero values are accepted on input as true.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">int4_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-7</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+7</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Signed 4-bit two&#8217;s-complement value. Excludes -8 to maintain a symmetric about zero range for weights.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-128</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+127</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Signed 8-bit two&#8217;s-complement value.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">uint8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">255</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Unsigned 8-bit value.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-32768</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+32767</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Signed 16-bit two&#8217;s-complement value.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">uint16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">65535</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Unsigned 16-bit value.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-(1&lt;&lt;31)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">(1&lt;&lt;31)-1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Signed 32-bit two&#8217;s-complement value.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">int48_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-(1&lt;&lt;47)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">(1&lt;&lt;47)-1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Signed 48-bit two&#8217;s-complement value.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">16-bit floating-point value.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">16-bit brain float value.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">32-bit floating-point value.</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>Note: In this specification minimum&lt;type&gt; and maximum&lt;type&gt; will denote the minimum and maximum values of the data as stored in memory (ignoring the zero point).
The minimum and maximum values for each type is given in the preceeding table.</p>
</div>
<div class="paragraph">
<p>Note: Integer number formats smaller than 8 bits may be used provided that the numerical result is the same as using a sequence of 8-bit TOSA operations.
For example, a convolution with low precision data must equal that of running the convolution at 8 bits and then clipping the result to the peritted output range.
This ensures that a Base Inference profile TOSA implementation can calculate the same result.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_integer_behavior">1.9. Integer Behavior</h3>
<div class="paragraph">
<p>Integer calculations must be standard two&#8217;s-complement or unsigned calculations.
If overflow occurs doing integer calculation, the result is unpredictable, as indicated by the REQUIRE checks in the pseudocode for the operators.</p>
</div>
<div class="paragraph">
<p>Unsigned 8 and 16-bit values are only allowed in the RESCALE operation, to allow for compatibility with networks which expect unsigned 8-bit or 16-bit tensors for input and output.</p>
</div>
<div class="sect3">
<h4 id="_quantization">1.9.1. Quantization</h4>
<div class="paragraph">
<p>Machine Learning frameworks may represent tensors with a quantized implementation, using integer values to represent the original floating-point numbers.
TOSA integer operations do not perform any implicit scaling to represent quantized values.
Required zero point values are passed to the operator as necessary, and will be processed according to the pseudocode for each operator.</p>
</div>
<div class="paragraph">
<p>To convert a network containing quantized tensors to TOSA, generate explicit RESCALE operators for any change of quantization scaling.
This reduces quantized operations to purely integer operations.</p>
</div>
<div class="paragraph">
<p>As an example, an ADD between two quantized tensors requires the integer values represent the same range.
The scale parameters for RESCALE can be calculated to ensure that the resulting tensors represent the same range.
Then the ADD is performed, and a RESCALE can be used to ensure that the result is scaled properly.</p>
</div>
<div class="paragraph">
<p>RESCALE provides support for per-tensor and per-channel scaling values to ensure compatibility with a range of possible quantization implementations.</p>
</div>
</div>
<div class="sect3">
<h4 id="_precision_scaling">1.9.2. Precision scaling</h4>
<div class="paragraph">
<p>TOSA uses the RESCALE operation to scale between values with differing precision.
The RESCALE operator is defined using an integer multiply, add, and shift.
This guarantees that all TOSA implementations will return the same result for a RESCALE, including those with no support for floating-point numbers.</p>
</div>
<div class="paragraph">
<p>This TOSA specification supports two precisions of multiplier: 16-bit and 32-bit.
The 32-bit multiplier version supports two rounding modes to enable simpler lowering of existing frameworks that use two stage rounding.
All arithmetic is designed so that it does not overflow a 64-bit accumulator and that the final result fits in 32 bits.
In particular a 48-bit value can only be scaled with the 16-bit multiplier.</p>
</div>
<div class="paragraph">
<p>The apply_scale functions provide a scaling of approximately (multiplier * 2<sup>-shift</sup>).
The shift and value range is limited to allow a variety of implementations.
The limit of 62 on shift allows the shift to be decomposed as two right shifts of 31.
The limit on value allows implementations that left shift the value before the multiply in the case of shifts of 32 or less.
For example, in the case shift=30 an implementation of the form ((value&lt;&lt;2) * multiplier + round)&gt;&gt;32 can be used.
A scaling range of 2<sup>+12</sup> down to 2<sup>-32</sup> is supported for both functions with a normalized multiplier.</p>
</div>
<div class="paragraph">
<p>For example, in typical usage a scaling of m*2<sup>-n</sup> where m is a fraction in the
range 1.0 &lt;= m &lt; 2.0 can be represented using multiplier=(1&lt;&lt;30)*m, shift=(30+n) for
apply_scale_32() and multiplier=(1&lt;&lt;14)*m, shift=(14+n) for apply_scale_16().
The values to achieve a scaling of 1.0 are shift=30, multiplier=1&lt;&lt;30 for apply_scale_32 and shift=14, multiplier=1&lt;&lt;14 for apply_scale_16.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">int32_t apply_scale_32(int32_t value, int32_t multipler, uint6_t shift, bool_t double_round=false) {
    REQUIRE(multiplier &gt;= 0);
    REQUIRE(2 &lt;= shift &amp;&amp; shift &lt;= 62);
    REQUIRE(value &gt;= (-1&lt;&lt;(shift-2)) &amp;&amp; value &lt; (1&lt;&lt;(shift-2));
    int64_t round = 1 &lt;&lt; (shift - 1);
    if (double_round) {
        if (shift &gt; 31 &amp;&amp; value &gt;= 0) round += 1&lt;&lt;30;
        if (shift &gt; 31 &amp;&amp; value &lt; 0)  round -= 1&lt;&lt;30;
    }
    int64_t result = (int64_t)value * multiplier + round;
    result = result &gt;&gt; shift;
    // result will fit a 32-bit range due to the REQUIRE on value
    return (int32_t)result;
}

int32_t apply_scale_16(int48_t value, int16_t multipler, uint6_t shift) {
    REQUIRE(multiplier &gt;= 0);
    REQUIRE(2 &lt;= shift &amp;&amp; shift &lt;= 62);
    int64_t round = (1 &lt;&lt; (shift - 1));
    int64_t result = (int64_t)value * multiplier + round;
    result = result &gt;&gt; shift;
    REQUIRE(result &gt;= minimum&lt;int32_t&gt; &amp;&amp; result &lt;= maximum&lt;int32_t&gt;);
    return (int32_t)result;
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>In some functions, the multiplier and shift are combined into a scale_t structure:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">typedef struct {
    int32_t multiplier;
    uint6_t shift;
} scale_t;</code></pre>
</div>
</div>
<div class="paragraph">
<p>In places where a divide is required, we also use the function below to calculate an appropriate scaling value.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">scale_t reciprocal_scale(uint32_t value) {
    REQUIRE(value &gt; 0);
    scale_t scale;
    int32_t k = 32 - count_leading_zeros(value - 1); // (1 &lt;&lt; k) / 2 &lt; value &lt;= (1 &lt;&lt; k)
    int64_t numerator = ((1 &lt;&lt; 30) + 1) &lt;&lt; k;
    scale.multiplier = numerator / value; // (1 &lt;&lt; 30) &lt;= multiplier &lt; (1 &lt;&lt; 31)
    scale.shift = 30 + k;
    return scale;
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_integer_convolutions">1.9.3. Integer Convolutions</h4>
<div class="paragraph">
<p>For the convolution operators, the input is not required to be scaled.
The integer versions of the convolution operators will subtract the zero point from the integer values as defined for each operator.
The convolution produces an accumulator output of type int32_t or int48_t.
This accumulator output is then scaled to the final output range using the RESCALE operator.
The scale applied in the RESCALE operator should be set to multiplier and shift values such that: multiplier * 2<sup>-shift</sup> = (input scale * weight scale) / output_scale.
Here, input_scale, weight_scale and output_scale are the conversion factors from integer to floating-point for the input, weight and output tensor values respectively.
If per-channel scaling is needed then the per-channel option of the RESCALE operation should be used.</p>
</div>
</div>
<div class="sect3">
<h4 id="_integer_elementwise_operators">1.9.4. Integer Elementwise Operators</h4>
<div class="paragraph">
<p>When two quantized tensors are used in an operation, they must represent the same numeric range for the result to be valid.
In this case, TOSA expects that RESCALE operators will be used as necessary to generate 32-bit integer values in a common range.
There are many valid choices for scale factors and options for the common range.
TOSA does not impose a requirement on which scale factors and range should be used.
Compilers generating TOSA sequences should choose a range that allows the operation to be computed without overflow, while allowing the highest possible accuracy of the output.</p>
</div>
</div>
<div class="sect3">
<h4 id="_general_unary_functions">1.9.5. General Unary Functions</h4>
<div class="paragraph">
<p>General unary functions such as sigmoid(), tanh(), exp() for integer inputs are expressed using a lookup table and interpolation to enable efficient implementation.
This also allows for other operations with the addition of user-supplied tables (the TABLE operation).
All table lookups are based on the following reference lookup function that takes as input a table of 513 entries of 16 bits each.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">int32_t apply_lookup(int16_t *table, int32_t value)
{
    int16_t clipped_value = (int16_t)apply_clip&lt;int32_t&gt;(value, -32768, +32767);
    int32_t index = (clipped_value + 32768) &gt;&gt; 7;
    int32_t fraction = clipped_value &amp; 0x7f;
    int16_t base = table[index];
    int16_t next = table[index+1];
    int32_t slope = next - base;
    REQUIRE(slope &gt;= minimum&lt;int16_t&gt; &amp;&amp; slope &lt;= maximum&lt;int16_t&gt;)
    int32_t return_value = (base &lt;&lt; 7) + slope * fraction;
    return return_value;	// return interpolated value of 16 + 7 = 23 bits
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Note that although the table lookup defined here has 16-bit precision, for 8-bit only operations an 8-bit table can be derived by applying the reference function to each of the possible 256 input values.
The following code constructs a 513-entry table based on a reference function.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">void generate_lookup_table(int16_t *table, int32_t (*reference)(int32_t))
{
    for (int i = -256; i &lt;= 256; i++) {
        int32_t value = (*reference)(i);
        table[i + 256] = (int16_t)apply_clip&lt;int32_t&gt;(value, -32768, +32767)
    }
}</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_floating_point">1.10. Floating-point</h3>
<div class="paragraph">
<p>Floating-point support is included in the main inference profile.
TOSA does not define bit-exact behavior of the floating-point type, since floating-point operation results can vary according to operation order (floating-point addition is not associative in general) and rounding behavior.
If a bit-exact answer is required then integer operations should be used.
TOSA does define that the floating-point type must support the following list of features.
These features ensure that detection of overflow and other exceptional conditions can be handled consistently.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The floating-point type must have at least 16 total bits including the sign bit</p>
</li>
<li>
<p>The floating-point type must support positive and negative infinity values</p>
</li>
<li>
<p>The floating-point type must support at least one Not-a-Number encoding (NaN)</p>
</li>
<li>
<p>The floating-point type must support signed zero</p>
</li>
<li>
<p>The floating-point type must support handling of infinities, NaNs, zeros as in the following table</p>
</li>
</ul>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 5. floating-point behavior</caption>
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Case</th>
<th class="tableblock halign-left valign-top">Result</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Operators other than explicitly mentioned by other rules: Any input operand is a NaN</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">a NaN</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Comparisons (EQUAL, GREATER, GREATER_EQUAL), where either or both operands is NaN</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">False</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Comparisons ignore the sign of 0</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RSQRT (reciprocal square root) of negative numbers</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">a NaN</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">(&#177; 0) &#215; (&#177; infinity), (&#177; infinity) &#215; (&#177; 0)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">a NaN</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">LOG of negative numbers</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">a NaN</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">nonzero numbers / (&#177; 0)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">(&#177; infinity)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">(&#177; 0) / (&#177; 0), (&#177; infinity) / (&#177; infinity)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">a NaN</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">(&#177; infinity) * 0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">a NaN</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">(+infinity) - (+infinity),  (+infinity) + (-infinity)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">a NaN</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any positive overflow</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+ infinity</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any negative overflow</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">- infinity</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any positive underflow</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+ 0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any negative underflow</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">- 0</p></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_operators">2. Operators</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_operator_parameters">2.1. Operator Parameters</h3>
<div class="paragraph">
<p>An operator processes input operands to produce output operands. An operator can have three types of parameters:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>An input operand. This must be a tensor or a list of tensors and data is read by the operation.</p>
</li>
<li>
<p>An output operand. This must be a tensor or a list of tensors and data is written by the operation.</p>
</li>
<li>
<p>An attribute. This is a parameter that is constant for a particular instance of the operator. It may have any data type supported by TOSA. It is expected to be set at compile time.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_operator_graphs">2.2. Operator Graphs</h3>
<div class="paragraph">
<p>A TOSA graph is a collection of TOSA operators where:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The output of an operator in the graph may be connected to one or more inputs of other operators in the graph</p>
</li>
<li>
<p>When an output is connected to an input the tensor list shapes must match</p>
</li>
<li>
<p>The attributes of the operators are defined and considered part of the graph</p>
</li>
<li>
<p>The attributes must be in the valid range permitted for the operator</p>
</li>
<li>
<p>The tensor dimensions must be in the valid range permitted for the operator</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Some operators, such as control flow operators, take a graph of other operators as an attribute. The type tosa_graph_t will denote a graph of operators and the following functions define the tensor shape list for the graph input and outputs:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">shape_list_t tosa_input_shape(tosa_graph_t graph);
shape_list_t tosa_output_shape(tosa_graph_t graph);</code></pre>
</div>
</div>
<div class="paragraph">
<p>Similarly the type tensor_list_t will be used for a list of tensors and the following function returns the shape of a tensor list:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">shape_list_t tensor_list_shape(tosa_list_t tensor_list);</code></pre>
</div>
</div>
<div class="paragraph">
<p>The following function denotes the execution of a TOSA graph, on an input tensor list to produce an output tensor list.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">tosa_execute_graph(tosa_graph_t graph, tosa_list_t input_list, tosa_list_t output_list) {
    ERROR_IF(tensor_list_shape(input_list) != tosa_input_shape(graph));
    ERROR_IF(tensor_list_shape(output_list) != tosa_output_shape(graph));
    for_each(operator in graph order) {
        ERROR_IF(operator input tensors do not meet requirement of operator Arguments inputs)
        ERROR_IF(operator attributes do not meet requirement of operator Arguments attributes)
        ERROR_IF(operator output tensors do not meet requirement of operator Arguments outputs)
        ERROR_IF(operator data types do not meet requirement of operator Supported Data Types)
        &lt;Execute operator as defined by the Operation Function pseduo-code&gt;
    }
}</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_tensor_operators">2.3. Tensor Operators</h3>
<div class="sect3">
<h4 id="_argmax">2.3.1. ARGMAX</h4>
<div class="paragraph">
<p>This returns the index with the largest value across the given axis of the input tensor.</p>
</div>
<div class="paragraph">
<p><strong>Arguments</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with rank from 1 to 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">axis</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Axis in range from 0 to rank(shape1)-1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor, with rank = rank(shape1)-1</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">ERROR_IF(axis &lt; 0 || axis &gt;= rank(shape1) || rank(shape1) &gt; 4);
if (axis == 0) {
    left_shape = [];
} else {
    left_shape = shape1[0:axis - 1];
}
if (axis == rank(shape1)-1) {
    right_shape = [];
} else {
    right_shape = shape1[axis+1:rank(shape1) - 1];
}
ERROR_IF(flatten(left_shape, right_shape) != shape);
for_each(left_index in left_shape) {
    for_each(right_index in right_shape) {
        in_t max_value = minimum_value&lt;in_t&gt;;
        out_t max_index = 0;
        for (i = 0; i &lt; shape[axis]; i++) {
            index = flatten(left_index, [i], right_index);
            in_t value = tensor_read&lt;in_t&gt;(input, shape1, index);
            if (value &gt; max_value) { max_value = value; max_index = i; }
        }
        index = flatten(left_index, right_index);
        tensor_write&lt;out_t&gt;(output, shape, index, max_index);
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_t</th>
<th class="tableblock halign-left valign-top">out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_avg_pool2d">2.3.2. AVG_POOL2D</h4>
<div class="paragraph">
<p>This performs an average pooling over the given input tensor.
A sliding window of size given by &lt;kernel size&gt; is passed over the input tensor, with the mean value being placed in the output tensor.
When calculating the average, only the number of valid input tensor values, but not padding, are used to calculate the divisor.
<strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,IH,IW,C]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor 4D</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">kernel</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[2]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[kernel_y, kernel_x]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">stride</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[2]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[stride_y, stride_x]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">pad</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[4]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[pad_top, pad_bottom, pad_left, pad_right]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor zero point. Must be zero for non-int8 types.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor zero point. Must be zero for non-int8 types.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,OH,OW,C]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor 4D</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">ERROR_IF(in_out_t != int8_t &amp;&amp; input_zp != 0); // Zero point only for int8_t
ERROR_IF(in_out_t != int8_t &amp;&amp; output_zp != 0); // Zero point only for int8_t
ERROR_IF(kernel_y &lt; 1 || kernel_x &lt; 1); // kernel size must be &gt;= 1
ERROR_IF(stride_y &lt; 1 || stride_x &lt; 1);
ERROR_IF(pad_top &lt; 0 || pad_bottom &lt; 0 || pad_left &lt; 0 || pad_right &lt; 0);
// Padding must be less than kernel size to avoid
// a divide-by-zero.
ERROR_IF(pad_right &gt;= kernel_x || pad_left &gt;= kernel_x);
ERROR_IF(pad_top &gt;= kernel_y || pad_bottom &gt;= kernel_y);
ERROR_IF(OH != idiv_check(IH + pad_top + pad_bottom - kernel_y, stride_y) + 1);
ERROR_IF(OW != idiv_check(IW + pad_left + pad_right - kernel_x, stride_x) + 1);

for_each(0 &lt;= n &lt; N, 0 &lt;= oy &lt; OH, 0 &lt;= ox &lt; OW, 0 &lt;= c &lt; C ) {
    in_out_t output_val;
    acc_t acc = 0;
    int count = 0;
    iy = oy * stride_y - pad_top;
    ix = ox * stride_x - pad_left;
    for_each(0 &lt;= ky &lt; kernel_y, 0 &lt;= kx &lt; kernel_x) {
        y = iy + ky;
        x = ix + kx;
        // Only values from the input tensor are used to calculate the
        // average, padding does not count
        if (0 &lt;= y &lt; IH and 0 &lt;= x &lt; IW) {
            count++;
            acc_t value = tensor_read&lt;in_out_t&gt;(input, [N,IH,IW,C], [n,y,x,c]);
            value = value - input_zp;
            acc = apply_add&lt;acc_t&gt;(acc, value);
        }
    }
    if (is_float(in_out_t)) {
        output_val = acc / (float)count;
    } else {
        scale_t scale = reciprocal_scale(count);
        acc = apply_scale_32(acc, scale.multiplier, scale.shift, false);
        output_val = (in_out_t)apply_clip&lt;acc_t&gt;(acc + output_zp, minimum&lt;in_out_t&gt;, maximum&lt;in_out_t&gt;)
    }
    tensor_write&lt;in_out_t&gt;(output, [N,OH,OW,C], [n,oy,ox,c], output_val);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
<th class="tableblock halign-left valign-top">acc_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 with fp16 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_conv2d">2.3.3. CONV2D</h4>
<div class="paragraph">
<p>Performs a 2D convolution over the given tensor input, using the weight tensor.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,IH,IW,IC]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input (MT profile) Attribute (BI/MI profiles)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">weight_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">weight</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[OC,KH,KW,IC]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Weight kernel size KH x KW</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input (MT profile) Attribute (BI/MI profiles)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bias</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[OC]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Per output channel bias data.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">pad</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[4]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[pad_top, pad_bottom, pad_left, pad_right]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">stride</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[2]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[stride_y, stride_x]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">dilation</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[2]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[dilation_y, dilation_x]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor zero point. Must be zero for non-int8 types.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">weight_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">weight_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Weight zero point. Must be zero for non-int8 types.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,OH,OW,OC]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">ERROR_IF(in_t != int8_t &amp;&amp; input_zp != 0); // Zero point only for int8_t
ERROR_IF(weight_t != int8_t &amp;&amp; weight_zp != 0);
ERROR_IF(pad_top &lt; 0 || pad_bottom &lt; 0 || pad_left &lt; 0 || pad_right &lt; 0);
ERROR_IF(stride_y &lt; 1 || stride_x &lt; 1);
ERROR_IF(dilation_y &lt; 1 || dilation_x &lt; 1);
ERROR_IF(OH != idiv_check(IH - 1 + pad_top + pad_bottom - (KH - 1) * dilation_y, stride_y) + 1);
ERROR_IF(OW != idiv_check(IW - 1 + pad_left + pad_right - (KW - 1) * dilation_x, stride_x) + 1);

pad = flatten([0,0], pad, [0,0]);
for_each(0 &lt;= n &lt; N, 0 &lt;= oy &lt; OH, 0 &lt;= ox &lt; OW; 0 &lt;= oc &lt; OC) {
    out_t acc = 0;
    iy = oy * stride_y - pad_top;
    ix = ox * stride_x - pad_left;
    for_each(0 &lt;= ky &lt; KH, 0 &lt;= kx &lt; KW, 0 &lt;= ic &lt; IC) {
        y = iy + ky * dilation_y;
        x = ix + kx * dilation_x;
        if (0 &lt;= y &lt; IH &amp;&amp; 0 &lt;= x &lt; IW) {
            out_t value  = tensor_read&lt;in_t&gt;(input, [N,IH,IW,IC], [n,y,x,ic]);
            out_t weight = tensor_read&lt;weight_t&gt;(weight, [OC,KH,KW,IC], [oc,ky,kx,ic]);
            value  = value - input_zp;
            weight = weight - weight_zp;
            acc = apply_add&lt;out_t&gt;(acc, value * weight);
        }
    }
    acc = apply_add&lt;out_t&gt;(acc, bias[oc]);
    tensor_write&lt;out_t&gt;(output, [N,OH,OW,OC], [n,oy,ox,oc], acc);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_t</th>
<th class="tableblock halign-left valign-top">weight_t</th>
<th class="tableblock halign-left valign-top">out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8x8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8x4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int4_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16x8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int48_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 with fp16 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_conv3d">2.3.4. CONV3D</h4>
<div class="paragraph">
<p>Performs a 3D convolution over the given input tensor.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,ID,IH,IW,IC]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input (MT profile) Attribute (BI/MI profiles)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">weight_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">weight</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[OC,KD,KH,KW,IC]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Weight kernel size KDxKHxKW</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input (MT profile) Attribute (BI/MI profiles)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bias</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[OC]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Per output channel bias data.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">pad</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[6]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[pad_d0, pad_d1, pad_top, pad_bottom, pad_left, pad_right]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">stride</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[3]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[stride_d, stride_y, stride_x]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">dilation</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[3]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[dilation_d, dilation_y, dilation_x]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor zero point. Must be zero for non-int8 types.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">weight_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">weight_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Weight zero point. Must be zero for non-int8 types.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,OD,OH,OW,OC]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">ERROR_IF(in_t != int8_t &amp;&amp; input_zp != 0); // Zero point only for int8_t
ERROR_IF(weight_t != int8_t &amp;&amp; weight_zp != 0);
ERROR_IF(pad_d0 &lt; 0 || pad_d1 &lt; 0 || pad_top &lt; 0 || pad_bottom &lt; 0 || pad_left &lt; 0 || pad_right &lt; 0);
ERROR_IF(stride_d &lt; 1 || stride_y &lt; 1 || stride_x &lt; 1);
ERROR_IF(dilation_d &lt; 1 || dilation_y &lt; 1 || dilation_x &lt; 1);
ERROR_IF(OD != idiv_check(ID - 1 + pad_d0 + pad_d1      - (KD - 1) * dilation_d, stride_d) + 1);
ERROR_IF(OH != idiv_check(IH - 1 + pad_top + pad_bottom - (KH - 1) * dilation_y, stride_y) + 1);
ERROR_IF(OW != idiv_check(IW - 1 + pad_left + pad_right - (KW - 1) * dilation_x, stride_x) + 1);

pad = flatten([0,0], pad, [0,0]);
for_each(0 &lt;= n &lt; N, 0 &lt;= od &lt; OD, 0 &lt;= oy &lt; OH, 0 &lt;= ox &lt; OW; 0 &lt;= oc &lt; OC) {
    out_t acc = 0;
    id = od * stride_d - pad_d0;
    iy = oy * stride_y - pad_top;
    ix = ox * stride_x - pad_left;
    for_each(0 &lt;= kd &lt; KD, 0 &lt;= ky &lt; KH, 0 &lt;= kx &lt; KW, 0 &lt;= ic &lt; IC) {
        d = id + kd * dilation_d;
        y = iy + ky * dilation_y;
        x = ix + kx * dilation_x;
        if (0 &lt;= x &lt; IW &amp;&amp; 0 &lt;= y &lt; IH &amp;&amp; 0 &lt;= d &lt;= ID) {
            out_t value  = tensor_read&lt;in_t&gt;(input, [N,ID,IH,IW,IC], [n,d,y,x,ic]);
            out_t weight = tensor_read&lt;weight_t&gt;(weight,[OC,KD,KH,KW,IC],[oc,kd,ky,kx,ic]);
            value  = value - input_zp;
            weight = weight - weight_zp;
            acc = apply_add&lt;out_t&gt;(acc, value * weight);
        }
    }
    acc = apply_add&lt;out_t&gt;(acc, bias[oc]);
    tensor_write&lt;out_t&gt;(output, [N,OD,OH,OW,OC], [n,od,oy,ox,oc], acc);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_t</th>
<th class="tableblock halign-left valign-top">weight_t</th>
<th class="tableblock halign-left valign-top">out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8x8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8x4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int4_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16x8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int48_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 with fp16 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_depthwise_conv2d">2.3.5. DEPTHWISE_CONV2D</h4>
<div class="paragraph">
<p>Performs 2D convolutions separately over each channel of the given tensor input, using the weight tensor.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,H,W,C]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input (MT profile) Attribute (BI/MI profiles)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">weight_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">weight</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[KH,KW,C,M]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Weight kernel size KH x KW</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input (MT profile) Attribute (BI/MI profiles)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bias</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[C*M]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Per output channel bias data.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">pad</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[4]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[pad_top, pad_bottom, pad_left, pad_right]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">stride</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[2]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[stride_y, stride_x]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">dilation</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[2]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[dilation_y, dilation_x]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor zero point. Must be zero for non-int8 types.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">weight_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">weight_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Weight zero point. Must be zero for non-int8 types.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,OH,OW,C*M]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">ERROR_IF(in_t != int8_t &amp;&amp; input_zp != 0); // Zero point only for int8_t
ERROR_IF(weight_t != int8_t &amp;&amp; weight_zp != 0);
ERROR_IF(pad_top &lt; 0 || pad_bottom &lt; 0 || pad_left &lt; 0 || pad_right &lt; 0);
ERROR_IF(stride_y &lt; 1 || stride_x &lt; 1);
ERROR_IF(dilation_y &lt; 1 || dilation_x &lt; 1);
ERROR_IF(OH != idiv_check(IH - 1 + pad_top + pad_bottom - (KH - 1) * dilation_y, stride_y) + 1);
ERROR_IF(OW != idiv_check(IW - 1 + pad_left + pad_right - (KW - 1) * dilation_x, stride_x) + 1);

pad = flatten([0,0], pad, [0,0]);
for_each(0 &lt;= n&lt;N, 0 &lt;= oy &lt; OH, 0 &lt;= ox &lt; OW; 0 &lt;= c &lt; C, 0 &lt;= m &lt; M) {
    out_t acc = 0;
    iy = oy * stride_y - pad_top;
    ix = ox * stride_x - pad_left;
    for_each(0 &lt;= ky &lt; KH, 0 &lt;= kx &lt; KW) {
        y = iy + ky * dilation_y;
        x = ix + kx * dilation_x;
        if (0 &lt;= y &lt; IH &amp;&amp; 0 &lt;= x &lt; IW) {
            out_t value  = tensor_read&lt;in_t&gt;(input, [N,IH,IW,C], [n,y,x,c]);
            out_t weight = tensor_read&lt;weight_t&gt;(weight, [KH,KW,C,M], [ky,kx,c,m]);
            value  = value - input_zp;
            weight = weight - weight_zp;
            acc = apply_add&lt;out_t&gt;(acc, value * weight);
        }
    }
    acc = apply_add&lt;out_t&gt;(acc, bias[(c * M) + m]);
    tensor_write&lt;out_t&gt;(output, [N,OH,OW,C * M], [n,oy,ox,c * M + m], acc);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_t</th>
<th class="tableblock halign-left valign-top">weight_t</th>
<th class="tableblock halign-left valign-top">out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8x8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8x4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int4_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16x8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int48_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 with fp16 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_fft2d">2.3.6. FFT2D</h4>
<div class="paragraph">
<p>Performs a batched complex 2D Fast Fourier Transform over the input.
The complex input values are constructed from the corresponding values in the input_real and input_imag tensors.
The resulting values in the output are split into the output_real and output_imag tensors.
No normalization is applied on either the forward or inverse versions of the operation.</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="/assets/images/forward_fft2d.svg" alt="forward FFT definition">
</div>
<div class="title">Figure 1. Calculation for the forward FFT2D calculation (direction=false)</div>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="/assets/images/inverse_fft2d.svg" alt="inverse FFT definition">
</div>
<div class="title">Figure 2. Calculation for the inverse FFT2D calculation (direction=true)</div>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input_real</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,H,W]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Real part of the complex input. H,W must be powers of two.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input_imag</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,H,W]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Imaginary part of the complex input. H,W must be powers of two.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">inverse</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false for forward FFT, true for inverse FFT</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output_real</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,H,W]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Real part of the complex output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output_imag</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,H,W]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Imaginary part of the complex output.</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">ERROR_IF(!power_of_two(H));
ERROR_IF(!power_of_two(W));

float sign_val = 1.0;

if (inverse) {
    sign_val = -1.0;
}

for_each(0 &lt;= n &lt; N, 0 &lt;= oy &lt; H, 0 &lt;= ox &lt; W) {
    in_out_t sum_real = 0.0;
    in_out_t sum_imag = 0.0;
    for_each(0 &lt;= iy &lt; H, 0 &lt;= ix &lt; W) {
        in_out_t val_real = tensor_read&lt;in_out_t&gt;(input_real, [N,H,W], [n,iy,ix]);
        in_out_t val_imag = tensor_read&lt;in_out_t&gt;(input_imag, [N,H,W], [n,iy,ix]);
        float_t a = sign_val * 2 * pi() * ((iy * oy) / H + (ix * ox) / W);
        sum_real += val_real * cos(a) + val_imag * sin(a);
        sum_imag += -val_real * sin(a) + val_imag * cos(a);
    }
    tensor_write&lt;in_out_t&gt;(output_real, [N,H,W], [n,oy,ox], sum_real);
    tensor_write&lt;in_out_t&gt;(output_imag, [N,H,W], [n,oy,ox], sum_imag);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI,MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_fully_connected">2.3.7. FULLY_CONNECTED</h4>
<div class="paragraph">
<p>Performs a fully connected network.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,IC]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">weight_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">weight</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[OC,IC]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bias</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[OC]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Per output channel bias data.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor zero point. Must be zero for non-int8 types.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">weight_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">weight_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Weight zero point. Must be zero for non-int8 types.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,OC]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">ERROR_IF(in_t != int8_t &amp;&amp; input_zp != 0); // Zero point only for int8_t
ERROR_IF(weight_t != int8_t &amp;&amp; weight_zp != 0);
for_each(0 &lt;= n &lt; N, 0 &lt;= oc &lt; OC) {
    out_t acc = 0;
    for_each(0 &lt;= ic &lt; IC) {
        out_t value  = tensor_read&lt;in_t&gt;(input, [N,IC], [n,ic]);
        out_t weight = tensor_read&lt;weight_t&gt;(weight, [OC,IC], [oc,ic]);
        value  = value - input_zp;
        weight = weight - weight_zp;
        acc = apply_add&lt;out_t&gt;(acc, value * weight);
    }
    acc = apply_add&lt;out_t&gt;(acc, bias[oc]);
    tensor_write&lt;out_t&gt;(output, [N,OC], [n,oc], acc);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_t</th>
<th class="tableblock halign-left valign-top">weight_t</th>
<th class="tableblock halign-left valign-top">out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8x8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8x4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int4_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16x8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int48_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 with fp16 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_matmul">2.3.8. MATMUL</h4>
<div class="paragraph">
<p>Performs two dimensional matrix multiplications. This allows both inputs to be activations, rather than reserving weights as an attribute in the FULLY_CONNECTED operator.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,H,C]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor A, N matrices of size HxC</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">B</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,C,W]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor B, N matrices of size CxW</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor A zero point. Must be zero for non-int8 types.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">B_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor B zero point. Must be zero for non-int8 types.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,H,W]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor, N matrices of size HxW</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">ERROR_IF(in_t != int8_t &amp;&amp; (A_zp != 0 || B_zp != 0)); // Zero point only for int8_t
for_each(0 &lt;= n &lt; N, 0 &lt;= h &lt; H, 0 &lt;= w &lt; W) {
    out_t acc = 0;
    for_each(0 &lt;= c &lt; C) {
        out_t value1 = tensor_read&lt;in_t&gt;(A, [N,H,C], [n,h,c]);
        out_t value2 = tensor_read&lt;in_t&gt;(B, [N,C,W], [n,c,w]);
        value1 = value1 - A_zp;
        value2 = value2 - B_zp;
        acc = apply_add&lt;out_t&gt;(acc, value1 * value2);
    }
    tensor_write&lt;out_t&gt;(output, [N,H,W], [n,h,w], acc);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_t</th>
<th class="tableblock halign-left valign-top">out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8x8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16x16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int48_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 with fp16 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_max_pool2d">2.3.9. MAX_POOL2D</h4>
<div class="paragraph">
<p>This performs a max pooling over the given input tensor. A sliding window of size given by &lt;kernel size&gt; is passed over the input tensor, with the maximum value being placed in the output tensor.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,IH,IW,C]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor 4D</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">kernel</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[2]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[kernel_y, kernel_x]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">stride</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[2]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[stride_y, stride_x]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">pad</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[4]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[pad_top, pad_bottom, pad_left, pad_right]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,OH,OW,C]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor 4D</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">ERROR_IF(kernel_y &lt; 1 || kernel_x &lt; 1); // kernel size must be &gt;= 1
ERROR_IF(stride_y &lt; 1 || stride_x &lt; 1);
ERROR_IF(pad_top &lt; 0 || pad_bottom &lt; 0 || pad_left &lt; 0 || pad_right &lt; 0);
// Padding must be less than kernel size, otherwise no
// input values will be used.
ERROR_IF(pad_right &gt;= kernel_x || pad_left &gt;= kernel_x);
ERROR_IF(pad_top &gt;= kernel_y || pad_bottom &gt;= kernel_y);
ERROR_IF(OH != idiv_check(IH + pad_top + pad_bottom - kernel_y, stride_y) + 1);
ERROR_IF(OW != idiv_check(IW + pad_left + pad_right - kernel_x, stride_x) + 1);

for_each(0 &lt;= n &lt; N, 0 &lt;= oy &lt; H, 0 &lt;= ox &lt; W, 0 &lt;= c &lt; C ) {
    in_out_t acc = minimum_value&lt;in_out_t&gt;;
    iy = oy * stride_y - pad_top;
    ix = ox * stride_x - pad_left;
    for_each( 0 &lt;= ky &lt; kernel_y, 0 &lt;= kx &lt; kernel_x ) {
        y = iy + ky;
        x = ix + kx;
        if (y &gt;= 0 &amp;&amp; y &lt; IH &amp;&amp; x &gt;= 0 &amp;&amp; x &lt; IW) {
            in_out_t value = tensor_read&lt;in_out_t&gt;(input, [N,IH,IW,C], [n,y,x,c]);
            acc = apply_max(acc, value);
        }
    }
    tensor_write&lt;in_out_t&gt;(output, [N,OH,OW,C], [n,oy,ox,c], acc);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">16-bit</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_rfft2d">2.3.10. RFFT2D</h4>
<div class="paragraph">
<p>Performs a batched 2D real-valued Fast Fourier Transform over the input where the input tensor consists of real values producing complex valued output.
The complex output values will be split into the output_real and output_imag tensor arguments.
RFFT2D takes advantage of Hermitian symmetry to only calculate the first half of the output.
Imaginary values with locations h=0,H/2 or w=0,W/2 are zero.</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="/assets/images/forward_fft2d.svg" alt="forward FFT definition">
</div>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,H,W]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Real input. H,W must be powers of two.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output_real</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,H/2 + 1,W/2 + 1]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Real part of the complex output</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output_imag</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,H/2 + 1,W/2 + 1]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Imaginary part of the complex output.</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">ERROR_IF(!power_of_two(H));
ERROR_IF(!power_of_two(W));

for_each(0 &lt;= n &lt; N, 0 &lt;= oy &lt; H/2 + 1, 0 &lt;= ox &lt; W/2 + 1) {
    in_out_t sum_real = 0.0;
    in_out_t sum_imag = 0.0;
    for_each(0 &lt;= iy &lt; H, 0 &lt;= ix &lt; W) {
        in_out_t val_real = tensor_read&lt;in_out_t&gt;(input_real, [N,H,W], [n,iy,ix]);
        float_t a = 2 * pi() * ((iy * oy) / H + (ix * ox) / W);
        sum_real += val_real * cos(a);
        sum_imag += -val_real * sin(a);
    }
    tensor_write&lt;in_out_t&gt;(output_real, [N,H,W], [n,oy,ox], sum_real);
    tensor_write&lt;in_out_t&gt;(output_imag, [N,H,W], [n,oy,ox], sum_imag);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI,MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_transpose_conv2d">2.3.11. TRANSPOSE_CONV2D</h4>
<div class="paragraph">
<p>Performs a 2D transposed convolution over the given tensor input, using the weights tensor.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,IH,IW,IC]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input (MT profile) Attribute (BI/MI profiles)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">weight_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">weight</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[OC,KH,KW,IC]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Weight kernel size KH x KW</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input (MT profile) Attribute (BI/MI profiles)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bias</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[OC]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Per output channel bias data.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">out_pad</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[4]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[out_pad_top, out_pad_bottom, out_pad_left, out_pad_right]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">stride</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[2]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[stride_y, stride_x]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">out_shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[4]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,OH,OW,OC]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor zero point. Must be zero for non-int8 types.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">weight_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">weight_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Weight zero point. Must be zero for non-int8 types.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,OH,OW,OC]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">ERROR_IF(in_t != int8_t  &amp;&amp; input_zp != 0); // Zero point only allowed for int8_t
ERROR_IF(weight_t != int8_t &amp;&amp; weight_zp != 0);
ERROR_IF(out_pad_top &lt; 0 || out_pad_bottom &lt; 0);
ERROR_IF(out_pad_left &lt; 0 || out_pad_right &lt; 0);
ERROR_IF(stride_y &lt; 1 || stride_x &lt; 1);
ERROR_IF(OH != (IH - 1) * stride_y - out_pad_top - out_pad_bottom + KH);
ERROR_IF(OW != (IW - 1) * stride_x - out_pad_left - out_pad_right + KW);

for_each(index in out_shape) {
    tensor_write&lt;out_t&gt;(output, [N,OH,OW,OC], index, bias[index[3]])
}
for_each(0 &lt;= n &lt; N, 0 &lt;= iy &lt; IH, 0 &lt;= ix &lt; IW, 0 &lt;= oc &lt; OC,
          0 &lt;= ic &lt; IC, 0 &lt;= ky &lt; KH,  0 &lt;= kx &lt; KW) {
    oy = iy * stride_y - out_pad_top  + ky;
    ox = ix * stride_x - out_pad_left + kx;
    if (oy &gt;= 0 &amp;&amp; oy &lt; OH &amp;&amp; ox &gt;= 0 &amp;&amp; ox &lt; OW) {
        out_t acc = tensor_read&lt;out_t&gt;(output, [N,OH,OW,OC], [n,oy,ox,oc]);
        out_t value = tensor_read&lt;in_t&gt;(input, [N,IH,IW,IC], [n,iy,ix,ic]);
        out_t weight = tensor_read&lt;weight_t&gt;(weight, [OC,KH,KW,IC], [oc,ky,kx,ic]);
        value = value - input_zp;
        weight = weight - weight_zp;
        acc = apply_add&lt;out_t&gt;(acc, value * weight);
        tensor_write&lt;out_t&gt;(output, [N,OH,OW,OC], [n,oy,ox,oc], acc);
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_t</th>
<th class="tableblock halign-left valign-top">weight_t</th>
<th class="tableblock halign-left valign-top">out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8x8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8x4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int4_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16x8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int48_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 with fp16 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16 with fp32 accumulate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_activation_functions">2.4. Activation Functions</h3>
<div class="sect3">
<h4 id="_clamp">2.4.1. CLAMP</h4>
<div class="paragraph">
<p>Clamp to an arbitrary minimum and maximum value.
Maximum and minimum values are specified as values in the range of the input type.
No zero point subtraction is done to the values, thus to clamp to the zero point value, the zero point itself should be supplied as the minimum value.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">min_val</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">minimum clip value</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">max_val</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">maximum clip value</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type and shape as input</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">ERROR_IF(max_val &lt; min_val);
for_each(index in shape) {
    in_out_t value = tensor_read&lt;in_out_t&gt;(input, shape, index);
    value = apply_clip&lt;in_out_t&gt;(value, min_val, max_val);
    tensor_write&lt;in_out_t&gt;(output, shape, index, value);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_sigmoid">2.4.2. SIGMOID</h4>
<div class="paragraph">
<p>Sigmoid function: output = 1 / (1 + exp(-input))</p>
</div>
<div class="paragraph">
<p>For quantized integer data types, the TABLE operator should be used instead with
the following definition.</p>
</div>
<div class="paragraph">
<p>The sigmoid table has 513 entries each of 16-bit precision and covering the input range -16.0 to +16.0 in steps of 1/16.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">int16_t sigmoid_reference(int16_t x) { // input x range is -256 to + 256 inclusive
    F64 v = (double)x / (double)16;
    v = 1.0/(1.0 + exp(-v));
    return round_to_nearest_int(32768.0 * v);
}

generate_lookup_table(&amp;sigmoid_table, &amp;sigmoid_reference);</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type and shape as input</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_tanh">2.4.3. TANH</h4>
<div class="paragraph">
<p>Parameterized hyperbolic tangent.</p>
</div>
<div class="paragraph">
<p>For quantized integer data types, the TABLE operator should be used instead with
the following definition.</p>
</div>
<div class="paragraph">
<p>The tanh_table has 513 entries each of 16-bit precision and covering the input range -8.0 to +8.0 in steps of 1/32. The table is specified by:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">int16_t tanh_reference(int16_t x) {  // input x range is -256 to +256 inclusive
    F64 v = (double)x/(double)32;
    v = exp(-2.0*v);
    v = (1.0-v)/(1.0+v);
    return round_to_nearest_int(32768.0 * v);
}

generate_lookup_table(&amp;tanh_table, &amp;tanh_reference);</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type and shape as input</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_elementwise_binary_operators">2.5. Elementwise Binary Operators</h3>
<div class="sect3">
<h4 id="_add">2.5.1. ADD</h4>
<div class="paragraph">
<p>Elementwise addition of input1 and input2.
Axis of size 1 will be broadcast, as necessary. Rank of input tensors must match.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with the same rank as input1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor with broadcast shape if necessary</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">for_each(index in shape) {
    index1 = apply_broadcast(shape, shape1, index);
    index2 = apply_broadcast(shape, shape2, index);
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape1, index1);
    in_out_t value2 = tensor_read&lt;in_out_t&gt;(input2, shape2, index2);
    in_out_t result = apply_add&lt;in_out_t&gt;(value1, value2);
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_arithmetic_right_shift">2.5.2. ARITHMETIC_RIGHT_SHIFT</h4>
<div class="paragraph">
<p>Elementwise arithmetic right shift of input1 by the amount specified in input2.
Axis of size 1 will be broadcast, as necessary. Rank of input tensors must match.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with the same rank as input1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">round</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">If true then the shift is rounded</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor with broadcast shape if necessary</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">for_each(index in shape) {
    index1 = apply_broadcast(shape, shape1, index);
    index2 = apply_broadcast(shape, shape2, index);
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape1, index1);
    in_out_t value2 = tensor_read&lt;in_out_t&gt;(input2, shape2, index2);

    // Ensure that shift amount is appropriate for the data type
    REQUIRE((in_out_t == int32_t &amp;&amp; 0 &lt;= value2 &amp;&amp; value2 &lt;= 31) ||
            (in_out_t == int16_t &amp;&amp; 0 &lt;= value2 &amp;&amp; value2 &lt;= 15) ||
            (in_out_t == int8_t &amp;&amp; 0 &lt;= value2 &amp;&amp; value2 &lt;= 7));

    in_out_t result = value1 &gt;&gt; value2;
    if (round == true &amp;&amp; value2 &gt; 0 &amp;&amp; (value1 &gt;&gt; (value2 - 1)) &amp; 1 != 0) {
        result = result + 1;
    }
    result = apply_clip&lt;in_out_t&gt;(result, minimum&lt;in_out_t&gt;, maximum&lt;in_out_t&gt;);
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_bitwise_and">2.5.3. BITWISE_AND</h4>
<div class="paragraph">
<p>Elementwise bitwise AND of input1 and input2.
Axis of size 1 will be broadcast as necessary. Rank of input tensors must match.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with the same rank as input1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type as the input tensors, with broadcast shape if necessary</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">for_each(index in shape) {
    index1 = apply_broadcast(shape, shape1, index);
    index2 = apply_broadcast(shape, shape2, index);
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape1, index1);
    in_out_t value2 = tensor_read&lt;in_out_t&gt;(input2, shape2, index2);
    in_out_t result = value1 &amp; value2;
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_bitwise_or">2.5.4. BITWISE_OR</h4>
<div class="paragraph">
<p>Elementwise bitwise OR of input1 and input2.
Axis of size 1 will be broadcast as necessary. Rank of input tensors must match.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with the same rank as input1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor with broadcast shape if necessary</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">for_each(index in shape) {
    index1 = apply_broadcast(shape, shape1, index);
    index2 = apply_broadcast(shape, shape2, index);
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape1, index1);
    in_out_t value2 = tensor_read&lt;in_out_t&gt;(input2, shape2, index2);
    in_out_t result = value1 | value2;
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_bitwise_xor">2.5.5. BITWISE_XOR</h4>
<div class="paragraph">
<p>Elementwise bitwise XOR of input1 and input2.
Axis of size 1 will be broadcast as necessary. Rank of input tensors must match.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with the same rank as input1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor with broadcast shape if necessary</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">for_each(index in shape) {
    index1 = apply_broadcast(shape, shape1, index);
    index2 = apply_broadcast(shape, shape2, index);
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape1, index1);
    in_out_t value2 = tensor_read&lt;in_out_t&gt;(input2, shape2, index2);
    in_out_t result = value1 ^ value2;
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_intdiv">2.5.6. INTDIV</h4>
<div class="paragraph">
<p>Elementwise integer divide of input1 by input2.
The result of the divide is truncated towards zero.
Expected use is for operations on non-scaled integers.
Floating point divide should use RECIPROCAL and MUL.
Quantized integer divide should use TABLE (for 1/x) and MUL.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with the same rank as input1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor with broadcast shape if necessary</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">for_each(index in shape) {
    index1 = apply_broadcast(shape, shape1, index);
    index2 = apply_broadcast(shape, shape2, index);
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape1, index1);
    in_out_t value2 = tensor_read&lt;in_out_t&gt;(input2, shape2, index2);
    REQUIRE(value2 != 0);
    // This catches the case where we divide minimum&lt;in_out_t&gt; by -1
    // which is not representable in two's complement
    REQUIRE((int64_t)value1 / value2 &lt;= maximum&lt;in_out_t&gt;);
    in_out_t result = value1 / value2;
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_logical_and">2.5.7. LOGICAL_AND</h4>
<div class="paragraph">
<p>Elementwise logical AND of input1 and input2.
Axis of size 1 will be broadcast, as necessary. Rank of input tensors must match.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with the same rank as input1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor with broadcast shape if necessary</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">for_each(index in shape) {
    index1 = apply_broadcast(shape, shape1, index);
    index2 = apply_broadcast(shape, shape2, index);
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape1, index1);
    in_out_t value2 = tensor_read&lt;in_out_t&gt;(input2, shape2, index2);
    in_out_t result = value1 &amp;&amp; value2;
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Bool</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_logical_left_shift">2.5.8. LOGICAL_LEFT_SHIFT</h4>
<div class="paragraph">
<p>Elementwise left shift of input1 and input2.
Axis of size 1 will be broadcast, as necessary. Rank of input tensors must match.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with the same rank as input1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor with broadcast shape if necessary</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">for_each(index in shape) {
    index1 = apply_broadcast(shape, shape1, index);
    index2 = apply_broadcast(shape, shape2, index);
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape1, index1);
    in_out_t value2 = tensor_read&lt;in_out_t&gt;(input2, shape2, index2);
    REQUIRE(0 &lt;= value2 &amp;&amp; value2 &lt;= 31);
    in_out_t result = value1 &lt;&lt; value2;
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_logical_right_shift">2.5.9. LOGICAL_RIGHT_SHIFT</h4>
<div class="paragraph">
<p>Elementwise logical right shift of input1 by the amount specified in input2.
Axis of size 1 will be broadcast, as necessary. Rank of input tensors must match.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with the same rank as input1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor with broadcast shape if necessary</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">for_each(index in shape) {
    index1 = apply_broadcast(shape, shape1, index);
    index2 = apply_broadcast(shape, shape2, index);
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape1, index1);
    in_out_t value2 = tensor_read&lt;in_out_t&gt;(input2, shape2, index2);
    REQUIRE(0 &lt;= value2 &amp;&amp; value2 &lt;= 31);
    in_out_t result = (in_out_t)((unsigned in_out_t)value1 &gt;&gt; value2);
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_logical_or">2.5.10. LOGICAL_OR</h4>
<div class="paragraph">
<p>Elementwise logical OR of input1 and input2.
Axis of size 1 will be broadcast as necessary. Rank of input tensors must match.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with the same rank as input1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor with broadcast shape if necessary</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">for_each(index in shape) {
    index1 = apply_broadcast(shape, shape1, index);
    index2 = apply_broadcast(shape, shape2, index);
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape1, index1);
    in_out_t value2 = tensor_read&lt;in_out_t&gt;(input2, shape2, index2);
    in_out_t result = value1 || value2;
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Bool</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_logical_xor">2.5.11. LOGICAL_XOR</h4>
<div class="paragraph">
<p>Elementwise logical XOR of input1 and input2.
Axis of size 1 will be broadcast as necessary. Rank of input tensors must match.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with the same rank as input1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type as the input tensors, with broadcast shape if necessary</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">for_each(index in shape) {
    index1 = apply_broadcast(shape, shape1, index);
    index2 = apply_broadcast(shape, shape2, index);
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape1, index1);
    in_out_t value2 = tensor_read&lt;in_out_t&gt;(input2, shape2, index2);
    in_out_t result = value1 != value2;
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Bool</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_maximum">2.5.12. MAXIMUM</h4>
<div class="paragraph">
<p>Elementwise max of input1 and input2.
Axis of size 1 will be broadcast, as necessary. Rank of input tensors must match.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with the same rank as input1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor with broadcast shape if necessary</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">for_each(index in shape) {
    index1 = apply_broadcast(shape, shape1, index);
    index2 = apply_broadcast(shape, shape2, index);
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape1, index1);
    in_out_t value2 = tensor_read&lt;in_out_t&gt;(input2, shape2, index2);
    in_out_t result = apply_max(value1, value2);
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_minimum">2.5.13. MINIMUM</h4>
<div class="paragraph">
<p>Elementwise minimum of input1 and input2.
Axis of size 1 will be broadcast, as necessary. Rank of input tensors must match.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with the same rank as input1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor with broadcast shape if necessary</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">for_each(index in shape) {
    index1 = apply_broadcast(shape, shape1, index);
    index2 = apply_broadcast(shape, shape2, index);
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape1, index1);
    in_out_t value2 = tensor_read&lt;in_out_t&gt;(input2, shape2, index2);
    in_out_t result = apply_min(value1, value2);
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_mul">2.5.14. MUL</h4>
<div class="paragraph">
<p>Elementwise multiplication (Hadamard product) of input1 and input2.
Axis of size 1 will be broadcast, as necessary. Rank of input tensors must match.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with the same rank as input1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input (MT profile) Attribute (BI/MI profiles)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">uint6_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shift</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Result right shift (int32_t data type only)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor with broadcast shape if necessary</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">ERROR_IF(in_t != int32_t &amp;&amp; shift &gt; 0);
for_each(index in shape) {
    index1 = apply_broadcast(shape, shape1, index);
    index2 = apply_broadcast(shape, shape2, index);
    in_t value1 = tensor_read&lt;in_t&gt;(input1, shape1, index1);
    in_t value2 = tensor_read&lt;in_t&gt;(input2, shape2, index2);
    out_t result;
    if (in_t == int32_t &amp;&amp; shift &gt; 0) {
        int64_t product = (int64_t)value1 * (int64_t)value2;
        int64_t round   = (int64_t)1 &lt;&lt; (shift-1);
        product = (product + round) &gt;&gt; shift;
        REQUIRE(product &gt;= minimum&lt;int32_t&gt; &amp;&amp; product &lt;= maximum&lt;int32_t&gt;)
        result = product;
    } else {
        result = value1 * value2;  // low 32-bits of result for int32_t
    }
    tensor_write&lt;out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_t</th>
<th class="tableblock halign-left valign-top">out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_pow">2.5.15. POW</h4>
<div class="paragraph">
<p>Elementwise input1 value raised to the power of input2.
Axis of size 1 will be broadcast, as necessary. Rank of input tensors must match.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor from 1 to 4 dims</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with the same rank as input1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type as the input tensors, with broadcast shape if necessary</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">for_each(index in shape) {
    index1 = apply_broadcast(shape, shape1, index);
    index2 = apply_broadcast(shape, shape2, index);
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape1, index1);
    in_out_t value2 = tensor_read&lt;in_out_t&gt;(input2, shape2, index2);
    in_out_t result = apply_pow&lt;in_out_t&gt;(value1, value2);
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_sub">2.5.16. SUB</h4>
<div class="paragraph">
<p>Elementwise subtraction of input1 and input2.
Axis of size 1 will be broadcast as necessary. Rank of input tensors must match.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with the same rank as input1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor with broadcast shape if necessary</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">for_each(index in shape) {
    index1 = apply_broadcast(shape, shape1, index);
    index2 = apply_broadcast(shape, shape2, index);
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape1, index1);
    in_out_t value2 = tensor_read&lt;in_out_t&gt;(input2, shape2, index2);
    in_out_t result = apply_sub&lt;in_out_t&gt;(value1, value2);
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_table">2.5.17. TABLE</h4>
<div class="paragraph">
<p>Table lookup operation.
For int8_t TABLE operation, perform a 256 entry table lookup returning an int8_t value.
For int16_t tables, the int16_t input is treated as a fixed-point 9.7 value.
The most significant 9 bits are used to index into the table.
The fractional 7 bits are used to interpolate based on table[index] and table[index+1].
For int16_t inputs, the TABLE operator returns a 16.7 interpolated value in an int32_t.
This value can then be input to the RESCALE operator to scale to the required output data type.
Note that int16_t table has 513 values to handle table[index+1] when index=511.</p>
</div>
<div class="paragraph">
<p>An int16_t to int16_t table lookup can be constructed in TOSA as follows:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Use the TABLE operator to produce a fixed point 16.7 interpolated result</p>
</li>
<li>
<p>Use RESCALE (in_t=int32_t, out_t=int16_t, scale=1&lt;&lt;14, shift=21) to scale the output to int16_t range (or alternate scale as required)</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input (MT profile) Attribute (BI/MI profiles)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">table_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">table</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[TABLE_SIZE]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Lookup table tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">REQUIRE(length(table) == TABLE_SIZE);
for_each(index in shape) {
    in_t value = tensor_read&lt;in_t&gt;(input, shape, index);
    out_t result;
    if (in_t == int8_t) {
        // value is a signed int, convert to a 0 based index
        result = table[value + 128];
    } else {
        result = apply_lookup(table, value);
    }
    tensor_write&lt;out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_t</th>
<th class="tableblock halign-left valign-top">table_t</th>
<th class="tableblock halign-left valign-top">TABLE_SIZE</th>
<th class="tableblock halign-left valign-top">out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">256</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">513</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_elementwise_unary_operators">2.6. Elementwise Unary Operators</h3>
<div class="sect3">
<h4 id="_abs">2.6.1. ABS</h4>
<div class="paragraph">
<p>Elementwise absolute value operation</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type, size as the input tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Floating-point behavior:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Input</th>
<th class="tableblock halign-left valign-top">-infinity</th>
<th class="tableblock halign-left valign-top">+infinity</th>
<th class="tableblock halign-left valign-top">-0</th>
<th class="tableblock halign-left valign-top">+0</th>
<th class="tableblock halign-left valign-top">NaN</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">NaN</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">for_each(index in shape) {
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape, index);
    if (in_out_t == float_t &amp;&amp; value1 == -0.0) {
        value1 = 0.0;
    }
    if (value1 &lt; 0.0)
        value1 = apply_sub&lt;in_out_t&gt;(0, value1);
    tensor_write&lt;in_out_t&gt;(output, shape, index, value1);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">floating-point</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_bitwise_not">2.6.2. BITWISE_NOT</h4>
<div class="paragraph">
<p>Elementwise bitwise NOT of input tensor.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type, size as the input tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">for_each(index in shape) {
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape, index);
    in_out_t result = ~value1;
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_ceil">2.6.3. CEIL</h4>
<div class="paragraph">
<p>Elementwise ceiling operation</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type, size as the input tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Floating-point behavior:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Input</th>
<th class="tableblock halign-left valign-top">-infinity</th>
<th class="tableblock halign-left valign-top">+infinity</th>
<th class="tableblock halign-left valign-top">-0</th>
<th class="tableblock halign-left valign-top">+0</th>
<th class="tableblock halign-left valign-top">NaN</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">NaN</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">for_each(index in shape) {
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape, index);
    in_out_t result = apply_ceil&lt;in_out_t&gt;(value1);
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">floating-point</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_clz">2.6.4. CLZ</h4>
<div class="paragraph">
<p>Elementwise count leading zeros operation</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type, size as the input tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">for_each(index in shape) {
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape, index);
    in_out_t result = count_leading_zeros(value1);
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_exp">2.6.5. EXP</h4>
<div class="paragraph">
<p>Elementwise e to the x operation</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type, size as the input tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Floating-point behavior:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Input</th>
<th class="tableblock halign-left valign-top">-infinity</th>
<th class="tableblock halign-left valign-top">+infinity</th>
<th class="tableblock halign-left valign-top">-0</th>
<th class="tableblock halign-left valign-top">+0</th>
<th class="tableblock halign-left valign-top">NaN</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">NaN</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">for_each(index in shape) {
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape, index);
    in_out_t result = apply_exp&lt;in_out_t&gt;(value1);
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_floor">2.6.6. FLOOR</h4>
<div class="paragraph">
<p>Elementwise floor operation</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type, size as the input tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Floating-point behavior:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Input</th>
<th class="tableblock halign-left valign-top">-infinity</th>
<th class="tableblock halign-left valign-top">+infinity</th>
<th class="tableblock halign-left valign-top">-0</th>
<th class="tableblock halign-left valign-top">+0</th>
<th class="tableblock halign-left valign-top">NaN</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">NaN</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">for_each(index in shape) {
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape, index);
    in_out_t result = apply_floor&lt;in_out_t&gt;(value1);
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_log">2.6.7. LOG</h4>
<div class="paragraph">
<p>Elementwise natural logarithm operation</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type, size as the input tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Floating-point behavior:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Input</th>
<th class="tableblock halign-left valign-top">-infinity</th>
<th class="tableblock halign-left valign-top">+infinity</th>
<th class="tableblock halign-left valign-top">-0</th>
<th class="tableblock halign-left valign-top">+0</th>
<th class="tableblock halign-left valign-top">NaN</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">NaN</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">NaN</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">for_each(index in shape) {
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape, index);
    in_out_t result = apply_log&lt;in_out_t&gt;(value1);
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_logical_not">2.6.8. LOGICAL_NOT</h4>
<div class="paragraph">
<p>Elementwise logical NOT of input.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type, size as the input tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">for_each(index in shape) {
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape1, index);
    in_out_t result = !value1;
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_negate">2.6.9. NEGATE</h4>
<div class="paragraph">
<p>Elementwise negation operation</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input 1 zero point. Must be zero for non-int8 types.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output zero point. Must be zero for non-int8 types.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type, size as the input tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Floating-point behavior:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Input</th>
<th class="tableblock halign-left valign-top">-infinity</th>
<th class="tableblock halign-left valign-top">+infinity</th>
<th class="tableblock halign-left valign-top">-0</th>
<th class="tableblock halign-left valign-top">+0</th>
<th class="tableblock halign-left valign-top">NaN</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">NaN</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">ERROR_IF(in_out_t != int8_t &amp;&amp; input1_zp != 0) // Zero point only for int8_t
ERROR_IF(in_out_t != int8_t &amp;&amp; output_zp != 0) // Zero point only for int8_t
for_each(index in shape) {
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape, index);
    acc_t value = (acc_t)value1 - input1_zp;
    value = apply_sub&lt;acc_t&gt;(0, value);
    in_out_t result = (in_out_t)apply_clip&lt;acc_t&gt;(value + output_zp, minimum&lt;in_out_t&gt;, maximum&lt;in_out_t&gt;);
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
<th class="tableblock halign-left valign-top">acc_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_reciprocal">2.6.10. RECIPROCAL</h4>
<div class="paragraph">
<p>Elementwise reciprocal operation. For integer operation, a TABLE should be used with the appropriate ranges.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type, size as the input tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Floating-point behavior:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Input</th>
<th class="tableblock halign-left valign-top">-infinity</th>
<th class="tableblock halign-left valign-top">+infinity</th>
<th class="tableblock halign-left valign-top">-0</th>
<th class="tableblock halign-left valign-top">+0</th>
<th class="tableblock halign-left valign-top">NaN</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">NaN</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">for_each(index in shape) {
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape1, index);
    in_out_t result = 1.0 / value1;
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_rsqrt">2.6.11. RSQRT</h4>
<div class="paragraph">
<p>Elementwise reciprocal square root operation. For integer operation, a TABLE should be used with the appropriate ranges.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type, size as the input tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Floating-point behavior:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.6666%;">
<col style="width: 16.667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Input</th>
<th class="tableblock halign-left valign-top">-infinity</th>
<th class="tableblock halign-left valign-top">+infinity</th>
<th class="tableblock halign-left valign-top">-0</th>
<th class="tableblock halign-left valign-top">+0</th>
<th class="tableblock halign-left valign-top">NaN</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">NaN</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">+infinity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">NaN</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">for_each(index in shape) {
    in_out_t value1 = tensor_read&lt;in_out_t&gt;(input1, shape1, index);
    in_out_t result;
    if (value1 &lt; 0) {
        result = NaN;
    }
    else {
        result = 1.0 / apply_sqrt&lt;in_out_t&gt;(value1);
    }
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_elementwise_ternary_operators">2.7. Elementwise Ternary Operators</h3>
<div class="sect3">
<h4 id="_select">2.7.1. SELECT</h4>
<div class="paragraph">
<p>Elementwise select of the output based on a condition.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">cmp_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input selector tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input value tensor if input1 is True</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input value tensor if input1 is False</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type as input2 and input3, with broadcast shape if necessary</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">for_each(index in shape) {
    index1 = apply_broadcast(shape, shape1, index);
    index2 = apply_broadcast(shape, shape2, index);
    index3 = apply_broadcast(shape, shape3, index);
    cmp_t value1 = tensor_read&lt;cmp_t&gt;(input1, shape1, index1);
    in_out_t value2 = tensor_read&lt;in_out_t&gt;(input2, shape2, index2);
    in_out_t value3 = tensor_read&lt;in_out_t&gt;(input3, shape3, index3);
    in_out_t result;
    if (value1) {
         result = value2;
    } else {
         result = value3;
    }
    tensor_write&lt;in_out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">cmp_t</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_comparison_operators">2.8. Comparison Operators</h3>
<div class="sect3">
<h4 id="_equal">2.8.1. EQUAL</h4>
<div class="paragraph">
<p>Elementwise comparison operation</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with the same rank as input1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor with broadcast shape if necessary</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">for_each(index in shape) {
    index1 = apply_broadcast(shape, shape1, index);
    index2 = apply_broadcast(shape, shape2, index);
    in_t value1 = tensor_read&lt;in_t&gt;(input1, shape1, index1);
    in_t value2 = tensor_read&lt;in_t&gt;(input2, shape2, index2);
    out_t result;
    if (isNaN(value1) || isNaN(value2))
        result = False;
    else
        result = (value1 == value2) ? True : False;
    tensor_write&lt;out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_t</th>
<th class="tableblock halign-left valign-top">out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_greater">2.8.2. GREATER</h4>
<div class="paragraph">
<p>Elementwise greater than comparison operation</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with the same rank as input1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor with broadcast shape if necessary</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">for_each(index in shape) {
    index1 = apply_broadcast(shape, shape1, index);
    index2 = apply_broadcast(shape, shape2, index);
    in_t value1 = tensor_read&lt;in_t&gt;(input1, shape1, index1);
    in_t value2 = tensor_read&lt;in_t&gt;(input2, shape2, index2);
    out_t result;
    if (isNaN(value1) || isNaN(value2))
        result = False;
    else
        result = (value1 &gt; value2) ? True : False;
    tensor_write&lt;out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_t</th>
<th class="tableblock halign-left valign-top">out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_greater_equal">2.8.3. GREATER_EQUAL</h4>
<div class="paragraph">
<p>Elementwise comparison operation</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with the same rank as input1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor with broadcast shape if necessary</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">for_each(index in shape) {
    index1 = apply_broadcast(shape, shape1, index);
    index2 = apply_broadcast(shape, shape2, index);
    in_t value1 = tensor_read&lt;in_t&gt;(input1, shape1, index1);
    in_t value2 = tensor_read&lt;in_t&gt;(input2, shape2, index2);
    out_t result;
    if (isNaN(value1) || isNaN(value2))
        result = False;
    else
        result = (value1 &gt;= value2) ? True : False;
    tensor_write&lt;out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_t</th>
<th class="tableblock halign-left valign-top">out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_reduction_operators">2.9. Reduction Operators</h3>
<div class="sect3">
<h4 id="_reduce_all">2.9.1. REDUCE_ALL</h4>
<div class="paragraph">
<p>Reduce a tensor along the given axis with a logical AND operation</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with rank from 1 to 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">axis</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Axis to reduce, in range from 0 to rank(shape1)-1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor. Same rank as the input tensor.</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">ERROR_IF(axis &lt; 0  || axis &gt;= rank(shape1));
ERROR_IF(shape[axis] != 1);

// Initialize output state to true
for_each(index in shape) {
    tensor_write&lt;in_out_t&gt;(output, shape, index, true);
}
for_each(index in shape1) {
    out_index = index;
    out_index[axis] = 0;
    in_out_t value = tensor_read&lt;in_out_t&gt;(input, shape1, index);
    in_out_t state = tensor_read&lt;in_out_t&gt;(output, shape, out_index);
    state      = state &amp;&amp; value;
    tensor_write&lt;in_out_t&gt;(output, shape, out_index, state);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_reduce_any">2.9.2. REDUCE_ANY</h4>
<div class="paragraph">
<p>Reduce a tensor along the given axis with a logical OR operation</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with rank from 1 to 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">axis</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Axis to reduce, in range from 0 to rank(shape1)-1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor. Same rank as the input tensor.</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">ERROR_IF(axis &lt; 0  || axis &gt;= rank(shape1));
ERROR_IF(shape[axis] != 1);

// Initialize output state to false
for_each(index in shape) {
    tensor_write&lt;in_out_t&gt;(output, shape, index, false);
}
for_each(index in shape1) {
    out_index = index;
    out_index[axis] = 0;
    in_out_t value = tensor_read&lt;in_out_t&gt;(input, shape1, index);
    in_out_t state = tensor_read&lt;in_out_t&gt;(output, shape, out_index);
    state      = state || value;
    tensor_write&lt;in_out_t&gt;(output, shape, out_index, state);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_reduce_max">2.9.3. REDUCE_MAX</h4>
<div class="paragraph">
<p>Reduce a tensor along the given axis with a maximum operation</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with rank from 1 to 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">axis</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Axis to reduce, in range from 0 to rank(shape1)-1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor. Same rank as the input tensor.</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">ERROR_IF(axis &lt; 0  || axis &gt;= rank(shape1));
ERROR_IF(shape[axis] != 1);
for_each(index in shape) {
    tensor_write&lt;in_out_t&gt;(output, shape, index, minimum&lt;in_out_t&gt;);
}
for_each(index in shape1) {
    out_index = index;
    out_index[axis] = 0;
    in_out_t value = tensor_read&lt;in_out_t&gt;(input, shape1, index);
    in_out_t state = tensor_read&lt;in_out_t&gt;(output, shape, out_index);
    state      = apply_max&lt;in_out_t&gt;(state, value);
    tensor_write&lt;in_out_t&gt;(output, shape, out_index, state);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_reduce_min">2.9.4. REDUCE_MIN</h4>
<div class="paragraph">
<p>Reduce a tensor along the given axis with a minimum operation</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with rank from 1 to 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">axis</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Axis to reduce, in range from 0 to rank(shape1)-1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor. Same rank as the input tensor.</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">ERROR_IF(axis &lt; 0  || axis &gt;= rank(shape1));
ERROR_IF(shape[axis] != 1);
for_each(index in shape) {
    tensor_write&lt;in_out_t&gt;(output, shape, index, maximum&lt;in_out_t&gt;);
}
for_each(index in shape1) {
    out_index = index;
    out_index[axis] = 0;
    in_out_t value = tensor_read&lt;in_out_t&gt;(input, shape1, index);
    in_out_t state = tensor_read&lt;in_out_t&gt;(output, shape, out_index);
    state      = apply_min&lt;in_out_t&gt;(state, value);
    tensor_write&lt;in_out_t&gt;(output, shape, out_index, state);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_reduce_product">2.9.5. REDUCE_PRODUCT</h4>
<div class="paragraph">
<p>Reduce a tensor along the given axis by computing the product of the axis.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with rank from 1 to 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">axis</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Axis to reduce, in range from 0 to rank(shape1)-1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor. Same rank as the input tensor.</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">ERROR_IF(axis &lt; 0  || axis &gt;= rank(shape1));
ERROR_IF(shape[axis] != 1);
for_each(index in shape) {
    tensor_write&lt;in_out_t&gt;(output, shape, index, 1.0);
}
for_each(index in shape1) {
    out_index = index;
    out_index[axis] = 0;
    in_out_t value = tensor_read&lt;in_out_t&gt;(input, shape1, index);
    in_out_t state = tensor_read&lt;in_out_t&gt;(output, shape, out_index);
    state      = state * value;
    tensor_write&lt;in_out_t&gt;(output, shape, out_index, state);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_reduce_sum">2.9.6. REDUCE_SUM</h4>
<div class="paragraph">
<p>Reduce a tensor along the given axis by computing the sum of the axis.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with rank from 1 to 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">axis</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Axis to reduce, in range from 0 to rank(shape1)-1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor. Same rank as the input tensor.</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">ERROR_IF(axis &lt; 0  || axis &gt;= rank(shape1));
ERROR_IF(shape[axis] != 1);
for_each(index in shape) {
    tensor_write&lt;in_out_t&gt;(output, shape, index, 0);
}
for_each(index in shape1) {
    out_index = index;
    out_index[axis] = 0;
    in_out_t value = tensor_read&lt;in_out_t&gt;(input, shape1, index);
    in_out_t state = tensor_read&lt;in_out_t&gt;(output, shape, out_index);
    state      = apply_add&lt;in_out_t&gt;(state, value);
    tensor_write&lt;in_out_t&gt;(output, shape, out_index, state);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_data_layout">2.10. Data Layout</h3>
<div class="sect3">
<h4 id="_concat">2.10.1. CONCAT</h4>
<div class="paragraph">
<p>Concatenate a list of tensors along a given axis.
No data conversion happens during a concat operation.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shapes1[]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">List of input tensors. All inputs must have the same rank and data type</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">axis</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Axis along which concatenation is to occur, in range from 0 to rank(shape)-1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c" data-lang="c">ERROR_IF(axis &lt; 0 || axis &gt;= rank(shapes1[0]));
ERROR_IF(shape[axis] != sum(shape1[k][axis] for all k))
// The following checks ensure all inputs are compatible for concatenation
for_each(input_shape in shapes1) {
    ERROR_IF(rank(input_shape) != rank(shapes1[0]));
    for_each(index in input_shape) {
        ERROR_IF(input_shape[index] != shapes1[0][index] &amp;&amp; index != axis);
    }
}
for_each(index1 in shape) {
    index2 = index1;
    for (tensor t = 0; t &lt; length(input1); t++) {
        // Continue to concatenate along axis from each tensor
        // For each output location, we are looking for the
        // appropriate input tensor
        if (index2[axis] &gt;= 0 &amp;&amp; index2[axis] &lt; shapes1[t][axis]) {
            in_out_t value = tensor_read&lt;in_out_t&gt;(input1[t], shapes1[t], index2);
            tensor_write&lt;in_out_t&gt;(output, shape, index1, value);
        }
        index2[axis] = index2[axis] - shapes1[t][axis];
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_pad">2.10.2. PAD</h4>
<div class="paragraph">
<p>Pads a tensor along the borders of each dimension with a supplied value.
Returns a new tensor with the padding included.
The pad_const value includes the zero point if the tensor uses a zero point.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">padding</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[rank(input1),2]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Amount of padding to be done</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">pad_const</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Constant value to be used as padding</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type as the input tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">// Padding sizes must be &gt;= 0.
for_each(pad_size in padding) {
    ERROR_IF(pad_size &lt; 0);
}
for_each(index in shape) {
    index1 = index;
    bool_t is_pad = false;
    for(i = 0; i &lt; rank(shape); i++) {
        index1[i] = index1[i] - padding[i,0];
        if (index1[i] &lt; 0 || index[i] &gt;= length(shape[i])) {
            is_pad = true;
        }
    }
    in_out_t value = is_pad ? pad_const : tensor_read&lt;in_out_t&gt;(input1, shape1, index1);
    tensor_write&lt;in_out_t&gt;(output, shape, index, value);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_reshape">2.10.3. RESHAPE</h4>
<div class="paragraph">
<p>Returns a tensor with the same type/values as the input, with a new shape specified by the shape argument. Reshape may operate on tensors of any rank. No data conversion happens during a reshape operation.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">new_shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[rank(shape)]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">List of values, with each element giving the size of the result tensor for the given dimension.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type, size as the input tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">ERROR_IF(tensor_size(shape1) != tensor_size(shape));

for_each(index in shape) {
    // Calculate flattened index for the output location (index)
    size_t offset = tensor_index_to_offset(shape, index);
    // Now convert to the location in the input
    dim_t tmp_index = tensor_offset_to_index(shape1, offset);

    // Now read/write the value
    in_out_t val = tensor_read&lt;in_out_t&gt;(input, shape1, tmp_index);
    tensor_write&lt;in_out_t&gt;(output, shape, index, val);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_reverse">2.10.4. REVERSE</h4>
<div class="paragraph">
<p>Returns a tensor with the same type/values as the input, with the data reversed along the given axis. No data conversion happens during a reverse operation.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor from 1 to 4 dims</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">axis</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Axis to reverse, in range from 0 to rank(shape)-1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor. Same shape as input tensor.</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">ERROR_IF(axis &lt; 0 || axis &gt;= rank(shape));
for_each(index in shape) {
    tmp_index = index;
    tmp_index[axis] = shape[axis] - 1 - index[axis];
    in_out_t value = tensor_read&lt;in_out_t&gt;(input, shape, tmp_index);
    tensor_write&lt;in_out_t&gt;(output, shape, index, value);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_slice">2.10.5. SLICE</h4>
<div class="paragraph">
<p>Extracts a slice of the input1 on the given axis, beginning at the start coordinates, and extending for size elements in each direction.
No data conversion happens during a slice operation.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with rank from 1 to 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">start</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[rank(input1)]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">List of integer coordinates, of length equal to the rank of input1. Start coordinate for slicing.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">size</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[rank(input1)]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">List of integer size values, of length equal to the rank of input1. Size of the input to be used.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type as the input tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">ERROR_IF(rank(input1) != length(start) || rank(input1) != length(size));
ERROR_IF(rank(input1) != rank(output))
// Sanity check the given coordinates, ensure start and end are
// within tensor bounds
for_each(index in rank(input1)) {
    ERROR_IF(start[index] &lt; 0);
    ERROR_IF(size[index] &lt;= 0); //Output must be positive size
    ERROR_IF(start[index] + size[index] &gt; shape1[index]);
    ERROR_IF(shape[index] != size[index]);
}

for_each(index in shape) {
    tmp_index = index;
    for(i = 0; i &lt; rank(shape); i++) {
       tmp_index[i] = index[i] + start[i];
    }
    in_out_t value = tensor_read&lt;in_out_t&gt;(input, shape1, tmp_index);
    tensor_write&lt;in_out_t&gt;(output, shape, index, value);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_tile">2.10.6. TILE</h4>
<div class="paragraph">
<p>Replicates input1 multiples times along each dimension.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with rank from 1 to 4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">multiples</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[rank(shape1)]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of times to replicate input1 in each dimension</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type, rank as the input tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">for_each(index in shape) {
    tmp_index = index;
    for(i = 0; i &lt; rank(shape); i++) {
        ERROR_IF(shape1[i] * multiples[i] != shape[i]);
        tmp_index[i] = index[i] % shape1[i];
    }
    in_out_t value = tensor_read&lt;in_out_t&gt;(input, shape1, tmp_index);
    tensor_write&lt;in_out_t&gt;(output, shape, index, value);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_transpose">2.10.7. TRANSPOSE</h4>
<div class="paragraph">
<p>Permutes the dimensions of the input tensor input1 based on the perms argument.
Each value in the perms list must be a valid dimension of the input tensor and may not be repeated.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor with minimum rank of one.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">perms</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[rank(input1)]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">List of integers of length equal to the rank of input1. Values must be valid dimensions within shape1, and may not be repeated.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type, rank as the input tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">for_each(index in perms) {
    // Ensure each perms value is a valid value
    ERROR_IF(index &gt;= rank(shape1));
    ERROR_IF(index &lt; 0);
    // Ensure ranks aren't repeated
    ERROR_IF(indexes_used[index] == true);
    indexes_used[index] = true;
}

// Ensure that the output shapes have the properly
// permuted shapes
for(i = 0; i &lt; rank(shape); i++) {
    ERROR_IF(shape1[perms[i]] != shape[i])
}

for_each(index in shape) {
    tmp_index = index;
    for(i = 0; i &lt; rank(shape); i++) {
        tmp_index[perms[i]] = index[i]
    }
    in_out_t value = tensor_read&lt;in_out_t&gt;(input, shape1, tmp_index);
    tensor_write&lt;in_out_t&gt;(output, shape, index, value);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_scattergather_operators">2.11. Scatter/Gather Operators</h3>
<div class="sect3">
<h4 id="_gather">2.11.1. GATHER</h4>
<div class="paragraph">
<p>Generate a tensor for which each element in the output is a subtensor of the values tensor based on the indices.
N is the number of batches, W the number of indices in each batch, K the range of each index and C the number data channels for each index.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">value_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">values</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,K,C]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3D value tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">index_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">indices</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,W]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2D index tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">value_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,W,C]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3D output tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">for_each(0 &lt;= n &lt; N, 0 &lt;= w &lt; W, 0 &lt;= c &lt; C) {
    index_t k = tensor_read&lt;index_t&gt;(indices, [N,W], [n,w]);
    REQUIRE(0 &lt;= k &amp;&amp; k &lt; K);
    value_t value = tensor_read&lt;value_t&gt;(values, [N,K,C], [n,k,c]);
    tensor_write&lt;value_t&gt;(output, [N,W,C], [n,w,c], value);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">index_t</th>
<th class="tableblock halign-left valign-top">value_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI,MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_scatter">2.11.2. SCATTER</h4>
<div class="paragraph">
<p>The values_out tensor is set to the values_in tensor with data modified as follows: data from the input tensor is inserted at the positions specified by the indices tensor.
N is the number of batches, W the number of indices in each batch, K the range of each index and C the number data channels for each index.
It is not permitted to repeat the same output index within a single SCATTER operation and so each output index occurs at most once.
In use cases that require multiple updates to the same output position, these must be decomposed into multiple SCATTER operations.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">value_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">values_in</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,K,C]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3D values in tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">index_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">indices</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,W]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2D index tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">value_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,W,C]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3D input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">value_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">values_out</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,K,C]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3D values out tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Quantization Parameters:</strong></p>
</div>
<div class="paragraph">
<p>None</p>
</div>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">// The following array is used to check compliance that an output position
// is modified at most once.
bool_t output_modified[N,K,C];

// Copy the values_in tensor to the values_out tensor.
// Values not written by the scatter operation are unchanged in the output.
for_each(0 &lt;= n &lt; N, 0 &lt;= k &lt; K, 0 &lt;= c &lt; C) {
    value_t value = tensor_read&lt;value_t&gt;(values_in, [N,K,C], [n,k,c]);
    tensor_write&lt;value_t&gt;(values_out, [N,K,C], [n, k, c], value);
    output_modified[n,k,c]=false;
}

// Now perform the SCATTER operation, modifying the positions from the indices tensor
for_each(0 &lt;= n &lt; N, 0 &lt;= w &lt; W, 0 &lt;= c &lt; C) {
    index_t k = tensor_read&lt;index_t&gt;(indices, [N,W], [n,w]);
    REQUIRE(0 &lt;= k &amp;&amp; k &lt; K);
    REQUIRE(output_modified[n,k,c] == false);
    value_t value = tensor_read&lt;value_t&gt;(input, [N,W,C], [n,w,c]);
    tensor_write&lt;value_t&gt;(values_out, [N,K,C], [n, k, c], value);
    output_modified[n,k,c] = true;
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">index_t</th>
<th class="tableblock halign-left valign-top">value_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI,MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI,MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI,MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_image_operators">2.12. Image Operators</h3>
<div class="sect3">
<h4 id="_resize">2.12.1. RESIZE</h4>
<div class="paragraph">
<p>Resizes a tensor. Resize is only allowed in the H and W dimensions.</p>
</div>
<div class="paragraph">
<p>The NEAREST_NEIGHBOR mode returns the value of the input tensor closest to the
calculated sample position for both floating-point and integer data formats.</p>
</div>
<div class="paragraph">
<p>Floating-point BILINEAR mode returns a bilinearly interpolated output value
based on the four closest input sample positions.</p>
</div>
<div class="paragraph">
<p>For integer BILINEAR interpolation mode, the output value is calculated by using
the shift value along with the other parameters to create a fixed point scaling
factor for each input. These values are then summed to create the value for
output, which has 2 * shift fractional bits. To convert back to the original
integer size, the output value must be rescaled.</p>
</div>
<div class="paragraph">
<p>The following examples show practical uses of the parameters:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>For approximate uniform input sampling between (0, 0) and (IH-1, IW-1) set
stride_y = ( (IH-1) * (1&lt;&lt;shift) ) / (OH-1),
stride_x = ( (IW-1) * (1&lt;&lt;shift) ) / (OW-1),
offset_x=0, offset_y=0, border_x=0, border_y=0.</p>
</li>
<li>
<p>For power of two upscale by factor (1&lt;&lt;k) the following parameters can
be used for fixed point upscales:</p>
<div class="ulist">
<ul>
<li>
<p>For upscale [OH-1,OW-1] = (1&lt;&lt;k) * [IH-1, IW-1] set
shift=k, stride_y=1, stride_x=1, offset_x=0, offset_y=0,
border_x=0, border_y=0.</p>
</li>
<li>
<p>For upscale [OH,OW] = (1&lt;&lt;k) * [IH,IW] set
shift=(k+1), stride_y=2, stride_x=2, offset_x=-(1&lt;&lt;k)+1, offset_y=-(1&lt;&lt;k)+1,
border_x=1&lt;&lt;(k-1), border_y=1&lt;&lt;(k-1). This samples approximately
the input area (-0.5, -0.5) to (IH-0.5, IW-0.5).</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,IH,IW,C]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output_size</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[2]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[OH,OW]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">resize_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">stride</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[2]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[stride_y, stride_x]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">resize_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">offset</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[2]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[offset_y, offset_x]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">border</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[2]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[border_y, border_x]</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shift</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Shift value (must be zero if resize_t is float)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">mode_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">mode</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">BILINEAR or NEAREST</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[N,OH,OW,C]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">// Derive the output dimensions from the input dimensions
OH = idiv((IH-1)*(1&lt;&lt;shift) - offset_y, stride_y) + 1 + border_y;
OW = idiv((IW-1)*(1&lt;&lt;shift) - offset_x, stride_x) + 1 + border_x;
// Ensure the image size is supported by GPU APIs and that for integer
// implementations, position * stride does not overflow int32_t.
ERROR_IF(max(OH,OW,IH,IW) &gt;= 16384);
ERROR_IF(stride_x &lt;= 0 || stride_y &lt;= 0);
if (is_floating_point(resize_t)) {
    // The shift attribute is not used for floating point
    ERROR_IF(shift != 0);
    ERROR_IF(stride_x &gt; IW || stride_y &gt; IH);
} else {
    // if in_t=int8_t ensure that an int32_t accumulator can be used
    ERROR_IF(shift &lt; 1 || shift &gt; 11);
    // set a consistent lower limit of 1/16 downscale
    // independent of the shift value to simplify implementations
    ERROR_IF(stride_x &gt;= (16 &lt;&lt; shift));
    ERROR_IF(stride_y &gt;= (16 &lt;&lt; shift));
    // offset range is similarly limited to maximum 16 pixels irrespective
    // of shift. Both stride and offset fit in int16_t when shift=11.
    ERROR_IF(offset_x &lt;= (-16 &lt;&lt; shift) || offset_x &gt;= (16 &lt;&lt; shift));
    ERROR_IF(offset_y &lt;= (-16 &lt;&lt; shift) || offset_y &gt;= (16 &lt;&lt; shift));
}
for_each(0 &lt;= n &lt; N, 0 &lt;= oy &lt; OH, 0 &lt;= ox &lt; OW; 0 &lt;= c &lt; C) {
    unit = (is_floating_point(resize_t)) ? 1.0 : (1 &lt;&lt; shift);
    y = oy * stride_y + offset_y;
    x = ox * stride_x + offset_x;
    if (is_floating_point(resize_t)) {
        iy = (int32_t)apply_floor(y); dy = y - (resize_t)iy;
        ix = (int32_t)apply_floor(x); dx = x - (resize_t)ix;
    } else {
        iy = y &gt;&gt; shift; dy = y - (iy&lt;&lt;shift);
        ix = x &gt;&gt; shift; dx = x - (ix&lt;&lt;shift);
    }
    iy0 = apply_max(iy, 0);
    iy1 = apply_min(iy+1, IH-1);
    ix0 = apply_max(ix, 0);
    ix1 = apply_min(ix+1, IW-1);
    REQUIRE(ix0 &lt;= ix1 &amp;&amp; iy0 &lt;= iy1);
    if (mode==BILINEAR) {
        v00 = tensor_read&lt;in_t&gt;(input, [N,IH,IW,C], [n,iy0,ix0,c]);
        v01 = tensor_read&lt;in_t&gt;(input, [N,IH,IW,C], [n,iy0,ix1,c]);
        v10 = tensor_read&lt;in_t&gt;(input, [N,IH,IW,C], [n,iy1,ix0,c]);
        v11 = tensor_read&lt;in_t&gt;(input, [N,IH,IW,C], [n,iy1,ix1,c]);
        out_t acc = v00 * (unit - dy) * (unit - dx) + v01 * (unit - dy) * dx;
        acc = acc + v10 * dy * (unit-dx) + v11 * dy * dx;
        tensor_write&lt;out_t&gt;(output, [N,OH,OW,C], [n,oy,ox,c], acc);
    } else if (mode==NEAREST) {
        iy = (dy &gt;= unit/2) ? iy1 : iy0;
        ix = (dx &gt;= unit/2) ? ix1 : ix0;
        v = tensor_read&lt;in_t&gt;(input, [N,IH,IW,C], [n,iy,ix,c]);
        tensor_write&lt;out_t&gt;(output, [N,OH,OW,C], [n,oy,ox,c], v);
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">resize_t</th>
<th class="tableblock halign-left valign-top">in_t</th>
<th class="tableblock halign-left valign-top">out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8,  bilinear</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8,  nearest</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16, bilinear</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int48_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16, nearest</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI,MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI,MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI,MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Resize Modes:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">NEAREST</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Nearest Neighbor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">BILINEAR</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Bilinear interpoloation</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_type_conversion">2.13. Type Conversion</h3>
<div class="sect3">
<h4 id="_cast">2.13.1. CAST</h4>
<div class="paragraph">
<p>Casts a tensor from one data type to another.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">for_each(index in shape) {
    in_t in = tensor_read&lt;in_t&gt;(input, shape, index);
    out_t out;
    if (out_t == bool_t) {
        out = (in != 0) ? true : false;
    } else if (in_t == bool_t) {
        out = (in) ? 1 : 0;
    } else if (out_t == fp16_t || out_t == bf16_t || out_t == fp32_t) {
        out = round_to_nearest_float(in);
    } else if (in_t == fp16_t || in_t == bf16_t || in_t == fp32_t) {
        out = apply_clip&lt;out_t&gt;(round_to_nearest_int(in), minimum&lt;out_t&gt;, maximum&lt;out_t&gt;);
    } else if (sizeof(out_t) &gt;= sizeof(in_t)) {
        out = sign_extend(in);
    } else {
        out = truncate(in);
    }
    tensor_write&lt;out_t&gt;(output, shape, index, out)
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_t</th>
<th class="tableblock halign-left valign-top">out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool to signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool to signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool to signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8 to bool</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8 to signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8 to signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8 to fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8 to bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8 to fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16 to bool</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16 to signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16 to signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16 to fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16 to bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16 to fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32 to bool</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32 to signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32 to signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32 to fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32 to bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32 to fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 to signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 to signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16 to signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16 to signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16 to signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16 to signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32 to signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32 to signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32 to signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_rescale">2.13.2. RESCALE</h4>
<div class="paragraph">
<p>Rescale quantized values into a new domain. This function scales by factor: multiplier * 2<sup>-shift</sup>.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor from 1 to 4 dims</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor with the same shape as input</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor zero point. Must be zero for non-int8 types.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">out_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output_zp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor zero point. Must be zero for non-int8 types.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input (MT profile) Attribute (BI/MI profiles)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">mul_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">multiplier</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[NC]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling multiplier array</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input (MT profile) Attribute (BI/MI profiles)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">uint6_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shift</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">[NC]</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Scaling shift array</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">scale32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">if (scale32) mul_t=int32_t else mul_t=int16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">double_round</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Select double round mode</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">per_channel</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">if (per_channel) NC=shape[dims-1] else NC=1</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">for_each(index in shape) {
    // uint16 values can have zero_point 0 or 32768
    // int8/uint8 can have zero point within their valid range
    // No other types can have zero point != 0
    ERROR_IF(in_t != int8_t &amp;&amp;
             in_t != uint8_t &amp;&amp;
             in_t != uint16_t &amp;&amp; input_zp != 0);
    ERROR_IF(out_t != int8_t &amp;&amp;
             out_t != uint8_t &amp;&amp;
             out_t != uint16_t &amp;&amp; output_zp != 0);
    ERROR_IF(in_t == uint16_t &amp;&amp; (input_zp != 0 || input_zp != 32768));
    ERROR_IF(out_t == uint16_t &amp;&amp; (output_zp != 0 || output_zp != 32768));
    ERROR_IF(scale32 &amp;&amp; in_t == int48_t);
    ERROR_IF(!scale32 &amp;&amp; double_round);
    int48_t value = tensor_read&lt;in_t&gt;(input, shape, index);
    value = value - input_zp;
    int c = (per_channel) ? index[dims-1] : 0;
    int32_t result = (scale32) ?
        apply_scale_32(value, multiplier[c], shift[c], double_round) :
        apply_scale_16(value, multiplier[c], shift[c]);
    result = (out_t)apply_clip&lt;int32_t&gt;(result + output_zp, minimum&lt;out_t&gt;, maximum&lt;out_t&gt;);
    tensor_write&lt;out_t&gt;(output, shape, index, result);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_t</th>
<th class="tableblock halign-left valign-top">out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8 to signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8 to signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8 to signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8 to unsigned 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">uint8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16 to signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16 to signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16 to signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16 to unsigned 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">uint8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16 to unsigned 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">uint16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32 to signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32 to signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32 to signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 48 to signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int48_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 48 to signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int48_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 48 to signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int48_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">unsigned 8 to signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">uint8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">unsigned 8 to signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">uint8_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">unsigned 16 to signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">uint16_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_data_nodes">2.14. Data Nodes</h3>
<div class="sect3">
<h4 id="_const">2.14.1. CONST</h4>
<div class="paragraph">
<p>A node containing constant data for use as the input to an operation. May hold data in any of the supported data formats.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">values</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Constant values</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type, size as the input tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_identity">2.14.2. IDENTITY</h4>
<div class="paragraph">
<p>Returns a tensor with the same shape, type, and contents as the input.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Shape</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">in_out_t*</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output tensor of same type, size as the input tensor</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Supported Data Types:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Profile</th>
<th class="tableblock halign-left valign-top">Mode</th>
<th class="tableblock halign-left valign-top">in_out_t</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">signed 32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int32_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bf16_t</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MI, MT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">fp32_t</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_custom_operators">2.15. Custom Operators</h3>
<div class="paragraph">
<p>Hardware implementing TOSA may choose to add additional custom operators that are not expressed in the existing TOSA operations. These operators are not expected to be portable across TOSA implementations. The input and output signatures must be expressed in the corresponding TOSA node.</p>
</div>
<div class="sect3">
<h4 id="_custom">2.15.1. CUSTOM</h4>
<div class="paragraph">
<p>Input Operands:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Num input operands – Scalar number of input operands</p>
</li>
<li>
<p>Num output operands – Scalar number of output operands</p>
</li>
<li>
<p>Operator code – untyped data consisting of the operator data</p>
</li>
<li>
<p>Affine transform description for each tensor</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_control_flow_operators">2.16. Control Flow Operators</h3>
<div class="paragraph">
<p>TOSA implements two control flow operators, for conditional branching and loop based control. Both have attributes that are TOSA sub-graphs.</p>
</div>
<div class="sect3">
<h4 id="_cond_if">2.16.1. COND_IF</h4>
<div class="paragraph">
<p>Evaluates a Boolean condition and then takes one of two distinct execution paths. This implements the semantic if-then-else structure.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">tensor_list_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input_list</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">List of input tensors</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">condition</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input condition as rank-0 tensor</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">tosa_graph_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">then_graph</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">TOSA graph to execute if condition is true</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">tosa_graph_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">else_graph</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">TOSA graph to execute if condition is false</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">tensor_list_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output_list</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">List of output tensors</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">ERROR_IF(tensor_list_shape(input_list) != tosa_input_shape(then_graph));
ERROR_IF(tensor_list_shape(input_list) != tosa_input_shape(else_graph));
ERROR_IF(tensor_list_shape(output_list) != tosa_output_shape(then_graph));
ERROR_IF(tensor_list_shape(output_list) != tosa_output_shape(else_graph));

if (condition) {
    tosa_execute_graph(then_graph, input_list, output_list);
} else {
    tosa_execute_graph(else_graph, input_list, output_list);
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_while_loop">2.16.2. WHILE_LOOP</h4>
<div class="paragraph">
<p>Generates and evaluates a Bool condition and either executes a loop body or exits the loop. This action is performed repeatedly after updating and re-evaluating the Boolean condition every iteration. This implements the semantic foreach or while iterative loop structure.</p>
</div>
<div class="paragraph">
<p><strong>Arguments:</strong></p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argument</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Input</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">tensor_list_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">input_list</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">List of input tensors</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">tosa_graph_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">cond_graph</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">TOSA graph to evaluate the condition</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Attribute</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">tosa_graph_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">body_graph</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">TOSA graph to execute the loop body</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Output</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">tensor_list_t</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">output_list</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">List of output tensors</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><strong>Operation Function:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">ERROR_IF(tensor_list_shape(input_list) != tosa_list_shape(output_list));
ERROR_IF(tensor_list_shape(input_list) != tosa_input_shape(cond_graph));
ERROR_IF(tensor_list_shape(input_list) != tosa_input_shape(body_graph));
ERROR_IF(tensor_list_shape(input_list) != tosa_output_shape(body_graph));
ERROR_IF(tosa_output_shape(cond_graph) != tosa_list_shape([bool_t]));

// The iteration number 'i' is included to give unique names to variables
// in each iteration of the loop and is not required by implementations
int32_t i=0;             // iteration number
list[i] = input_list;    // copy input data as list[0]
tosa_execute_graph(cond_graph, list[i], [condition[i]]);   // initial condition
while (condition[i]) {
    tosa_execute_graph(body_graph, list[i], list[i+1]);
    i = i+1;
    tosa_execute_graph(cond_graph, list[i], [condition[i]]);
}
output_list = list[i];</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_tosa_pseudocode">3. TOSA Pseudocode</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The TOSA pseudocode provides precise descriptions of TOSA operations.
Each operator contains pseudocode describing the operator&#8217;s functionality.
This section contains pseudocode functions shared across multiple operators in the specification.</p>
</div>
<div class="sect2">
<h3 id="_operator_validation_helpers">3.1. Operator Validation Helpers</h3>
<div class="paragraph">
<p>The following functions are used to define the valid conditions for TOSA operators.</p>
</div>
<div class="paragraph">
<p>The REQUIRE function defines the conditions required by the TOSA operator.
If the conditions are not met then the result of the TOSA graph is marked as unpredictable.
Once the tosa_graph_result is set to tosa_unpredictable, the whole graph is considered unpredictable.</p>
</div>
<div class="paragraph">
<p>The ERROR_IF function defines a condition that must set an error if the condition holds and the graph is not unpredictable.
Note that if a graph contains both unpredictable and error statements then result of tosa_execute_graph() is tosa_unpredictable.
This condition is captured in the ERROR_IF function.</p>
</div>
<div class="paragraph">
<p><strong>Implementation Notes</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>An implementation is not required to detect unpredictable behavior. If tosa_execute_graph() returns tosa_unpredictable then the tosa_test_compliance() function does not require any specific output from an implementation.</p>
</li>
<li>
<p>An implementation is required to detect errors in a graph that does not have unpredictable behavior (see tosa_test_compliance).</p>
</li>
<li>
<p>An acceptable implementation is to stop and report an error on the first ERROR_IF condition that occurs. This satifies tosa_test_compliance() even if the tosa_execute_graph() was tosa_unpredictable.</p>
</li>
<li>
<p>If the tosa_execute_graphs() result is tosa_unpredictable or tosa_error, then there is no requirement on the implementation to execute any portion of the TOSA graph.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">void REQUIRE(condition) {
    // Unpredictable overrides any previous result
    if (!(condition)) {
        tosa_graph_result = tosa_unpredictable;
    }
}

void ERROR_IF(condition) {
    // Error encodes a predictable error state and so is not registered
    // if the graph is marked as unpredictable.
    if (tosa_graph_result != tosa_unpredictable &amp;&amp; condition) {
        tosa_graph_result = tosa_error;
    }
}</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_tensor_access_helpers">3.2. Tensor Access Helpers</h3>
<div class="sect3">
<h4 id="_tensor_utilities">3.2.1. Tensor Utilities</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">size_t tensor_index_to_offset(dim_t shape, dim_t index) {
    // Ensure this is a proper tensor with each dimension having size &gt;= 1
    for_each(dimension_size in shape) {
        REQUIRE(dimension_size &gt;= 1);
    }
    size_t offset = 0;
    for (int32_t i = 0; i &lt; rank(shape); i++) {
        REQUIRE(index[i] &gt;= 0 &amp;&amp; index[i] &lt; shape[i]);
        offset = offset * shape[i] + index[i];
    }
    return offset;
}

dim_t tensor_offset_to_index(dim_t shape, size_t offset) {
    // Index is a dim_t with rank equal to the rank of shape
    dim_t index(rank(shape));
    for(int32_t r = rank(shape1) - 1; r &gt;= 0; r--) {
        index[r] = offset % shape1[r];
        calculated_index /= shape[r];
    }
    return index;
}

// Input is the shape of the given tensor
size_t tensor_size(dim_t shape) {
    size_t size = 1;
    for (int32_t i=0; i &lt; rank(shape); i++) {
        size *= input[i];
    }
    return size;
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_tensor_read">3.2.2. Tensor Read</h4>
<div class="paragraph">
<p>tensor_read reads a single data value out of the given tensor.
The shape argument contains the shape of the tensor.
Index is the coordinates within the tensor of the value to be read.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">in_t tensor_read&lt;in_t&gt;(in_t *address, dim_t shape, dim_t index) {
    size_t offset = tensor_index_to_offset(shape, index);
    return address[offset];
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_tensor_write">3.2.3. Tensor Write</h4>
<div class="paragraph">
<p>tensor_write writes a single data value into the given tensor.
The shape argument contains the shape of the tensor.
Index is the coordinates within the tensor of the value to be written.
value is the value to be written to the given coordinate.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">void tensor_write&lt;type&gt;(&lt;type&gt; *address, dim_t shape, dim_t index, &lt;type&gt; value) {
    size_t offset = tensor_index_to_offset(shape, index);
    address[offset] = value;
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_broadcast_helper">3.2.4. Broadcast Helper</h4>
<div class="paragraph">
<p>The following function maps an index in the output tensor to an index in the input tensor.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">// The index argument should be a valid location within out_shape.
// The function returns the location within in_shape that contributes
// to the output based on broadcasting rules.

dim_t apply_broadcast(dim_t out_shape, dim_t in_shape, dim_t index) {
    ERROR_IF(rank(out_shape) != rank(in_shape));
    ERROR_IF(rank(out_shape) != rank(index));
    for (int32_t i = 0; i &lt; rank(out_shape); i++) {
        if (out_shape[i] != in_shape[i]) {
            ERROR_IF(in_shape[i] != 1);
            index[i] = 0;
        }
    }
    return index;
}</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_general_pseudocode_helpers">3.3. General Pseudocode Helpers</h3>
<div class="paragraph">
<p>This section contains general pseudocode utility functions used throughout the specification.</p>
</div>
<div class="sect3">
<h4 id="_arithmetic_helpers">3.3.1. Arithmetic Helpers</h4>
<div class="paragraph">
<p>The following functions provide arithmetic while defining requirements such that values stay in the valid range.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">in_t apply_add&lt;in_t&gt;(in_t a, in_t b) {
    if (is_floating_point(in_t)) return a + b;
    int64_t c = (int64_t)a + (int64_t)b;
    REQUIRE(c &gt;= minimum&lt;in_t&gt; &amp;&amp; c &lt;= maximum&lt;in_t&gt;);
    return (in_t)c;
}

in_t apply_ceil&lt;in_t&gt;(in_t input) {
    return input value rounded up to nearest integer
}

in_t apply_clip&lt;in_t&gt;(in_t value, in_t min_val, in_t max_val) {
    REQUIRE(min_val &lt;= max_val);
    value = apply_max(value, min_val);
    value = apply_min(value, max_val);
    return value;
}

in_t apply_exp&lt;in_t&gt;(in_t input) {
    return e to the power input
}

in_t apply_floor&lt;in_t&gt;(in_t input) {
    return input value rounded down to nearest integer
}

in_t apply_log&lt;in_t&gt;(in_t input) {
    if (input == 0) {
        return -INFINITY
    }
    else if (input &lt; 0) {
        return NaN;
    }
    return the natural logarithm of input
}

in_t apply_max&lt;in_t&gt;(in_t a, in_t b) {
    if (is_floating_point(in_t)) {
        if (isNaN(a) || isNaN(b)) {
            return NaN;
        }
    }
    if (a &gt;= b) return a; else return b;
}

in_t apply_min&lt;in_t&gt;(in_t a, in_t b) {
    if (is_floating_point(in_t)) {
        if (isNaN(a) || isNaN(b)) {
            return NaN;
        }
    }
    if (a &lt; b) return a; else return b;
}

in_t apply_pow&lt;in_t&gt;(in_t a, in_t b) {
    return a ** b; // a raised to the power b
}

in_t apply_sqrt&lt;in_t&gt;(in_t input) {
    return the square root of input
}

in_t apply_sub&lt;in_t&gt;(in_t a, in_t b) {
    if (is_floating_point(in_t)) return a - b;
    int64_t c = (int64_t)a - (int64_t)b;
    REQUIRE(c &gt;= minimum&lt;in_t&gt; &amp;&amp; c &lt;= maximum&lt;in_t&gt;);
    return (in_t)c;
}

int32_t count_leading_zeros(int32_t a) {
    int32_t acc = 32;
    if (a != 0) {
        uint32_t mask;
        mask = 1 &lt;&lt; (32 - 1); // width of int32_t - 1
        acc = 0;
        while ((mask &amp; a) == 0) {
            mask = mask &gt;&gt; 1;
            acc = acc + 1;
        }
    }
    return acc;
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_numeric_conversion_helpers">3.3.2. Numeric Conversion Helpers</h4>
<div class="paragraph">
<p>The following definitions are used in pseudocode to do numeric conversions.
Where the <strong>float_t</strong> type is used, it represents all of the floating-point data types supported by the given profile.
See <a href="#Number formats">[Number formats]</a> for details on the floating-point formats.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">int round_to_nearest_int(float_t f)
  Converts the floating-point value to f, with rounding to the nearest integer value.

float_t round_to_nearest_float(in_t f)
  Converts the input value into floating-point, rounding to the nearest representable value.
  The behavior for ties is implementation dependent.

out_t sign_extend(in_t input)
  Only valid for two's complement integer values where out_t has more bits than in_t.
  Output = input
  Replicate the top bit of input for all bits between the top bit of input and the top bit of output.

out_t truncate(in_t input)
  output is the sizeof(out_t) least significant bits in input.</code></pre>
</div>
</div>
<div class="paragraph">
<p>The following definition is used to flatten a list of lists into a single list.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">in_t* flatten(in_t lists[]) {
    in_t output = [];
    for_each(list in lists) {
        for_each(element in list) {
            output.append(element);
        }
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Generic helper functions used to keep the pseudocode concise.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-c++" data-lang="c++">bool_t is_floating_point(type) {
    if (type == fp16_t || type == fp32_t || type == bf16_t)
        return true;
    return false;
}

int32_t idiv(int32_t input1, int32_t input2) {
    return input1 / input2; // Integer divide that truncates towards zero
}

// Integer division that checks input1 is a multiple of input2

int32_t idiv_check(int32_t input1, int32_t input2) {
    ERROR_IF(input1 % input2 != 0); // input1 must be a multiple of input2
    return input1 / input2;         // exact quotient without rounding
}

int32_t length(in_t input)
    return number of elements in input list

int32_t rank(in_t input)
    return rank of an input tensor

int32_t sum(in_t input[])
    return the sum of values of an input list

bool isNaN(float input)
    return True if floating-point input value is NaN

float_t pi()
    returns value of pi

float_t sin(angle)
    return sine of angle given in radians

float_t cos(angle)
    return cosine of angle given in radians

bool power_of_two(int32_t value)
    return true if value is a power of two, false otherwise</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Version 0.30.0<br>
Last updated 2022-06-13 13:00:40 -0700
</div>
</div>
</body>
</html>
